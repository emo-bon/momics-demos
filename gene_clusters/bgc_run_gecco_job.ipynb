{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App for running GECCO jobs in Galaxy\n",
    "\n",
    "1. Upload and run workflow.\n",
    "2. Monitor the job.\n",
    "3. Receive completion notification with some basic summary provided by Galaxy.\n",
    "\n",
    "Note: \"Receiving\" the results (tentatively download) is part of the analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "- does NOT support, but include `.gb`, `.gbk` and `.embl` formats to be allowed\n",
    "  - .embl from ena comes as `.txt` actually.\n",
    "  - ncbi genbank download full or normal always cames as `.gb`\n",
    "  - careful, this has implication by selecting datasets by key method\n",
    "    - conditions need to be in a list\n",
    "  - \n",
    "- add history id to the saved metadata\n",
    "- save json, from the analysis dashboard, update the json (this will be heavily environmental dependent)\n",
    "  - note for which environments it works (like GColab env will get deleted etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "logger = logging.getLogger(name=\"GECCO galaxy runner\")\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # clone the momics-demos repository to use the utils module from there\n",
    "    # TODO: eventually utils from momics will be used for that\n",
    "    try:\n",
    "        os.system('git clone https://github.com/palec87/momics-demos.git')\n",
    "        logger.info(f\"Repository cloned\")\n",
    "    except OSError as e:\n",
    "        logger.info(f\"An error occurred while cloning the repository: {e}\")\n",
    "\n",
    "    sys.path.insert(0,'/content/momics-demos')\n",
    "\n",
    "else:\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # local utils, to be removed in the future\n",
    "\n",
    "    # downside of this is that all the deps need to be installed in the current (momics-demos) environment\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics')))  # local momics package, to be removed too\n",
    "\n",
    "from utils import init_setup, get_notebook_environment\n",
    "init_setup()\n",
    "\n",
    "# Initialize the environment variable\n",
    "notebook_environment = 'unknown'\n",
    "# Determine the notebook environment\n",
    "env = get_notebook_environment()\n",
    "logger.info(f\"Environment: {env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be repeated here for the Pannel dashboard to work, WEIRD\n",
    "# TODO: report as possible bug\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "import bioblend.galaxy as g  # BioBlend is a Python library, wrapping the functionality of Galaxy and CloudMan APIs\n",
    "# import boto3\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "# from bioblend.galaxy import GalaxyInstance\n",
    "# from bioblend.galaxy.config import ConfigClient\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import init_setup\n",
    "init_setup()\n",
    "\n",
    "from bioblend.galaxy.datasets import DatasetClient\n",
    "\n",
    "from momics.galaxy import BCGalaxy\n",
    "from momics.panel_utils import (\n",
    "    serve_app, close_server,\n",
    ")\n",
    "from momics.utils import memory_load, reconfig_logger\n",
    "\n",
    "# instead of the jupyter magic, you can also use\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True  # enable stdout logging\n",
    "reconfig_logger()  # Set up logging\n",
    "\n",
    "# these variables need to be set in the .env file at the root of the project\n",
    "exp = BCGalaxy(\"GALAXY_EARTH_URL\", \"GALAXY_EARTH_KEY\")\n",
    "gecco_tool_id = \"toolshed.g2.bx.psu.edu/repos/althonos/gecco/gecco/0.9.6\"  # The id of the tool GECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environmentally dependent paths.\n",
    "# TODO: why is this not in the momics package already?\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    root_folder = os.path.abspath(os.path.join('/content/momics-demos'))\n",
    "else:\n",
    "    root_folder = os.path.abspath(os.path.join('../'))\n",
    "\n",
    "assets_folder = os.path.join(root_folder, 'assets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App setup\n",
    "\n",
    "TODO: do I really need to duplicate the `current_history`, `current_file` name and id? I could handle the tuples in the \"backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buttons\n",
    "but_login = pn.widgets.Button(name=\"üîê Galaxy Login\")\n",
    "but_get_histories = pn.widgets.Button(name=\"üìö Refresh Histories\")\n",
    "but_create_history = pn.widgets.Button(name=\"üìù Create New History\")\n",
    "but_get_datasets = pn.widgets.Button(name=\"üìñ Refresh Datasets\")\n",
    "\n",
    "# input file handling\n",
    "but_upload_dataset = pn.widgets.Button(name=\"üì§ Upload Dataset to Galaxy\")\n",
    "file_input = pn.widgets.FileSelector('~', file_pattern='*.fasta')\n",
    "file_source_checkbox = pn.widgets.Checkbox(name='Use a file from the Galaxy', value=True)\n",
    "\n",
    "but_submit = pn.widgets.Button(name=\"üöÄ Submit GECCO task\")\n",
    "\n",
    "# this perhaps can get solved with file selector\n",
    "history_name = pn.widgets.TextInput(name='New History Name', placeholder='Enter a string here...')\n",
    "\n",
    "current_history_name = pn.widgets.StaticText(name='Current History Name', value='No history selected')\n",
    "current_history_id = pn.widgets.StaticText(name='Current History ID', value='')\n",
    "\n",
    "current_file_name = pn.widgets.StaticText(name='Current filename for GECCO', value='No file selected')\n",
    "current_file_id = pn.widgets.StaticText(name='Current file ID for GECCO', value='')\n",
    "\n",
    "# selectors\n",
    "select_history = pn.widgets.Select(\n",
    "    name=\"Select History\",\n",
    "    options=[],\n",
    "    description=\"Your Galaxy histories, create a new one if needed\",\n",
    ")\n",
    "select_dataset = pn.widgets.Select(\n",
    "    name=\"Select Dataset\",\n",
    "    options=[(\"\", \"\")],\n",
    "    description=\"Your Galaxy fasta datasets\",\n",
    "    value=(\"\", \"\"),\n",
    ")\n",
    "\n",
    "# intro text\n",
    "intro_text = pn.pane.Markdown(\n",
    "    \"\"\"\n",
    "    # GECCO Galaxy Runner\n",
    "\n",
    "    GECCO (Gene Cluster prediction with Conditional Random Fields) is a fast and scalable method for identifying putative novel Biosynthetic Gene Clusters (BGCs) in genomic and metagenomic data using Conditional Random Fields (CRFs). It is developed in the Zeller group and is part of the suite of computational microbiome analysis tools hosted at EMBL.\n",
    "\n",
    "    ## Instructions\n",
    "\n",
    "    1. Log in to your Galaxy instance.\n",
    "    2. Select a history or create a new one.\n",
    "    3. Select or upload a fasta/GenBank/EMBL file to the selected history.\n",
    "    4. Submit the GECCO task.\n",
    "    5. Continue with the post-processing of the results in the analysis NB.\n",
    "\n",
    "    ## Output\n",
    "\n",
    "    GECCO will create the following files once done (using the same prefix as the input file):\n",
    "\n",
    "    - features.tsv: The genes file, containing the genes identified in the input sequences.\n",
    "    - features.tsv: The features file, containing the protein domains identified in the input sequences.\n",
    "    - clusters.tsv: A clusters file, containing the coordinates of the predicted clusters, along their putative biosynthetic type.\n",
    "    - {sequence}_cluster_{N}.gbk: If any BGCs were found, a GenBank file per cluster, containing the cluster sequence annotated with its member proteins and domains.\n",
    "\n",
    "    ## References\n",
    "    [link](https://doi.org/10.1101/2021.05.03.442509) Carroll, L. M., Larralde, M., Fleck, J. S., Ponnudurai, R., Milanese, A., Cappio, E., & Zeller, G. (2021). Accurate de novo identification of biosynthetic gene clusters with GECCO.\n",
    "    [GECCO tool page](https://usegalaxy.eu/?tool_id=toolshed.g2.bx.psu.edu%2Frepos%2Falthonos%2Fgecco%2Fgecco%2F0.9.6)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# gecco params\n",
    "mask = pn.widgets.Checkbox(name='Enable masking of regions with unknown nucleotides', value=False)\n",
    "pad = pn.widgets.Checkbox(name='Enable padding of gene sequences smaller than the CRF window length', value=True)\n",
    "cds = pn.widgets.IntInput(name='IntInMinimum number of genes required for a clusterput',\n",
    "                          value=3, step=1, start=2, end=1000,\n",
    "                          )\n",
    "threshold = pn.widgets.FloatInput(name='Probability threshold for cluster detection',\n",
    "                                  value=0.05, step=0.01, start=0.0, end=1.0,\n",
    "                                  )\n",
    "postproc = pn.widgets.Select(\n",
    "    name=\"Post-processing method for gene cluster validation\",\n",
    "    options=[\"gecco\", \"antiSMASH\"],\n",
    ")\n",
    "gene_filter = pn.widgets.IntInput(\n",
    "    name='Number of genes from the contig edges to filter out',\n",
    "    value=0, step=1, start=0, end=100)\n",
    "\n",
    "antimash_sideload = pn.widgets.Checkbox(name='Generate an antiSMASH v6 sideload JSON file', value=False)\n",
    "\n",
    "# this is currently not Implemented for Galaxy tools\n",
    "# monitor here, https://github.com/galaxyproject/galaxy/issues/1364\n",
    "# email_input = pn.widgets.TextInput(name='Email notification', placeholder='Enter a string here...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks and methods\n",
    "def handle_login(clicks):\n",
    "    exp = BCGalaxy(\"GALAXY_EARTH_URL\", \"GALAXY_EARTH_KEY\")\n",
    "    if DEBUG:\n",
    "        logger.debug(\"exp id: \", id(exp))\n",
    "    pn.state.notifications.info(f\"User logged in: {exp.cfg.whoami()}\")\n",
    "    logger.info(f'You have clicked me {clicks} times')\n",
    "\n",
    "    # get the histories right upon login\n",
    "    handle_get_histories(clicks)\n",
    "\n",
    "    # get the datasets right upon login\n",
    "    handle_get_datasets(clicks)\n",
    "\n",
    "\n",
    "def handle_get_histories(clicks):\n",
    "    if DEBUG:\n",
    "        logger.debug(\"exp id: \", id(exp))\n",
    "    exp.get_histories()\n",
    "\n",
    "    # clean histories dict for display, remove deleted histories and select fust relevant fields\n",
    "    clean_histories = exp.clean_histories_for_display()\n",
    "\n",
    "    select_history.options = clean_histories\n",
    "    select_history.value = clean_histories[0]\n",
    "    logger.info(f\"{len(clean_histories)} histories found.\")\n",
    "\n",
    "    # update the current history name\n",
    "    handle_update_current_history_name(select_history.value)\n",
    "    handle_update_current_history_id(select_history.value)\n",
    "\n",
    "\n",
    "def handle_get_datasets(clicks):\n",
    "    # this already filters the datasets by the extension\n",
    "    datasets, *_ = exp.get_datasets_by_key(\"extension\", \"fasta\")\n",
    "    logger.info(f\"Datasets found: {datasets}\")\n",
    "    # fill the select_dataset widget\n",
    "    select_dataset.options = datasets\n",
    "    select_dataset.value = datasets[0]\n",
    "    if DEBUG:\n",
    "        logger.info(f\"Datasets selector options: {select_dataset.options}\")\n",
    "        logger.info(f\"Datasets selector value: {select_dataset.value}, {type(select_dataset.value)}\")\n",
    "        logger.info(f\"Datasets selector value[0]: {select_dataset.value[0]}\")\n",
    "        logger.info(f\"Datasets selector value[1]: {select_dataset.value[1]}\")\n",
    "    # this is the id of the dataset\n",
    "    handle_update_current_file_name(select_dataset.value)\n",
    "    \n",
    "    logger.info(f\"{len(datasets)} datasets found.\")\n",
    "\n",
    "\n",
    "def handle_update_current_file_name(value):\n",
    "    current_file_name.value = value[0]\n",
    "    current_file_id.value = value[1]\n",
    "\n",
    "\n",
    "def handle_update_current_history_name(value):\n",
    "    current_history_name.value = value['name']\n",
    "\n",
    "\n",
    "def handle_update_current_history_id(value):\n",
    "    current_history_id.value = value['id']\n",
    "\n",
    "\n",
    "def handle_create_history(clicks):\n",
    "    # this supresses history creation upon startup\n",
    "    if clicks == 0:\n",
    "        return\n",
    "    \n",
    "    if history_name.value != \"\":\n",
    "        exp.set_history(hname=history_name.value)\n",
    "    else:\n",
    "        exp.set_history()\n",
    "    \n",
    "    # and update the select widget\n",
    "    handle_get_histories(clicks)\n",
    "\n",
    "\n",
    "def handle_upload_dataset(clicks):\n",
    "    if file_source_checkbox.value:\n",
    "        pn.state.notifications.warning(\"You selected Galaxy source and not upload.\")\n",
    "    else:\n",
    "        upload_data = exp.gi.tools.upload_file(\n",
    "            file_input.value[0],\n",
    "            select_history.value['id'],\n",
    "            )\n",
    "\n",
    "        # this needs to wait until the upload is done\n",
    "        while exp.gi.datasets.show_dataset(upload_data[\"outputs\"][0][\"id\"])[\"state\"] != \"ok\":\n",
    "            time.sleep(1)\n",
    "\n",
    "        logger.info(f\"Upload data: {upload_data}\")\n",
    "        uploaded_dataset_id = upload_data[\"outputs\"][0][\"id\"]\n",
    "        current_file_name.value = upload_data[\"outputs\"][0][\"name\"]\n",
    "        current_file_id.value = upload_data[\"outputs\"][0][\"id\"]\n",
    "        pn.state.notifications.success(f\"Dataset {uploaded_dataset_id} uploaded.\")\n",
    "\n",
    "\n",
    "def handle_submit_gecco(clicks):\n",
    "    if clicks == 0:\n",
    "        pn.state.notifications.warning(\"You need to log in first.\")\n",
    "        return\n",
    "\n",
    "    if current_file_id.value == \"\":\n",
    "        pn.state.notifications.warning(\"No dataset selected.\")\n",
    "        logger.warning(\"No dataset selected.\")\n",
    "        return\n",
    "    \n",
    "    if current_history_id.value == \"\":\n",
    "        pn.state.notifications.warning(\"No history selected.\")\n",
    "        logger.warning(\"No history selected.\")\n",
    "        return\n",
    "\n",
    "    # create a submission dictionary\n",
    "    submission_inputs = {\n",
    "        \"input\": {\n",
    "            \"id\": current_file_id.value,\n",
    "            \"src\": \"hda\",\n",
    "        },\n",
    "        \"mask\": mask.value,\n",
    "        \"cds\": cds.value,\n",
    "        \"threshold\": threshold.value,\n",
    "        \"postproc\": postproc.value,\n",
    "        \"antimash_sideload\": antimash_sideload.value,\n",
    "    }\n",
    "    \n",
    "    # Run the GECCO tool\n",
    "    tool_run = exp.gi.tools.run_tool(\n",
    "        history_id=current_history_id.value,\n",
    "        tool_id=gecco_tool_id,\n",
    "        tool_inputs=submission_inputs,\n",
    "    )\n",
    "\n",
    "    # Get job ID to monitor\n",
    "    job_id = tool_run[\"jobs\"][0][\"id\"]\n",
    "    logger.info(f\"GECCO tool job submitted with job ID: {job_id}\")\n",
    "    pn.state.notifications.info(f\"GECCO tool job submitted with job ID: {job_id}\")\n",
    "\n",
    "    # save the job_id and submission details to local json file, name is the job_id\n",
    "    with open(f\"{job_id}.json\", \"w\") as f:\n",
    "        json.dump(submission_inputs, f)\n",
    "    logger.info(f\"Submission details saved to {job_id}.json\")\n",
    "\n",
    "\n",
    "@pn.depends(file_source=file_source_checkbox, watch=True)\n",
    "def _generate_data_input_flexbox(file_source):\n",
    "    if file_source:\n",
    "        return pn.Column(but_get_datasets, select_dataset)\n",
    "    else:\n",
    "        return pn.Column(file_input, but_upload_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(\"tabulator\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pn.extension(comms='colab')\n",
    "pn.extension(notifications=True)\n",
    "ACCENT = \"teal\"\n",
    "\n",
    "styles = {\n",
    "    \"box-shadow\": \"rgba(50, 50, 93, 0.25) 0px 6px 12px -2px, rgba(0, 0, 0, 0.3) 0px 3px 7px -3px\",\n",
    "    \"border-radius\": \"4px\",\n",
    "    \"padding\": \"10px\",\n",
    "}\n",
    "\n",
    "image = pn.pane.JPG(os.path.join(assets_folder, \"figs/logo_gecco.jpeg\"),\n",
    "                    width=200,\n",
    "                    )\n",
    "\n",
    "\n",
    "def app():\n",
    "    history_flexbox = pn.Column(\n",
    "        pn.Row(but_get_histories, but_create_history),\n",
    "        history_name,\n",
    "        select_history,\n",
    "        pn.bind(handle_get_histories, clicks=but_get_histories.param.clicks),\n",
    "        pn.bind(handle_create_history, clicks=but_create_history.param.clicks),\n",
    "        sizing_mode=\"stretch_width\",\n",
    "    )\n",
    "\n",
    "    gecco_flexbox = pn.FlexBox(\n",
    "        pn.Column(\n",
    "            mask, pad, cds, threshold, postproc, gene_filter, antimash_sideload,\n",
    "            pn.layout.Divider(),\n",
    "            \"## Submit\", current_file_name, current_history_name, but_submit,\n",
    "        ),\n",
    "        sizing_mode=\"stretch_both\",\n",
    "    )\n",
    "\n",
    "    tabs = pn.Tabs(\n",
    "        (\"Introduction\", intro_text),\n",
    "        ('File Upload', _generate_data_input_flexbox),\n",
    "        ('GECCO Parameters', gecco_flexbox),\n",
    "        styles=styles, sizing_mode=\"stretch_both\",\n",
    "    )\n",
    "\n",
    "    pn.bind(handle_update_current_file_name, select_dataset, watch=True)\n",
    "    pn.bind(handle_update_current_history_name, select_history, watch=True)\n",
    "    pn.bind(handle_update_current_history_id, select_history, watch=True)\n",
    "    pn.bind(handle_submit_gecco, but_submit, watch=True)\n",
    "    template = pn.template.FastListTemplate(\n",
    "        title=\"Run GECCO on Galaxy\",\n",
    "        sidebar=[image,\n",
    "                but_login, pn.bind(handle_login, clicks=but_login.param.clicks),\n",
    "                pn.layout.Divider(margin=(-20, 0, 0, 0)),\n",
    "                \"## Histories\", history_flexbox,\n",
    "                \"## Datasets\", file_source_checkbox,\n",
    "                pn.bind(handle_get_datasets, clicks=but_get_datasets.param.clicks),  # this callback cannot be moved, do I need it with clicks?\n",
    "                pn.bind(handle_upload_dataset, clicks=but_upload_dataset.param.clicks),\n",
    "                ],\n",
    "        main=[tabs,\n",
    "            ],\n",
    "        main_layout=None,\n",
    "        accent=ACCENT,\n",
    "    )\n",
    "    return template\n",
    "\n",
    "template = app()\n",
    "logger.info(\"Template created\")\n",
    "\n",
    "# serve the app\n",
    "s = serve_app(template, env=env, name=\"GECCO_galaxy_runner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment this if running if running ngrok tunnel which you want to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "# server.stop()\n",
    "# ngrok.disconnect(server)\n",
    "# ngrok.kill()\n",
    "\n",
    "# new way\n",
    "# close_server(s, env=env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momicsdem",
   "language": "python",
   "name": "momicsdem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "panel-cell-order": [
   "b28f6eab",
   "541702a3",
   "8f00623f",
   "b9fb7d76",
   "3f721457",
   "858901f0",
   "b58fa68e",
   "9fd7ef01",
   "848d09a6"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
