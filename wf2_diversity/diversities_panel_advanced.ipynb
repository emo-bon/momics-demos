{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize taxonomy and alpha/beta diversities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform dependent part\n",
    "- Resolve platform setup\n",
    "- the difference to local imports should be resolved by setting the Blue Cloud VRE well, Colab will still be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binder\n",
      "Platform: local Linux\n",
      "Added local momics path: /media/davidp/Data/coding/marine_omics/marine-omics\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "from IPython import get_ipython\n",
    "logger = logging.getLogger(name=\"Diversity analysis app\")\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # clone the momics-demos repository to use the utils module from there\n",
    "    # TODO: eventually utils from momics will be used for that\n",
    "    try:\n",
    "        os.system('git clone https://github.com/palec87/momics-demos.git')\n",
    "        logger.info(f\"Repository cloned\")\n",
    "    except OSError as e:\n",
    "        logger.info(f\"An error occurred while cloning the repository: {e}\")\n",
    "\n",
    "    sys.path.insert(0,'/content/momics-demos')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    logger.info(\"Binder\")\n",
    "    print('binder')\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "else:\n",
    "    logger.info(\"Local\")\n",
    "    print('local')\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # local utils, to be removed in the future\n",
    "\n",
    "    # downside of this is that all the deps need to be installed in the current (momics-demos) environment\n",
    "    # sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics')))  # local momics package, to be removed too\n",
    "\n",
    "from utils import init_setup, get_notebook_environment\n",
    "# Determine the notebook environment\n",
    "env = get_notebook_environment()\n",
    "\n",
    "init_setup()\n",
    "logger.info(f\"Environment: {env}\")\n",
    "\n",
    "# if path exists add sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics')))  # local momics package, to be removed too\n",
    "local_momics_path = os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics'))\n",
    "if os.path.exists(local_momics_path):\n",
    "    sys.path.append(local_momics_path)\n",
    "    logger.info(f\"Added local momics path: {local_momics_path}\")\n",
    "    print(f\"Added local momics path: {local_momics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be repeated here for the Pannel dashboard to work, WEIRD\n",
    "# TODO: report as possible bug\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "import psutil\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import panel as pn\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "# All low level functions are imported from the momics package\n",
    "from momics.loader import load_parquets, process_collection_date, extract_season\n",
    "import momics.plotting as pl\n",
    "from momics.panel_utils import (\n",
    "    diversity_select_widgets, create_indicators_diversity,\n",
    "    serve_app, close_server,\n",
    ")\n",
    "from momics.utils import memory_load, reconfig_logger\n",
    "from momics.taxonomy import (\n",
    "    pivot_taxonomic_data,\n",
    "    separate_taxonomy)\n",
    "\n",
    "# Note: This is breaking the panel preview functionality\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | root | Logging.basicConfig completed successfully\n"
     ]
    }
   ],
   "source": [
    "DEBUG = True  # enable stdout logging\n",
    "\n",
    "# Set up logging\n",
    "reconfig_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_for_object_columns(df):\n",
    "    \"\"\"\n",
    "    Fill NA values with 'NA' for object columns in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with NA values filled for object columns.\n",
    "    \"\"\"\n",
    "    # Apply fillna only to object columns\n",
    "    df[df.select_dtypes(include=['object']).columns] = df.select_dtypes(include=['object']).apply(lambda col: col.fillna('NA'))\n",
    "    return df\n",
    "\n",
    "@pn.cache()\n",
    "def get_data(folder):\n",
    "    return load_parquets(folder)\n",
    "\n",
    "# @pn.cache()\n",
    "def get_metadata(folder):\n",
    "    # Load metadata\n",
    "    sample_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Batch1and2_combined_logsheets_2024-11-12.csv\")\n",
    "    )\n",
    "\n",
    "    observatory_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Observatory_combined_logsheets_validated.csv\")\n",
    "    )\n",
    "\n",
    "    # Merge metadata\n",
    "    full_metadata = pd.merge(\n",
    "        sample_metadata,\n",
    "        observatory_metadata,\n",
    "        on=[\"obs_id\", \"env_package\"],  # Matching conditions\n",
    "        how=\"inner\"  # Inner join\n",
    "    )\n",
    "\n",
    "    # Sort the merged dataframe by 'ref_code' column in ascending order\n",
    "    full_metadata = full_metadata.sort_values(by=\"ref_code\", ascending=True)\n",
    "\n",
    "    # first convert some of the boolean cols\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].astype(str)\n",
    "    # replace the 'nan' values with 'NA'\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].replace(\"nan\", \"NA\")\n",
    "\n",
    "\n",
    "    # adding replacement for the missing values for object type columns\n",
    "    full_metadata = fill_na_for_object_columns(full_metadata)\n",
    "    \n",
    "    return full_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    root_folder = os.path.abspath(os.path.join('/content/momics-demos'))\n",
    "else:\n",
    "    root_folder = os.path.abspath(os.path.join('../'))\n",
    "\n",
    "\n",
    "data_folder = os.path.join(root_folder, 'data/parquet_files')\n",
    "assets_folder = os.path.join(root_folder, 'assets')\n",
    "\n",
    "\n",
    "mgf_parquet_dfs = get_data(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance matadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: enhace metadata here\n",
    "# Load and merge metadata\n",
    "full_metadata = get_metadata(os.path.join(root_folder, 'data'))\n",
    "full_metadata = process_collection_date(full_metadata)\n",
    "full_metadata = extract_season(full_metadata)\n",
    "\n",
    "# fiter the metadata only for valid 181 samples\n",
    "df_valid = pd.read_csv(\n",
    "    os.path.join(root_folder, 'data/shipment_b1b2_181.csv')\n",
    ")\n",
    "\n",
    "# Filter the full_metadata on the 'ref_code' only for entries that are in df_valid\n",
    "full_metadata = full_metadata[full_metadata['ref_code'].isin(df_valid['ref_code'])]\n",
    "\n",
    "missing = df_valid[~df_valid['ref_code'].isin(full_metadata['ref_code'])]\n",
    "assert len(missing) == 0, \"Missing samples in the metadata\"\n",
    "assert len(full_metadata) == len(df_valid), \"Filtered metadata does not match the valid samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | Diversity analysis app | Data table names are:\n",
      "dict_keys(['go', 'go_slim', 'ips', 'ko', 'LSU', 'pfam', 'SSU'])\n",
      "INFO | Diversity analysis app | Categorical metadata columns are:\n",
      "['ENA_accession_number_project', 'ENA_accession_number_umbrella', 'ammonium_method', 'arr_date_hq', 'arr_date_seq', 'chlorophyll_method', 'conduc_method', 'contact_email', 'contact_name', 'contact_orcid', 'density_method', 'diss_oxygen_method', 'env_broad_biome', 'env_local', 'env_material', 'env_package', 'extra_site_info', 'failure', 'failure_comment', 'geo_loc_name', 'investigation_type', 'loc_broad_ocean', 'loc_loc', 'loc_regional', 'month_name', 'nitrate_method', 'nitrite_method', 'obs_id', 'organism_count', 'organism_count_method', 'organization', 'organization_country', 'organization_edmoid', 'other_person', 'other_person_orcid', 'ph_method', 'phaeopigments_method', 'phosphate_method', 'pigments', 'pigments_method', 'pressure_method', 'project_name', 'replicate', 'samp_collect_device', 'samp_mat_process', 'samp_mat_process_dev', 'samp_store_date', 'samp_store_loc', 'sampl_person', 'sampl_person_orcid', 'sampling_event', 'scientific_name', 'sea_subsurf_salinity_method', 'sea_subsurf_temp_method', 'sea_surf_salinity_method', 'sea_surf_temp_method', 'season', 'ship_date', 'ship_date_seq', 'silicate_method', 'size_frac', 'store_person', 'store_person_orcid', 'tidal_stage', 'time_fi', 'turbidity_method', 'wa_id']\n",
      "INFO | Diversity analysis app | Numerical metadata columns are:\n",
      "['ENA_accession_number_sample', 'alkalinity', 'alkalinity_method', 'ammonium', 'bac_prod', 'bac_prod_method', 'biomass', 'biomass_method', 'chem_administration', 'chlorophyll', 'conduc', 'day', 'density', 'depth', 'diss_carb_dioxide', 'diss_carb_dioxide_method', 'diss_inorg_carb', 'diss_inorg_carb_method', 'diss_org_carb', 'diss_org_carb_method', 'diss_org_nitro', 'diss_org_nitro_method', 'diss_oxygen', 'down_par', 'down_par_method', 'latitude', 'loc_broad_ocean_mrgid', 'loc_loc_mrgid', 'loc_regional_mrgid', 'long_store', 'longitude', 'membr_cut', 'month', 'n_alkanes', 'n_alkanes_method', 'nitrate', 'nitrite', 'noteworthy_env_cond', 'part_org_carb', 'part_org_carb_method', 'part_org_nitro', 'part_org_nitro_method', 'petroleum_hydrocarb', 'petroleum_hydrocarb_method', 'ph', 'phaeopigments', 'phosphate', 'pressure', 'primary_prod', 'primary_prod_method', 'samp_size_vol', 'samp_store_temp', 'sea_subsurf_salinity', 'sea_subsurf_temp', 'sea_surf_salinity', 'sea_surf_temp', 'silicate', 'size_frac_low', 'size_frac_up', 'store_temp_hq', 'sulfate', 'sulfate_method', 'sulfide', 'sulfide_method', 'tax_id', 'tot_depth_water_col', 'turbidity', 'water_current', 'water_current_method', 'year']\n"
     ]
    }
   ],
   "source": [
    "# select categorical columns from metadata\n",
    "categorical_columns = sorted(full_metadata.select_dtypes(include=['object', \"boolean\"]).columns)\n",
    "cat_to_remove = [\"ref_code\", \"samp_description\", \"source_mat_id\", \"source_mat_id_orig\"]\n",
    "categorical_columns = [k for k in categorical_columns if k not in cat_to_remove]\n",
    "\n",
    "# select numerical columns from metadata\n",
    "numerical_columns = sorted(full_metadata.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "assert (\n",
    "    len(full_metadata.columns) == len(numerical_columns) + len(categorical_columns) + len(cat_to_remove), # + for removed cats\n",
    "\"i have wrong number orf columns in the metadata\",\n",
    ")\n",
    "\n",
    "if DEBUG:\n",
    "    logger.info(f\"Data table names are:\\n{mgf_parquet_dfs.keys()}\")\n",
    "    logger.info(f\"Categorical metadata columns are:\\n{categorical_columns}\")\n",
    "    logger.info(f\"Numerical metadata columns are:\\n{numerical_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot the tables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSU and SSU\n",
    "lsu = mgf_parquet_dfs['LSU']\n",
    "ssu = mgf_parquet_dfs['SSU']\n",
    "\n",
    "lsu_standard = pivot_taxonomic_data(lsu)\n",
    "ssu_standard = pivot_taxonomic_data(ssu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncbi_tax_id</th>\n",
       "      <th>taxonomic_concat</th>\n",
       "      <th>EMOBON00001</th>\n",
       "      <th>EMOBON00003</th>\n",
       "      <th>EMOBON00004</th>\n",
       "      <th>EMOBON00005</th>\n",
       "      <th>EMOBON00006</th>\n",
       "      <th>EMOBON00007</th>\n",
       "      <th>EMOBON00008</th>\n",
       "      <th>EMOBON00009</th>\n",
       "      <th>...</th>\n",
       "      <th>EMOBON00242</th>\n",
       "      <th>EMOBON00243</th>\n",
       "      <th>EMOBON00244</th>\n",
       "      <th>EMOBON00245</th>\n",
       "      <th>EMOBON00246</th>\n",
       "      <th>EMOBON00247</th>\n",
       "      <th>EMOBON00248</th>\n",
       "      <th>EMOBON00249</th>\n",
       "      <th>EMOBON00250</th>\n",
       "      <th>EMOBON00251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2;sk_Bacteria;k_;p_;c_;o_;f_;g_;s_</td>\n",
       "      <td>0.134257</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.165285</td>\n",
       "      <td>0.217925</td>\n",
       "      <td>0.214523</td>\n",
       "      <td>0.263303</td>\n",
       "      <td>0.246803</td>\n",
       "      <td>0.083184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.226026</td>\n",
       "      <td>0.129445</td>\n",
       "      <td>0.232102</td>\n",
       "      <td>0.138737</td>\n",
       "      <td>0.203030</td>\n",
       "      <td>0.158843</td>\n",
       "      <td>0.197760</td>\n",
       "      <td>0.163707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprote...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.013479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16;sk_Bacteria;k_;p_Proteobacteria;c_Betaprote...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>18;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.014814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>20;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>22;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.017013</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>29;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...</td>\n",
       "      <td>0.095783</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>0.079210</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058446</td>\n",
       "      <td>0.026743</td>\n",
       "      <td>0.061341</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.058127</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>0.053793</td>\n",
       "      <td>0.026959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>31;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>39;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ncbi_tax_id                                   taxonomic_concat  \\\n",
       "0            2                 2;sk_Bacteria;k_;p_;c_;o_;f_;g_;s_   \n",
       "1            6  6;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprote...   \n",
       "2           10  10;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...   \n",
       "3           16  16;sk_Bacteria;k_;p_Proteobacteria;c_Betaprote...   \n",
       "4           18  18;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...   \n",
       "5           20  20;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprot...   \n",
       "6           22  22;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...   \n",
       "7           29  29;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...   \n",
       "8           31  31;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...   \n",
       "9           39  39;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...   \n",
       "\n",
       "   EMOBON00001  EMOBON00003  EMOBON00004  EMOBON00005  EMOBON00006  \\\n",
       "0     0.134257     0.131661     0.165285     0.217925     0.214523   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "5     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "6     0.042835     0.008986     0.008143     0.000000     0.000000   \n",
       "7     0.095783     0.008986     0.009973     0.015429     0.010733   \n",
       "8     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "9     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   EMOBON00007  EMOBON00008  EMOBON00009  ...  EMOBON00242  EMOBON00243  \\\n",
       "0     0.263303     0.246803     0.083184  ...     0.131825     0.118200   \n",
       "1     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "2     0.004139     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000  ...     0.009826     0.014814   \n",
       "5     0.007170     0.008663     0.000000  ...     0.000000     0.000000   \n",
       "6     0.000000     0.000000     0.000000  ...     0.017019     0.008553   \n",
       "7     0.089932     0.079210     0.005831  ...     0.091911     0.095238   \n",
       "8     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "9     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "\n",
       "   EMOBON00244  EMOBON00245  EMOBON00246  EMOBON00247  EMOBON00248  \\\n",
       "0     0.226026     0.129445     0.232102     0.138737     0.203030   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.014175     0.007147     0.012030     0.007071     0.011084   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "5     0.000000     0.015982     0.008506     0.010000     0.013576   \n",
       "6     0.012276     0.007147     0.017013     0.012247     0.015676   \n",
       "7     0.058446     0.026743     0.061341     0.018707     0.058127   \n",
       "8     0.000000     0.000000     0.006015     0.000000     0.000000   \n",
       "9     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   EMOBON00249  EMOBON00250  EMOBON00251  \n",
       "0     0.158843     0.197760     0.163707  \n",
       "1     0.000000     0.000000     0.000000  \n",
       "2     0.010841     0.009364     0.013479  \n",
       "3     0.000000     0.000000     0.000000  \n",
       "4     0.000000     0.000000     0.000000  \n",
       "5     0.015332     0.006622     0.016509  \n",
       "6     0.000000     0.009364     0.000000  \n",
       "7     0.023420     0.053793     0.026959  \n",
       "8     0.000000     0.000000     0.000000  \n",
       "9     0.000000     0.000000     0.000000  \n",
       "\n",
       "[10 rows x 183 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssu_standard.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | Diversity analysis app | Number of unique ref_codes: 181\n"
     ]
    }
   ],
   "source": [
    "# this is used fot the tabular view only\n",
    "df = mgf_parquet_dfs['SSU'].copy()\n",
    "if DEBUG:\n",
    "    logger.info(f'Number of unique ref_codes: {df.ref_code.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of the beta diversity part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: link these functions to the indicator\n",
    "# TODO: put them in the momics package\n",
    "def get_missing_taxa(df):\n",
    "    for taxon in [\"superkingdom\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]:\n",
    "        logger.info(f'Not classified on {taxon}: {get_missing_taxa_single(df, taxon)}')\n",
    "    return\n",
    "\n",
    "def get_missing_taxa_single(df, taxon):\n",
    "    return len(df[df[taxon].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permanova calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to aggregate data by a specific taxonomic level\n",
    "def aggregate_by_taxonomic_level(df, level):\n",
    "    # Drop rows where the level is missing\n",
    "    df_level = df.dropna(subset=[level])\n",
    "    # Group by the specified level and sum abundances across samples (columns)\n",
    "    df_grouped = df_level.groupby(level).sum(numeric_only=True)\n",
    "    return df_grouped\n",
    "\n",
    "def separate_taxonomy(df):\n",
    "    eukaryota_keywords = ['Discoba', 'Stramenopiles', 'Rhizaria', 'Alveolata', 'Amorphea', 'Archaeoplastida', 'Excavata']\n",
    "\n",
    "    # Separate rows based on \"Bacteria\", \"Archaea\", and \"Eukaryota\" entries\n",
    "    prokaryotes_all = df[df.index.str.contains(\"Bacteria|Archaea\", regex=True)]\n",
    "    eukaryota_all = df[df.index.str.contains(\"Eukaryota\", regex=True)]\n",
    "\n",
    "    # Further divide \"Prokaryotes all\" into \"Bacteria\" and \"Archaea\"\n",
    "    bacteria = prokaryotes_all[prokaryotes_all.index.str.contains(\"Bacteria\")]\n",
    "    archaea = prokaryotes_all[prokaryotes_all.index.str.contains(\"Archaea\")]\n",
    "\n",
    "    # Further divide \"Eukaryota all\" by specific keywords\n",
    "    eukaryota_dict = {}\n",
    "    for keyword in eukaryota_keywords:\n",
    "        subset = eukaryota_all[eukaryota_all.index.str.contains(keyword)]\n",
    "        eukaryota_dict[keyword] = subset\n",
    "        # Standardize each column to sum to 100 before saving the CSV\n",
    "        subset_normalized = subset.div(subset.sum(axis=0), axis=1) * 100\n",
    "\n",
    "    # Apply taxonomy splitting to the index\n",
    "    taxonomy_levels = bacteria.index.to_series().apply(split_taxonomy)\n",
    "    taxonomy_df = pd.DataFrame(taxonomy_levels.tolist(), columns=['phylum', 'class', 'order', 'family', 'genus', 'species'],\n",
    "                               index=bacteria.index)\n",
    "\n",
    "    # Combine taxonomy with the abundance data\n",
    "    bacteria_data = pd.concat([taxonomy_df, bacteria], axis=1)\n",
    "    \n",
    "\n",
    "    # Aggregate at each taxonomic level and save to CSV\n",
    "    taxonomic_levels = ['phylum', 'class', 'order', 'family', 'genus']\n",
    "    bacteria_levels_dict = {}\n",
    "    for level in taxonomic_levels:\n",
    "        aggregated_df = aggregate_by_taxonomic_level(bacteria_data, level)\n",
    "        # Standardize the values so each column sums to 100\n",
    "        aggregated_df_normalized = aggregated_df.div(aggregated_df.sum(axis=0), axis=1) * 100\n",
    "        bacteria_levels_dict[f\"Bacteria_{level}\"] = aggregated_df_normalized\n",
    "\n",
    "    all_data = {\n",
    "        \"Prokaryotes All\": prokaryotes_all,\n",
    "        \"Eukaryota All\": eukaryota_all,\n",
    "        \"Bacteria\": bacteria,\n",
    "        \"Archaea\": archaea\n",
    "    }\n",
    "    all_data.update(eukaryota_dict)\n",
    "    all_data.update(bacteria_levels_dict)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def split_taxonomy(index_name):\n",
    "    # Remove anything before \"Bacteria\" or \"Archaea\"\n",
    "    if \"Bacteria\" in index_name:\n",
    "        taxonomy = index_name.split(\"Bacteria;\", 1)[1].split(\";\")\n",
    "    elif \"Archaea\" in index_name:\n",
    "        taxonomy = index_name.split(\"Archaea;\", 1)[1].split(\";\")\n",
    "    else:\n",
    "        taxonomy = []\n",
    "    # Return a list with taxonomic levels up to species\n",
    "    return taxonomy[1:7]  # ['phylum', 'class', 'order', 'family', 'genus', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropdowns for the pCOA as Andrzej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncbi_tax_id</th>\n",
       "      <th>taxonomic_concat</th>\n",
       "      <th>EMOBON00001</th>\n",
       "      <th>EMOBON00003</th>\n",
       "      <th>EMOBON00004</th>\n",
       "      <th>EMOBON00005</th>\n",
       "      <th>EMOBON00006</th>\n",
       "      <th>EMOBON00007</th>\n",
       "      <th>EMOBON00008</th>\n",
       "      <th>EMOBON00009</th>\n",
       "      <th>...</th>\n",
       "      <th>EMOBON00242</th>\n",
       "      <th>EMOBON00243</th>\n",
       "      <th>EMOBON00244</th>\n",
       "      <th>EMOBON00245</th>\n",
       "      <th>EMOBON00246</th>\n",
       "      <th>EMOBON00247</th>\n",
       "      <th>EMOBON00248</th>\n",
       "      <th>EMOBON00249</th>\n",
       "      <th>EMOBON00250</th>\n",
       "      <th>EMOBON00251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2;sk_Bacteria;k_;p_;c_;o_;f_;g_;s_</td>\n",
       "      <td>0.366504</td>\n",
       "      <td>0.187182</td>\n",
       "      <td>0.227603</td>\n",
       "      <td>0.225391</td>\n",
       "      <td>0.219082</td>\n",
       "      <td>0.363413</td>\n",
       "      <td>0.340867</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361056</td>\n",
       "      <td>0.352079</td>\n",
       "      <td>0.335658</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>0.341322</td>\n",
       "      <td>0.18905</td>\n",
       "      <td>0.280487</td>\n",
       "      <td>0.209720</td>\n",
       "      <td>0.275366</td>\n",
       "      <td>0.206238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprote...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.009891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16;sk_Bacteria;k_;p_Proteobacteria;c_Betaprote...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>18;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ncbi_tax_id                                   taxonomic_concat  \\\n",
       "0            2                 2;sk_Bacteria;k_;p_;c_;o_;f_;g_;s_   \n",
       "1            6  6;sk_Bacteria;k_;p_Proteobacteria;c_Alphaprote...   \n",
       "2           10  10;sk_Bacteria;k_;p_Proteobacteria;c_Gammaprot...   \n",
       "3           16  16;sk_Bacteria;k_;p_Proteobacteria;c_Betaprote...   \n",
       "4           18  18;sk_Bacteria;k_;p_Proteobacteria;c_Deltaprot...   \n",
       "\n",
       "   EMOBON00001  EMOBON00003  EMOBON00004  EMOBON00005  EMOBON00006  \\\n",
       "0     0.366504     0.187182     0.227603     0.225391     0.219082   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.007395     0.000000     0.000000     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.010459     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   EMOBON00007  EMOBON00008  EMOBON00009  ...  EMOBON00242  EMOBON00243  \\\n",
       "0     0.363413     0.340867     0.053850  ...     0.361056     0.352079   \n",
       "1     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "2     0.003010     0.003971     0.004284  ...     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000  ...     0.011643     0.000000   \n",
       "\n",
       "   EMOBON00244  EMOBON00245  EMOBON00246  EMOBON00247  EMOBON00248  \\\n",
       "0     0.335658     0.191443     0.341322      0.18905     0.280487   \n",
       "1     0.000000     0.000000     0.000000      0.00000     0.000000   \n",
       "2     0.013024     0.007325     0.007712      0.00000     0.011679   \n",
       "3     0.000000     0.000000     0.000000      0.01016     0.000000   \n",
       "4     0.005317     0.000000     0.000000      0.00000     0.000000   \n",
       "\n",
       "   EMOBON00249  EMOBON00250  EMOBON00251  \n",
       "0     0.209720     0.275366     0.206238  \n",
       "1     0.004571     0.000000     0.004946  \n",
       "2     0.000000     0.010854     0.009891  \n",
       "3     0.004571     0.000000     0.000000  \n",
       "4     0.000000     0.000000     0.000000  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsu_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsu_standard.set_index('taxonomic_concat', inplace=True)\n",
    "ssu_standard.set_index('taxonomic_concat', inplace=True)\n",
    "\n",
    "split_taxo_tables_lsu = separate_taxonomy(lsu_standard)\n",
    "split_taxo_tables_ssu = separate_taxonomy(ssu_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.1/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.6.1/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.6.1/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/css/tabulator_simple.min.css?v=1.6.1\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='5be2ba19-aa70-4311-ac3c-5e34f6a8a123'>\n",
       "  <div id=\"a844ba5e-fdfe-4e65-8b4e-91c5d4ee06dc\" data-root-id=\"5be2ba19-aa70-4311-ac3c-5e34f6a8a123\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"c2711260-76cd-4820-96f9-23db3a532562\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"5be2ba19-aa70-4311-ac3c-5e34f6a8a123\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"75af476f-4a4f-4bff-aa86-50d6c83bf10d\",\"attributes\":{\"plot_id\":\"5be2ba19-aa70-4311-ac3c-5e34f6a8a123\",\"comm_id\":\"8454830ab60f475baf9126582e1a8347\",\"client_comm_id\":\"f2d88d16810d469cb30ac3b86a0aaf40\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"c2711260-76cd-4820-96f9-23db3a532562\",\"roots\":{\"5be2ba19-aa70-4311-ac3c-5e34f6a8a123\":\"a844ba5e-fdfe-4e65-8b4e-91c5d4ee06dc\"},\"root_ids\":[\"5be2ba19-aa70-4311-ac3c-5e34f6a8a123\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "5be2ba19-aa70-4311-ac3c-5e34f6a8a123"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.extension(\"tabulator\")\n",
    "\n",
    "granular_tables = {\n",
    "    \"LSU\": split_taxo_tables_lsu,\n",
    "    \"SSU\": split_taxo_tables_ssu\n",
    "}\n",
    "\n",
    "select_granular_table = pn.widgets.Select(\n",
    "    name=\"Granular analysis\",\n",
    "    # value=\"LSU\",\n",
    "    options= list(granular_tables.keys()),\n",
    "    description=\"Select a table for granular analysis\",\n",
    ")\n",
    "\n",
    "select_granular_level = pn.widgets.Select(\n",
    "    name=\"Subset taxonomic level\",\n",
    "    # value=options[0],\n",
    "    options=list(granular_tables[select_granular_table.value].keys()),\n",
    "    description=\"Select a table for analysis\",\n",
    ")\n",
    "\n",
    "logger.info(f\"Granular levels are:\\n{list(granular_tables[select_granular_table.value].keys())}\")\n",
    "\n",
    "\n",
    "factors_to_remove = ['ENA_accession_number_project', \"ENA_accession_number_umbrella\", \"arr_date_hq\",\n",
    "                     \"arr_date_seq\", \"contact_email\", \"contact_name\", \"contact_orcid\",\n",
    "                     \"investigation_type\", \"long_store\", \"organism_count_method\", \"organization_edmoid\",\n",
    "                     'other_person', 'other_person_orcid',\"organization_country\", \"project_name\",\n",
    "                     \"samp_store_date\", 'samp_mat_process', 'samp_mat_process_dev',\n",
    "                     'samp_store_loc', 'sampl_person', 'sampl_person_orcid', 'store_person',\n",
    "                     'store_person_orcid', 'time_fi', \"wa_id\",\n",
    "                     'env_broad_biome', 'env_local', \"extra_site_info\", 'failure_comment',\n",
    "                     'obs_id', 'size_frac','ship_date', 'ship_date_seq', 'sampling_event', 'organism_count',\n",
    "                     'samp_collect_device',\n",
    "                     'ammonium_method', 'chlorophyll_method', 'conduc_method', 'density_method', 'diss_oxygen_method',\n",
    "                     'nitrate_method', 'nitrite_method', 'ph_method', 'phaeopigments_method', 'phosphate_method', 'pigments_method', 'pressure_method',\n",
    "                     'sea_subsurf_salinity_method', 'sea_subsurf_temp_method', 'sea_surf_salinity_method', 'sea_surf_temp_method',\n",
    "                     'silicate_method', 'turbidity_method']\n",
    "factor_cols = [col for col in categorical_columns if col not in factors_to_remove]\n",
    "pcoa_factor_dropdowns = {\n",
    "    categorical_col: pn.widgets.MultiSelect(\n",
    "        name=categorical_col,\n",
    "        value=['All'],\n",
    "        options=['All'] + list(full_metadata[categorical_col].unique()),\n",
    "        size=8)\n",
    "        for categorical_col in factor_cols\n",
    "}\n",
    "box_granular = pn.GridBox(*pcoa_factor_dropdowns.values(), ncols=4)\n",
    "\n",
    "color_factor_granular = pn.widgets.Select(\n",
    "    name=\"Color by\",\n",
    "    value=factor_cols[0],\n",
    "    options=factor_cols,\n",
    "    # description=\"Select a table for analysis\",\n",
    ")\n",
    "\n",
    "# Filter the metadata table based on the selections in box_granular\n",
    "def filter_metadata_table(metadata_df, selected_factors):\n",
    "    # Create a copy of the metadata DataFrame\n",
    "    filtered_metadata = metadata_df.copy()\n",
    "    # Apply filters for each selected factor\n",
    "    for factor, selected_values in selected_factors.items():\n",
    "        if 'All' not in selected_values:\n",
    "            filtered_metadata = filtered_metadata[filtered_metadata[factor].isin(selected_values)]\n",
    "    return filtered_metadata\n",
    "\n",
    "def get_filtered_metadata():\n",
    "    # Retrieve the selected factors from the dropdowns\n",
    "    selected_factors = {col: pcoa_factor_dropdowns[col].value for col in factor_cols}\n",
    "    # Filter the metadata table\n",
    "    filtered_metadata = filter_metadata_table(full_metadata, selected_factors)\n",
    "    return filtered_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter data according to the metadata\n",
    "def filter_data(df, filtered_metadata):\n",
    "    # Filter the DataFrame column names based on the 'ref_code' values in the filtered metadata\n",
    "\n",
    "    # filter columns names of df which are in the filtered metadata\n",
    "    cols_to_keep = list([col for col in df.columns.str.strip() if col in filtered_metadata['ref_code'].to_list()])\n",
    "\n",
    "    filtered_df = df[cols_to_keep]\n",
    "    return filtered_df\n",
    "\n",
    "def filter_all_box_selection(df):\n",
    "    # Retrieve the filtered metadata\n",
    "    filtered_metadata = get_filtered_metadata()\n",
    "    # Filter the data\n",
    "    filtered_data = filter_data(df, filtered_metadata)\n",
    "    return filtered_metadata, filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new PCoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata, filtered_data = filter_all_box_selection(granular_tables['LSU']['Bacteria_phylum'])\n",
    "# logger.info(f'SHAPES {filtered_metadata.shape}, {filtered_data.shape}')\n",
    "# filtered_data.iloc[:, 1:].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skbio.diversity import beta_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta = beta_diversity(\"braycurtis\", filtered_data.iloc[:, 1:].T)\n",
    "# pcoa_result = pcoa(beta, method=\"eigh\")\n",
    "# pcoa_result.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcoa_df = pd.merge(\n",
    "#         pcoa_result.samples,\n",
    "#         filtered_metadata,\n",
    "#         left_index=True,\n",
    "#         right_on=\"ref_code\",\n",
    "#         how=\"inner\",\n",
    "#     )\n",
    "\n",
    "# plot = pl.plot_pcoa_black(\n",
    "#         pcoa_df,\n",
    "#         color_by='env_material',\n",
    "#         # factor='env_package',\n",
    "#         )\n",
    "\n",
    "# beta_pc_plot = pn.pane.Matplotlib(\n",
    "#     sizing_mode=\"stretch_both\",\n",
    "#     name=\"Beta PCoA\",\n",
    "#     )\n",
    "# beta_pc_plot.object = plot\n",
    "# beta_pc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional page to the app\n",
    "\n",
    "# show indicator of the explained variance\n",
    "explained_var_indicator2 = pn.indicators.Number(\n",
    "    name='Explained variance by PC1 + PC2', value=0, format='{value:.1f}%',\n",
    "    font_size='20pt',\n",
    "    title_size='12pt',\n",
    "    colors=[(33, 'red'), (50, 'gold'), (66, 'green')]\n",
    ")\n",
    "\n",
    "beta_pc_plot_granular = pn.pane.Matplotlib(\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    name=\"Beta PCoA\",\n",
    "    )\n",
    "\n",
    "def update_beta_pc_plot_granular(filtered_data, metadata, factor):\n",
    "    beta_pc_plot_granular.object, explained_var_indicator2.value = pl.beta_plot_pc_granular(\n",
    "        filtered_data=filtered_data,\n",
    "        metadata=metadata,\n",
    "        factor=factor)\n",
    "\n",
    "pn.bind(update_beta_pc_plot_granular,\n",
    "    filtered_data=filtered_data,\n",
    "    metadata=filtered_metadata,\n",
    "    factor=color_factor_granular,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def update_filtered_data(table, subtable):\n",
    "    logger.info(f\"Selections of BIg table and subtable: {table}, {subtable}\")\n",
    "    logger.info(f\"Shape of the table {granular_tables[table][subtable].shape}\")\n",
    "    \n",
    "    # logger.info(f\"Selections of BIg table and subtable: {table.value}, {subtable.value}\")\n",
    "    filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[table][subtable])\n",
    "    logger.info(f\"matadata shape {filtered_metadata.shape}\")\n",
    "    logger.info(f\"data shape {filtered_data.shape}\")\n",
    "\n",
    "pn.bind(update_filtered_data,\n",
    "    table=select_granular_table,\n",
    "    subtable=select_granular_level,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# watch any of the box_granular multiselects\n",
    "for factor in factor_cols:\n",
    "    pn.bind(update_filtered_data,\n",
    "        table=select_granular_table,\n",
    "        subtable=select_granular_level,\n",
    "        watch=True,\n",
    "        )\n",
    "\n",
    "button_filter_table = pn.widgets.Button(\n",
    "    name=\"Filter table\",\n",
    "    button_type=\"primary\",\n",
    "    sizing_mode=\"stretch_width\",\n",
    "    width=200,\n",
    ")\n",
    "def update_filtered_data(button):\n",
    "    logger.info(f\"Button clicked: {button.name}\")\n",
    "    # Retrieve the filtered metadata\n",
    "    filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[select_granular_table.value][select_granular_level.value])\n",
    "    logger.info(f\"matadata shape {filtered_metadata.shape}\")\n",
    "    logger.info(f\"data shape {filtered_data.shape}\")\n",
    "    # Update the beta plot\n",
    "    update_beta_pc_plot_granular(filtered_data, filtered_metadata, color_factor_granular.value)\n",
    "\n",
    "button_filter_table.on_click(update_filtered_data)\n",
    "\n",
    "pcoa_tab_granular = pn.Column(\n",
    "    box_granular,\n",
    "    button_filter_table,\n",
    "    explained_var_indicator2,\n",
    "    beta_pc_plot_granular,\n",
    "    sizing_mode=\"stretch_both\",\n",
    ")\n",
    "\n",
    "pcoa_tab_granular_plot = pn.Column(\n",
    "    explained_var_indicator2,\n",
    "    beta_pc_plot_granular,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"filtered data shape {filtered_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pn.extension(\"tabulator\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pn.extension(comms='colab')\n",
    "ACCENT = \"teal\"\n",
    "\n",
    "styles = {\n",
    "    \"box-shadow\": \"rgba(50, 50, 93, 0.25) 0px 6px 12px -2px, rgba(0, 0, 0, 0.3) 0px 3px 7px -3px\",\n",
    "    \"border-radius\": \"4px\",\n",
    "    \"padding\": \"10px\",\n",
    "}\n",
    "\n",
    "# TODO: there is a bug in the panel library that does not allow to open png files, renoming does not help \n",
    "image = pn.pane.JPG(os.path.join(assets_folder, \"figs/metaGOflow_logo_italics.jpg\"),\n",
    "                    width=200,\n",
    "                    height=100,\n",
    "                    )\n",
    "\n",
    "(select_table, select_cat_factor, \n",
    " select_table_beta, select_taxon,\n",
    " select_beta_factor, beta_norm,\n",
    " ) = diversity_select_widgets(categorical_columns, numerical_columns)\n",
    "\n",
    "progress_bar, indicator_usage = create_indicators_diversity()\n",
    "\n",
    "def update_used_gb(event):\n",
    "    if not event:\n",
    "        return\n",
    "\n",
    "    used_gb, total_gb = memory_load()\n",
    "    progress_bar.value = int(used_gb / total_gb * 100)\n",
    "    indicator_usage.value = used_gb\n",
    "\n",
    "bplot_alpha = pn.bind(\n",
    "    pl.alpha_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table,\n",
    "    factor=select_cat_factor,\n",
    "    metadata=full_metadata,\n",
    ")\n",
    "\n",
    "bplot_av_alpha = pn.bind(\n",
    "    pl.av_alpha_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table,\n",
    "    factor=select_cat_factor,\n",
    "    metadata=full_metadata,\n",
    ")\n",
    "\n",
    "bplot_beta_heatmap = pn.bind(\n",
    "    pl.beta_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table_beta,\n",
    "    norm=beta_norm,\n",
    "    taxon=select_taxon,\n",
    ")\n",
    "\n",
    "def update_beta_pc_plot(tables_dict, metadata, table_name, taxon, factor):\n",
    "    beta_pc_plot.object, explained_var_indicator.value = pl.beta_plot_pc(\n",
    "        tables_dict=tables_dict,\n",
    "        metadata=metadata,\n",
    "        table_name=table_name,\n",
    "        taxon=taxon,\n",
    "        factor=factor)\n",
    "\n",
    "beta_pc_plot = pn.pane.Matplotlib(\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    name=\"Beta PCoA\",\n",
    "    )\n",
    "\n",
    "pn.bind(update_beta_pc_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    metadata=full_metadata,\n",
    "    table_name=select_table_beta,\n",
    "    taxon=select_taxon,\n",
    "    factor=select_beta_factor,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "# show indicator of the explained variance\n",
    "explained_var_indicator = pn.indicators.Number(\n",
    "    name='Explained variance by PC1 + PC2', value=0, format='{value:.1f}%',\n",
    "    font_size='20pt',\n",
    "    title_size='12pt',\n",
    "    colors=[(33, 'red'), (50, 'gold'), (66, 'green')]\n",
    ")\n",
    "\n",
    "atable = pn.widgets.Tabulator(df, sizing_mode=\"stretch_both\", name=\"Data View\")\n",
    "\n",
    "# assemble tab with the matrix and checkbox\n",
    "heatmap_tab = pn.Column(\n",
    "    beta_norm,\n",
    "    bplot_beta_heatmap,\n",
    ")\n",
    "\n",
    "pcoa_tab = pn.Column(\n",
    "    explained_var_indicator,\n",
    "    beta_pc_plot,\n",
    ")\n",
    "\n",
    "tabs = pn.Tabs(\n",
    "    ('Alpha div.', bplot_alpha),\n",
    "    ('Av Aplpha div.', bplot_av_alpha),\n",
    "    ('Beta div.', heatmap_tab),\n",
    "    ('PCoA', pcoa_tab),\n",
    "    ('PCoA granular', pcoa_tab_granular),\n",
    "    ('PCoA granular plot', pcoa_tab_granular_plot),\n",
    "    atable,\n",
    "    styles=styles, sizing_mode=\"stretch_both\", margin=10,\n",
    ")\n",
    "\n",
    "# logger.info(f\"just before the app definition {granular_tables[select_granular_table][select_granular_level].shape}\")\n",
    "filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[select_granular_table.value][select_granular_level.value],\n",
    "        )\n",
    "\n",
    "def app():\n",
    "    cb = pn.state.add_periodic_callback(\n",
    "        partial(update_used_gb, indicator_usage),\n",
    "        period=1000,\n",
    "        timeout=None,\n",
    "        )\n",
    "    cb2 = pn.state.add_periodic_callback(\n",
    "        partial(update_used_gb, progress_bar),\n",
    "        period=1000,\n",
    "        timeout=None,\n",
    "        )\n",
    "    toggle = pn.widgets.Toggle(name='Toggle callback', value=True)\n",
    "    toggle.link(cb, bidirectional=True, value='running')\n",
    "    toggle.link(cb2, bidirectional=True, value='running')\n",
    "\n",
    "    indicators = pn.FlexBox(\n",
    "        progress_bar, indicator_usage, toggle)\n",
    "\n",
    "    template = pn.template.FastListTemplate(\n",
    "        title=\"Diversity Analysis\",\n",
    "        sidebar=[image,\n",
    "                \"# Alpha diversity\", select_table, select_cat_factor,\n",
    "                pn.layout.Divider(),\n",
    "                \"# Beta diversity\", select_table_beta, select_taxon, select_beta_factor,\n",
    "                pn.layout.Divider(),\n",
    "                \"# Beta granular\", select_granular_table, select_granular_level,\n",
    "                color_factor_granular, #symbol_factor_granular,\n",
    "                ],\n",
    "        main=[pn.Column(indicators,\n",
    "                        tabs,\n",
    "                        sizing_mode=\"stretch_both\",\n",
    "                    )],\n",
    "        main_layout=None,\n",
    "        accent=ACCENT,\n",
    "    )\n",
    "    return template\n",
    "\n",
    "template = app()\n",
    "\n",
    "# stupid trick to trigger updata()\n",
    "select_beta_factor.value = select_beta_factor.options[1]\n",
    "select_beta_factor.value = select_beta_factor.options[0]\n",
    "color_factor_granular.value = color_factor_granular.options[1]\n",
    "color_factor_granular.value = color_factor_granular.options[0]\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):  \n",
    "    s = serve_app(template, env=env, name=\"diversity_analysis\")\n",
    "else:\n",
    "    template.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment this if running if running ngrok tunnel which you want to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use for the ngrok tunnel in GColab\n",
    "# close_server(s, env=env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momicsdem",
   "language": "python",
   "name": "momicsdem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "panel-cell-order": [
   "34c21507",
   "5911b6c2",
   "800d5521",
   "b8e2ef8c",
   "3994457e",
   "39906e39",
   "6de5ad4b",
   "bc1d1b61",
   "7485ce5b",
   "8f444fef"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
