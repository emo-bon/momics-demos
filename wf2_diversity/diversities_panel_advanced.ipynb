{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize taxonomy and alpha/beta diversities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform dependent part\n",
    "- Resolve platform setup\n",
    "- the difference to local imports should be resolved by setting the Blue Cloud VRE well, Colab will still be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "from IPython import get_ipython\n",
    "logger = logging.getLogger(name=\"Diversity analysis app\")\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # clone the momics-demos repository to use the utils module from there\n",
    "    # TODO: eventually utils from momics will be used for that\n",
    "    try:\n",
    "        os.system('git clone https://github.com/palec87/momics-demos.git')\n",
    "        logger.info(f\"Repository cloned\")\n",
    "    except OSError as e:\n",
    "        logger.info(f\"An error occurred while cloning the repository: {e}\")\n",
    "\n",
    "    sys.path.insert(0,'/content/momics-demos')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    logger.info(\"Binder\")\n",
    "    print('binder')\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "else:\n",
    "    logger.info(\"Local\")\n",
    "    print('local')\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # local utils, to be removed in the future\n",
    "\n",
    "    # downside of this is that all the deps need to be installed in the current (momics-demos) environment\n",
    "    # sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics')))  # local momics package, to be removed too\n",
    "\n",
    "from utils import init_setup, get_notebook_environment\n",
    "# Determine the notebook environment\n",
    "env = get_notebook_environment()\n",
    "\n",
    "init_setup()\n",
    "logger.info(f\"Environment: {env}\")\n",
    "\n",
    "# if path exists add sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics')))  # local momics package, to be removed too\n",
    "local_momics_path = os.path.abspath(os.path.join(os.getcwd(), '../../../marine-omics'))\n",
    "if os.path.exists(local_momics_path):\n",
    "    sys.path.append(local_momics_path)\n",
    "    logger.info(f\"Added local momics path: {local_momics_path}\")\n",
    "    print(f\"Added local momics path: {local_momics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be repeated here for the Pannel dashboard to work, WEIRD\n",
    "# TODO: report as possible bug\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "import psutil\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import panel as pn\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "# All low level functions are imported from the momics package\n",
    "from momics.loader import load_parquets, process_collection_date, extract_season\n",
    "import momics.plotting as pl\n",
    "from momics.panel_utils import (\n",
    "    diversity_select_widgets, create_indicators_diversity,\n",
    "    serve_app, close_server,\n",
    ")\n",
    "from momics.utils import memory_load, reconfig_logger\n",
    "from momics.taxonomy import (\n",
    "    pivot_taxonomic_data,\n",
    "    separate_taxonomy)\n",
    "\n",
    "# Note: This is breaking the panel preview functionality\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True  # enable stdout logging\n",
    "\n",
    "# Set up logging\n",
    "reconfig_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_for_object_columns(df):\n",
    "    \"\"\"\n",
    "    Fill NA values with 'NA' for object columns in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with NA values filled for object columns.\n",
    "    \"\"\"\n",
    "    # Apply fillna only to object columns\n",
    "    df[df.select_dtypes(include=['object']).columns] = df.select_dtypes(include=['object']).apply(lambda col: col.fillna('NA'))\n",
    "    return df\n",
    "\n",
    "@pn.cache()\n",
    "def get_data(folder):\n",
    "    return load_parquets(folder)\n",
    "\n",
    "# @pn.cache()\n",
    "def get_metadata(folder):\n",
    "    # Load metadata\n",
    "    sample_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Batch1and2_combined_logsheets_2024-11-12.csv\")\n",
    "    )\n",
    "\n",
    "    observatory_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Observatory_combined_logsheets_validated.csv\")\n",
    "    )\n",
    "\n",
    "    # Merge metadata\n",
    "    full_metadata = pd.merge(\n",
    "        sample_metadata,\n",
    "        observatory_metadata,\n",
    "        on=[\"obs_id\", \"env_package\"],  # Matching conditions\n",
    "        how=\"inner\"  # Inner join\n",
    "    )\n",
    "\n",
    "    # Sort the merged dataframe by 'ref_code' column in ascending order\n",
    "    full_metadata = full_metadata.sort_values(by=\"ref_code\", ascending=True)\n",
    "\n",
    "    # first convert some of the boolean cols\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].astype(str)\n",
    "    # replace the 'nan' values with 'NA'\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].replace(\"nan\", \"NA\")\n",
    "\n",
    "\n",
    "    # adding replacement for the missing values for object type columns\n",
    "    full_metadata = fill_na_for_object_columns(full_metadata)\n",
    "    \n",
    "    return full_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    root_folder = os.path.abspath(os.path.join('/content/momics-demos'))\n",
    "else:\n",
    "    root_folder = os.path.abspath(os.path.join('../'))\n",
    "\n",
    "\n",
    "data_folder = os.path.join(root_folder, 'data/parquet_files')\n",
    "assets_folder = os.path.join(root_folder, 'assets')\n",
    "\n",
    "\n",
    "mgf_parquet_dfs = get_data(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance matadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: enhace metadata here\n",
    "# Load and merge metadata\n",
    "full_metadata = get_metadata(os.path.join(root_folder, 'data'))\n",
    "full_metadata = process_collection_date(full_metadata)\n",
    "full_metadata = extract_season(full_metadata)\n",
    "\n",
    "# fiter the metadata only for valid 181 samples\n",
    "df_valid = pd.read_csv(\n",
    "    os.path.join(root_folder, 'data/shipment_b1b2_181.csv')\n",
    ")\n",
    "\n",
    "# Filter the full_metadata on the 'ref_code' only for entries that are in df_valid\n",
    "full_metadata = full_metadata[full_metadata['ref_code'].isin(df_valid['ref_code'])]\n",
    "\n",
    "missing = df_valid[~df_valid['ref_code'].isin(full_metadata['ref_code'])]\n",
    "assert len(missing) == 0, \"Missing samples in the metadata\"\n",
    "assert len(full_metadata) == len(df_valid), \"Filtered metadata does not match the valid samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical columns from metadata\n",
    "categorical_columns = sorted(full_metadata.select_dtypes(include=['object', \"boolean\"]).columns)\n",
    "cat_to_remove = [\"ref_code\", \"samp_description\", \"source_mat_id\", \"source_mat_id_orig\"]\n",
    "categorical_columns = [k for k in categorical_columns if k not in cat_to_remove]\n",
    "\n",
    "# select numerical columns from metadata\n",
    "numerical_columns = sorted(full_metadata.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "assert (\n",
    "    len(full_metadata.columns) == len(numerical_columns) + len(categorical_columns) + len(cat_to_remove), # + for removed cats\n",
    "\"i have wrong number orf columns in the metadata\",\n",
    ")\n",
    "\n",
    "if DEBUG:\n",
    "    logger.info(f\"Data table names are:\\n{mgf_parquet_dfs.keys()}\")\n",
    "    logger.info(f\"Categorical metadata columns are:\\n{categorical_columns}\")\n",
    "    logger.info(f\"Numerical metadata columns are:\\n{numerical_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot the tables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSU and SSU\n",
    "lsu = mgf_parquet_dfs['LSU']\n",
    "ssu = mgf_parquet_dfs['SSU']\n",
    "\n",
    "lsu_standard = pivot_taxonomic_data(lsu)\n",
    "ssu_standard = pivot_taxonomic_data(ssu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssu_standard.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used fot the tabular view only\n",
    "df = mgf_parquet_dfs['SSU'].copy()\n",
    "if DEBUG:\n",
    "    logger.info(f'Number of unique ref_codes: {df.ref_code.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of the beta diversity part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: link these functions to the indicator\n",
    "# TODO: put them in the momics package\n",
    "def get_missing_taxa(df):\n",
    "    for taxon in [\"superkingdom\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]:\n",
    "        logger.info(f'Not classified on {taxon}: {get_missing_taxa_single(df, taxon)}')\n",
    "    return\n",
    "\n",
    "def get_missing_taxa_single(df, taxon):\n",
    "    return len(df[df[taxon].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permanova calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to aggregate data by a specific taxonomic level\n",
    "def aggregate_by_taxonomic_level(df, level):\n",
    "    # Drop rows where the level is missing\n",
    "    df_level = df.dropna(subset=[level])\n",
    "    # Group by the specified level and sum abundances across samples (columns)\n",
    "    df_grouped = df_level.groupby(level).sum(numeric_only=True)\n",
    "    return df_grouped\n",
    "\n",
    "def separate_taxonomy(df):\n",
    "    eukaryota_keywords = ['Discoba', 'Stramenopiles', 'Rhizaria', 'Alveolata', 'Amorphea', 'Archaeoplastida', 'Excavata']\n",
    "\n",
    "    # Separate rows based on \"Bacteria\", \"Archaea\", and \"Eukaryota\" entries\n",
    "    prokaryotes_all = df[df.index.str.contains(\"Bacteria|Archaea\", regex=True)]\n",
    "    eukaryota_all = df[df.index.str.contains(\"Eukaryota\", regex=True)]\n",
    "\n",
    "    # Further divide \"Prokaryotes all\" into \"Bacteria\" and \"Archaea\"\n",
    "    bacteria = prokaryotes_all[prokaryotes_all.index.str.contains(\"Bacteria\")]\n",
    "    archaea = prokaryotes_all[prokaryotes_all.index.str.contains(\"Archaea\")]\n",
    "\n",
    "    # Further divide \"Eukaryota all\" by specific keywords\n",
    "    eukaryota_dict = {}\n",
    "    for keyword in eukaryota_keywords:\n",
    "        subset = eukaryota_all[eukaryota_all.index.str.contains(keyword)]\n",
    "        eukaryota_dict[keyword] = subset\n",
    "        # Standardize each column to sum to 100 before saving the CSV\n",
    "        subset_normalized = subset.div(subset.sum(axis=0), axis=1) * 100\n",
    "\n",
    "    # Apply taxonomy splitting to the index\n",
    "    taxonomy_levels = bacteria.index.to_series().apply(split_taxonomy)\n",
    "    taxonomy_df = pd.DataFrame(taxonomy_levels.tolist(), columns=['phylum', 'class', 'order', 'family', 'genus', 'species'],\n",
    "                               index=bacteria.index)\n",
    "\n",
    "    # Combine taxonomy with the abundance data\n",
    "    bacteria_data = pd.concat([taxonomy_df, bacteria], axis=1)\n",
    "    \n",
    "\n",
    "    # Aggregate at each taxonomic level and save to CSV\n",
    "    taxonomic_levels = ['phylum', 'class', 'order', 'family', 'genus']\n",
    "    bacteria_levels_dict = {}\n",
    "    for level in taxonomic_levels:\n",
    "        aggregated_df = aggregate_by_taxonomic_level(bacteria_data, level)\n",
    "        # Standardize the values so each column sums to 100\n",
    "        aggregated_df_normalized = aggregated_df.div(aggregated_df.sum(axis=0), axis=1) * 100\n",
    "        bacteria_levels_dict[f\"Bacteria_{level}\"] = aggregated_df_normalized\n",
    "\n",
    "    all_data = {\n",
    "        \"Prokaryotes All\": prokaryotes_all,\n",
    "        \"Eukaryota All\": eukaryota_all,\n",
    "        \"Bacteria\": bacteria,\n",
    "        \"Archaea\": archaea\n",
    "    }\n",
    "    all_data.update(eukaryota_dict)\n",
    "    all_data.update(bacteria_levels_dict)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def split_taxonomy(index_name):\n",
    "    # Remove anything before \"Bacteria\" or \"Archaea\"\n",
    "    if \"Bacteria\" in index_name:\n",
    "        taxonomy = index_name.split(\"Bacteria;\", 1)[1].split(\";\")\n",
    "    elif \"Archaea\" in index_name:\n",
    "        taxonomy = index_name.split(\"Archaea;\", 1)[1].split(\";\")\n",
    "    else:\n",
    "        taxonomy = []\n",
    "    # Return a list with taxonomic levels up to species\n",
    "    return taxonomy[1:7]  # ['phylum', 'class', 'order', 'family', 'genus', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropdowns for the pCOA as Andrzej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsu_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsu_standard.set_index('taxonomic_concat', inplace=True)\n",
    "ssu_standard.set_index('taxonomic_concat', inplace=True)\n",
    "\n",
    "split_taxo_tables_lsu = separate_taxonomy(lsu_standard)\n",
    "split_taxo_tables_ssu = separate_taxonomy(ssu_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(\"tabulator\")\n",
    "\n",
    "granular_tables = {\n",
    "    \"LSU\": split_taxo_tables_lsu,\n",
    "    \"SSU\": split_taxo_tables_ssu\n",
    "}\n",
    "\n",
    "select_granular_table = pn.widgets.Select(\n",
    "    name=\"Granular analysis\",\n",
    "    # value=\"LSU\",\n",
    "    options= list(granular_tables.keys()),\n",
    "    description=\"Select a table for granular analysis\",\n",
    ")\n",
    "\n",
    "select_granular_level = pn.widgets.Select(\n",
    "    name=\"Subset taxonomic level\",\n",
    "    # value=options[0],\n",
    "    options=list(granular_tables[select_granular_table.value].keys()),\n",
    "    description=\"Select a table for analysis\",\n",
    ")\n",
    "\n",
    "logger.info(f\"Granular levels are:\\n{list(granular_tables[select_granular_table.value].keys())}\")\n",
    "\n",
    "\n",
    "factors_to_remove = ['ENA_accession_number_project', \"ENA_accession_number_umbrella\", \"arr_date_hq\",\n",
    "                     \"arr_date_seq\", \"contact_email\", \"contact_name\", \"contact_orcid\",\n",
    "                     \"investigation_type\", \"long_store\", \"organism_count_method\", \"organization_edmoid\",\n",
    "                     'other_person', 'other_person_orcid',\"organization_country\", \"project_name\",\n",
    "                     \"samp_store_date\", 'samp_mat_process', 'samp_mat_process_dev',\n",
    "                     'samp_store_loc', 'sampl_person', 'sampl_person_orcid', 'store_person',\n",
    "                     'store_person_orcid', 'time_fi', \"wa_id\",\n",
    "                     'env_broad_biome', 'env_local', \"extra_site_info\", 'failure_comment',\n",
    "                     'obs_id', 'size_frac','ship_date', 'ship_date_seq', 'sampling_event', 'organism_count',\n",
    "                     'samp_collect_device',\n",
    "                     'ammonium_method', 'chlorophyll_method', 'conduc_method', 'density_method', 'diss_oxygen_method',\n",
    "                     'nitrate_method', 'nitrite_method', 'ph_method', 'phaeopigments_method', 'phosphate_method', 'pigments_method', 'pressure_method',\n",
    "                     'sea_subsurf_salinity_method', 'sea_subsurf_temp_method', 'sea_surf_salinity_method', 'sea_surf_temp_method',\n",
    "                     'silicate_method', 'turbidity_method']\n",
    "factor_cols = [col for col in categorical_columns if col not in factors_to_remove]\n",
    "pcoa_factor_dropdowns = {\n",
    "    categorical_col: pn.widgets.MultiSelect(\n",
    "        name=categorical_col,\n",
    "        value=['All'],\n",
    "        options=['All'] + list(full_metadata[categorical_col].unique()),\n",
    "        size=8)\n",
    "        for categorical_col in factor_cols\n",
    "}\n",
    "box_granular = pn.GridBox(*pcoa_factor_dropdowns.values(), ncols=4)\n",
    "\n",
    "color_factor_granular = pn.widgets.Select(\n",
    "    name=\"Color by\",\n",
    "    value=factor_cols[0],\n",
    "    options=factor_cols,\n",
    "    # description=\"Select a table for analysis\",\n",
    ")\n",
    "\n",
    "# Filter the metadata table based on the selections in box_granular\n",
    "def filter_metadata_table(metadata_df, selected_factors):\n",
    "    # Create a copy of the metadata DataFrame\n",
    "    filtered_metadata = metadata_df.copy()\n",
    "    # Apply filters for each selected factor\n",
    "    for factor, selected_values in selected_factors.items():\n",
    "        if 'All' not in selected_values:\n",
    "            filtered_metadata = filtered_metadata[filtered_metadata[factor].isin(selected_values)]\n",
    "    return filtered_metadata\n",
    "\n",
    "def get_filtered_metadata():\n",
    "    # Retrieve the selected factors from the dropdowns\n",
    "    selected_factors = {col: pcoa_factor_dropdowns[col].value for col in factor_cols}\n",
    "    # Filter the metadata table\n",
    "    filtered_metadata = filter_metadata_table(full_metadata, selected_factors)\n",
    "    return filtered_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter data according to the metadata\n",
    "def filter_data(df, filtered_metadata):\n",
    "    # Filter the DataFrame column names based on the 'ref_code' values in the filtered metadata\n",
    "\n",
    "    # filter columns names of df which are in the filtered metadata\n",
    "    cols_to_keep = list([col for col in df.columns.str.strip() if col in filtered_metadata['ref_code'].to_list()])\n",
    "\n",
    "    filtered_df = df[cols_to_keep]\n",
    "    return filtered_df\n",
    "\n",
    "def filter_all_box_selection(df):\n",
    "    # Retrieve the filtered metadata\n",
    "    filtered_metadata = get_filtered_metadata()\n",
    "    # Filter the data\n",
    "    filtered_data = filter_data(df, filtered_metadata)\n",
    "    return filtered_metadata, filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional page to the app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata, filtered_data = filter_all_box_selection(granular_tables['LSU']['Bacteria_phylum'])\n",
    "\n",
    "# show indicator of the explained variance\n",
    "explained_var_indicator2 = pn.indicators.Number(\n",
    "    name='Explained variance by PC1 + PC2', value=0, format='{value:.1f}%',\n",
    "    font_size='20pt',\n",
    "    title_size='12pt',\n",
    "    colors=[(33, 'red'), (50, 'gold'), (66, 'green')]\n",
    ")\n",
    "\n",
    "beta_pc_plot_granular = pn.pane.Matplotlib(\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    name=\"Beta PCoA\",\n",
    "    )\n",
    "\n",
    "def update_beta_pc_plot_granular(filtered_data, metadata, factor):\n",
    "    beta_pc_plot_granular.object, explained_var_indicator2.value = pl.beta_plot_pc_granular(\n",
    "        filtered_data=filtered_data,\n",
    "        metadata=metadata,\n",
    "        factor=factor)\n",
    "\n",
    "pn.bind(update_beta_pc_plot_granular,\n",
    "    filtered_data=filtered_data,\n",
    "    metadata=filtered_metadata,\n",
    "    factor=color_factor_granular,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def update_filtered_data(table, subtable):\n",
    "    logger.info(f\"Selections of BIg table and subtable: {table}, {subtable}\")\n",
    "    logger.info(f\"Shape of the table {granular_tables[table][subtable].shape}\")\n",
    "    \n",
    "    # logger.info(f\"Selections of BIg table and subtable: {table.value}, {subtable.value}\")\n",
    "    filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[table][subtable])\n",
    "    logger.info(f\"matadata shape {filtered_metadata.shape}\")\n",
    "    logger.info(f\"data shape {filtered_data.shape}\")\n",
    "\n",
    "pn.bind(update_filtered_data,\n",
    "    table=select_granular_table,\n",
    "    subtable=select_granular_level,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# watch any of the box_granular multiselects\n",
    "for factor in factor_cols:\n",
    "    pn.bind(update_filtered_data,\n",
    "        table=select_granular_table,\n",
    "        subtable=select_granular_level,\n",
    "        watch=True,\n",
    "        )\n",
    "\n",
    "button_filter_table = pn.widgets.Button(\n",
    "    name=\"Filter table\",\n",
    "    button_type=\"primary\",\n",
    "    sizing_mode=\"stretch_width\",\n",
    "    width=200,\n",
    ")\n",
    "def update_filtered_data(button):\n",
    "    logger.info(f\"Button clicked: {button.name}\")\n",
    "    # Retrieve the filtered metadata\n",
    "    filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[select_granular_table.value][select_granular_level.value])\n",
    "    logger.info(f\"matadata shape {filtered_metadata.shape}\")\n",
    "    logger.info(f\"data shape {filtered_data.shape}\")\n",
    "    # Update the beta plot\n",
    "    update_beta_pc_plot_granular(filtered_data, filtered_metadata, color_factor_granular.value)\n",
    "\n",
    "button_filter_table.on_click(update_filtered_data)\n",
    "\n",
    "pcoa_tab_granular = pn.Column(\n",
    "    box_granular,\n",
    "    button_filter_table,\n",
    "    explained_var_indicator2,\n",
    "    beta_pc_plot_granular,\n",
    "    sizing_mode=\"stretch_both\",\n",
    ")\n",
    "\n",
    "pcoa_tab_granular_plot = pn.Column(\n",
    "    explained_var_indicator2,\n",
    "    beta_pc_plot_granular,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pn.extension(\"tabulator\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pn.extension(comms='colab')\n",
    "ACCENT = \"teal\"\n",
    "\n",
    "styles = {\n",
    "    \"box-shadow\": \"rgba(50, 50, 93, 0.25) 0px 6px 12px -2px, rgba(0, 0, 0, 0.3) 0px 3px 7px -3px\",\n",
    "    \"border-radius\": \"4px\",\n",
    "    \"padding\": \"10px\",\n",
    "}\n",
    "\n",
    "# TODO: there is a bug in the panel library that does not allow to open png files, renoming does not help \n",
    "image = pn.pane.JPG(os.path.join(assets_folder, \"figs/metaGOflow_logo_italics.jpg\"),\n",
    "                    width=200,\n",
    "                    height=100,\n",
    "                    )\n",
    "\n",
    "(select_table, select_cat_factor, \n",
    " select_table_beta, select_taxon,\n",
    " select_beta_factor, beta_norm,\n",
    " ) = diversity_select_widgets(categorical_columns, numerical_columns)\n",
    "\n",
    "progress_bar, indicator_usage = create_indicators_diversity()\n",
    "\n",
    "def update_used_gb(event):\n",
    "    if not event:\n",
    "        return\n",
    "\n",
    "    used_gb, total_gb = memory_load()\n",
    "    progress_bar.value = int(used_gb / total_gb * 100)\n",
    "    indicator_usage.value = used_gb\n",
    "\n",
    "bplot_alpha = pn.bind(\n",
    "    pl.alpha_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table,\n",
    "    factor=select_cat_factor,\n",
    "    metadata=full_metadata,\n",
    ")\n",
    "\n",
    "bplot_av_alpha = pn.bind(\n",
    "    pl.av_alpha_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table,\n",
    "    factor=select_cat_factor,\n",
    "    metadata=full_metadata,\n",
    ")\n",
    "\n",
    "bplot_beta_heatmap = pn.bind(\n",
    "    pl.beta_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    table_name=select_table_beta,\n",
    "    norm=beta_norm,\n",
    "    taxon=select_taxon,\n",
    ")\n",
    "\n",
    "def update_beta_pc_plot(tables_dict, metadata, table_name, taxon, factor):\n",
    "    beta_pc_plot.object, explained_var_indicator.value = pl.beta_plot_pc(\n",
    "        tables_dict=tables_dict,\n",
    "        metadata=metadata,\n",
    "        table_name=table_name,\n",
    "        taxon=taxon,\n",
    "        factor=factor)\n",
    "\n",
    "beta_pc_plot = pn.pane.Matplotlib(\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    name=\"Beta PCoA\",\n",
    "    )\n",
    "\n",
    "pn.bind(update_beta_pc_plot,\n",
    "    tables_dict=mgf_parquet_dfs,\n",
    "    metadata=full_metadata,\n",
    "    table_name=select_table_beta,\n",
    "    taxon=select_taxon,\n",
    "    factor=select_beta_factor,\n",
    "    watch=True,\n",
    "    )\n",
    "\n",
    "# show indicator of the explained variance\n",
    "explained_var_indicator = pn.indicators.Number(\n",
    "    name='Explained variance by PC1 + PC2', value=0, format='{value:.1f}%',\n",
    "    font_size='20pt',\n",
    "    title_size='12pt',\n",
    "    colors=[(33, 'red'), (50, 'gold'), (66, 'green')]\n",
    ")\n",
    "\n",
    "atable = pn.widgets.Tabulator(df, sizing_mode=\"stretch_both\", name=\"Data View\")\n",
    "\n",
    "# assemble tab with the matrix and checkbox\n",
    "heatmap_tab = pn.Column(\n",
    "    beta_norm,\n",
    "    bplot_beta_heatmap,\n",
    ")\n",
    "\n",
    "pcoa_tab = pn.Column(\n",
    "    explained_var_indicator,\n",
    "    beta_pc_plot,\n",
    ")\n",
    "\n",
    "tabs = pn.Tabs(\n",
    "    ('Alpha div.', bplot_alpha),\n",
    "    ('Av Aplpha div.', bplot_av_alpha),\n",
    "    ('Beta div.', heatmap_tab),\n",
    "    ('PCoA', pcoa_tab),\n",
    "    ('PCoA granular', pcoa_tab_granular),\n",
    "    ('PCoA granular plot', pcoa_tab_granular_plot),\n",
    "    atable,\n",
    "    styles=styles, sizing_mode=\"stretch_both\", margin=10,\n",
    ")\n",
    "\n",
    "# logger.info(f\"just before the app definition {granular_tables[select_granular_table][select_granular_level].shape}\")\n",
    "filtered_metadata, filtered_data = filter_all_box_selection(\n",
    "        granular_tables[select_granular_table.value][select_granular_level.value],\n",
    "        )\n",
    "\n",
    "def app():\n",
    "    cb = pn.state.add_periodic_callback(\n",
    "        partial(update_used_gb, indicator_usage),\n",
    "        period=1000,\n",
    "        timeout=None,\n",
    "        )\n",
    "    cb2 = pn.state.add_periodic_callback(\n",
    "        partial(update_used_gb, progress_bar),\n",
    "        period=1000,\n",
    "        timeout=None,\n",
    "        )\n",
    "    toggle = pn.widgets.Toggle(name='Toggle callback', value=True)\n",
    "    toggle.link(cb, bidirectional=True, value='running')\n",
    "    toggle.link(cb2, bidirectional=True, value='running')\n",
    "\n",
    "    indicators = pn.FlexBox(\n",
    "        progress_bar, indicator_usage, toggle)\n",
    "\n",
    "    template = pn.template.FastListTemplate(\n",
    "        title=\"Diversity Analysis\",\n",
    "        sidebar=[image,\n",
    "                \"# Alpha diversity\", select_table, select_cat_factor,\n",
    "                pn.layout.Divider(),\n",
    "                \"# Beta diversity\", select_table_beta, select_taxon, select_beta_factor,\n",
    "                pn.layout.Divider(),\n",
    "                \"# Beta granular\", select_granular_table, select_granular_level,\n",
    "                color_factor_granular, #symbol_factor_granular,\n",
    "                ],\n",
    "        main=[pn.Column(indicators,\n",
    "                        tabs,\n",
    "                        sizing_mode=\"stretch_both\",\n",
    "                    )],\n",
    "        main_layout=None,\n",
    "        accent=ACCENT,\n",
    "    )\n",
    "    return template\n",
    "\n",
    "template = app()\n",
    "\n",
    "# stupid trick to trigger updata()\n",
    "select_beta_factor.value = select_beta_factor.options[1]\n",
    "select_beta_factor.value = select_beta_factor.options[0]\n",
    "color_factor_granular.value = color_factor_granular.options[1]\n",
    "color_factor_granular.value = color_factor_granular.options[0]\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):  \n",
    "    s = serve_app(template, env=env, name=\"diversity_analysis\")\n",
    "else:\n",
    "    template.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment this if running if running ngrok tunnel which you want to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use for the ngrok tunnel in GColab\n",
    "# close_server(s, env=env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momicsdem",
   "language": "python",
   "name": "momicsdem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "panel-cell-order": [
   "34c21507",
   "5911b6c2",
   "800d5521",
   "b8e2ef8c",
   "3994457e",
   "39906e39",
   "6de5ad4b",
   "bc1d1b61",
   "7485ce5b",
   "8f444fef"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
