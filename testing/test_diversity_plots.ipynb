{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fater testing out of the panel app integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import init_setup\n",
    "init_setup()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import panel as pn\n",
    "\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "# All low level functions are imported from the momics package\n",
    "from momics.loader import load_parquets\n",
    "import momics.plotting as pl\n",
    "# from momics.panel_utils import diversity_select_widgets, create_indicators\n",
    "# from momics.utils import memory_load\n",
    "from momics.diversity import (\n",
    "    shannon_index,\n",
    "    calculate_alpha_diversity,\n",
    "    alpha_diversity_parametrized,\n",
    "    beta_diversity_parametrized,\n",
    ")\n",
    "\n",
    "# Note: This is breaking the panel preview functionality\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    return load_parquets(folder)\n",
    "\n",
    "def fill_na_for_object_columns(df):\n",
    "    \"\"\"\n",
    "    Fill NA values with 'NA' for object columns in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with NA values filled for object columns.\n",
    "    \"\"\"\n",
    "    # Apply fillna only to object columns\n",
    "    df[df.select_dtypes(include=['object']).columns] = df.select_dtypes(include=['object']).apply(lambda col: col.fillna('NA'))\n",
    "    return df\n",
    "\n",
    "def get_metadata(folder):\n",
    "    # Load metadata\n",
    "    sample_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Batch1and2_combined_logsheets_2024-09-11.csv\")\n",
    "    )\n",
    "\n",
    "    observatory_metadata = pd.read_csv(\n",
    "        os.path.join(folder, \"Observatory_combined_logsheets_validated.csv\")\n",
    "    )\n",
    "\n",
    "    # Merge metadata\n",
    "    full_metadata = pd.merge(\n",
    "        sample_metadata,\n",
    "        observatory_metadata,\n",
    "        on=[\"obs_id\", \"env_package\"],  # Matching conditions\n",
    "        how=\"inner\"  # Inner join\n",
    "    )\n",
    "\n",
    "    # Sort the merged dataframe by 'ref_code' column in ascending order\n",
    "    full_metadata = full_metadata.sort_values(by=\"ref_code\", ascending=True)\n",
    "\n",
    "    # first convert some of the boolean cols\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].astype(str)\n",
    "    # replace the 'nan' values with 'NA'\n",
    "    full_metadata[\"failure\"] = full_metadata[\"failure\"].replace(\"nan\", \"NA\")\n",
    "\n",
    "\n",
    "    # adding replacement for the missing values for object type columns\n",
    "    full_metadata = fill_na_for_object_columns(full_metadata)\n",
    "    \n",
    "    return full_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    root_folder = os.path.abspath(os.path.join('/content/momics-demos'))\n",
    "else:\n",
    "    root_folder = os.path.abspath(os.path.join('../'))\n",
    "\n",
    "\n",
    "data_folder = os.path.join(root_folder, 'data/parquet_files')\n",
    "assets_folder = os.path.join(root_folder, 'assets')\n",
    "\n",
    "\n",
    "mgf_parquet_dfs = get_data(data_folder)\n",
    "\n",
    "# metadata\n",
    "# Load and merge metadata\n",
    "full_metadata = get_metadata(data_folder)\n",
    "\n",
    "# select categorical columns from metadata\n",
    "categorical_columns = sorted(full_metadata.select_dtypes(include=['object', \"boolean\"]).columns)\n",
    "cat_to_remove = [\"ref_code\", \"samp_description\", \"source_mat_id\", \"source_mat_id_orig\"]\n",
    "categorical_columns = [k for k in categorical_columns if k not in cat_to_remove]\n",
    "\n",
    "# select numerical columns from metadata\n",
    "numerical_columns = sorted(full_metadata.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "assert len(full_metadata.columns) == len(numerical_columns) + len(categorical_columns) + len(cat_to_remove)  # +1 for 'ref_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mgf_parquet_dfs), len(mgf_parquet_dfs), type(mgf_parquet_dfs['go'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no problem here, just ADD the normalization option\n",
    "beta = beta_diversity_parametrized(mgf_parquet_dfs['SSU'], 'class')\n",
    "# beta.to_data_frame().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_result = pcoa(beta, method=\"eigh\") #, number_of_dimensions=3)\n",
    "pcoa_result.samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I just need to use pcoa_results.proportion_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test if eigen values are ordered\n",
    "plt.bar(range(len(pcoa_result.eigvals)), pcoa_result.eigvals)\n",
    "sum(pcoa_result.eigvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_result.proportion_explained[:2].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_df = pd.merge(\n",
    "        pcoa_result.samples,\n",
    "        full_metadata,\n",
    "        left_index=True,\n",
    "        right_on=\"ref_code\",\n",
    "        how=\"inner\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_df['contact_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in categorical_columns:\n",
    "    fig = pl.plot_pcoa_black(pcoa_df, color_by=factor)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot_pcoa_black(pcoa_df, color_by=\"alkalinity\")\n",
    "pcoa_df['alkalinity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metadata['alkalinity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tables_dict():\n",
    "    \"\"\"Fixture that provides a dictionary of sample tables for testing.\"\"\"\n",
    "    data = {\n",
    "        \"ref_code\": [\"sample1\", \"sample2\", \"sample3\"],\n",
    "        \"GO:0001\": [10, 0, 5],\n",
    "        \"GO:0002\": [20, 0, 5],\n",
    "        \"IPR0001\": [30, 0, 5],\n",
    "        \"K0001\": [40, 0, 5],\n",
    "        \"PF0001\": [50, 0, 5],\n",
    "        }\n",
    "    return {\"sample_table\": pd.DataFrame(data)}\n",
    "\n",
    "\n",
    "def sample_data(sample_tables_dict):\n",
    "    return sample_tables_dict[\"sample_table\"]\n",
    "\n",
    "\n",
    "def sample_factors():\n",
    "    \"\"\"Fixture that provides sample factors for testing.\"\"\"\n",
    "    factors = {\n",
    "        \"ref_code\": [\"sample1\", \"sample2\", \"sample3\"],\n",
    "        \"factor1\": [\"A\", \"B\", \"C\"],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(factors)\n",
    "\n",
    "\n",
    "def test_calculate_alpha_diversity(sample_data, sample_factors):\n",
    "    \"\"\"Tests the calculate_alpha_diversity function.\"\"\"\n",
    "    result = calculate_alpha_diversity(sample_data, sample_factors)\n",
    "\n",
    "    # Check if the result is a DataFrame\n",
    "    assert isinstance(result, pd.DataFrame), \"The result should be a DataFrame\"\n",
    "\n",
    "    # Check if the result contains the expected columns\n",
    "    expected_columns = [\"ref_code\", \"Shannon\", \"factor1\"]\n",
    "    assert all(\n",
    "        col in result.columns for col in expected_columns\n",
    "    ), f\"Expected columns {expected_columns}, but got {result.columns.tolist()}\"\n",
    "\n",
    "    # Check if the Shannon index values are calculated correctly\n",
    "    expected_shannon = sample_data.apply(lambda row: shannon_index(row[1:]), axis=1)\n",
    "    expected_shannon2 = sample_data.apply(lambda row: shannon_index(row[1:]))\n",
    "\n",
    "    display(expected_shannon, result[\"Shannon\"], result, expected_shannon2)\n",
    "\n",
    "    # assert all(\n",
    "    #     result[\"Shannon\"].round(3) == expected_shannon.round(3)\n",
    "    # ), \"The Shannon index values are not calculated correctly\"\n",
    "\n",
    "    assert np.isclose(result[\"Shannon\"], expected_shannon).all(), (\n",
    "        \"The Shannon_index values are not calculated correctly, diff is \" + \n",
    "        f\"{(result['Shannon'] - expected_shannon).tolist()}\"\n",
    "    )\n",
    "\n",
    "    # Check if the factors are merged correctly\n",
    "    assert all(\n",
    "        result[\"factor1\"] == sample_factors[\"factor1\"]\n",
    "    ), \"The factors are not merged correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= sample_tables_dict()\n",
    "sample_data = sample_data(d)\n",
    "sample_factors = sample_factors()\n",
    "\n",
    "test_calculate_alpha_diversity(sample_data, sample_factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momicsdem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
