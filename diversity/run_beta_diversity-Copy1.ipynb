{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05842fe-abe3-4f43-a341-5e44aa879126",
   "metadata": {},
   "source": [
    "<h1> Beta diversity <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f24b32-af5a-4c88-a39e-54cdb10e183b",
   "metadata": {},
   "source": [
    "<h3> Installing and importing required modules <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a1b39e-6844-4ce6-9d3b-e687bbacc843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-bio in /opt/conda/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (2.31.0)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (4.4.2)\n",
      "Requirement already satisfied: natsort>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (1.10.1)\n",
      "Requirement already satisfied: h5py>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (3.8.0)\n",
      "Requirement already satisfied: biom-format>=2.1.16 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (2.1.16)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from scikit-bio) (0.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from biom-format>=2.1.16->scikit-bio) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->scikit-bio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->scikit-bio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->scikit-bio) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->scikit-bio) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->scikit-bio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->scikit-bio) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->scikit-bio) (2023.7.22)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.14.0->scikit-bio) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.14.0->scikit-bio) (23.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.14.0->scikit-bio) (1.16.0)\n",
      "Requirement already satisfied: duckdb in /opt/conda/lib/python3.10/site-packages (1.1.2)\n",
      "Requirement already satisfied: pingouin in /opt/conda/lib/python3.10/site-packages (0.5.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from pingouin) (3.7.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.5 in /opt/conda/lib/python3.10/site-packages (from pingouin) (2.0.2)\n",
      "Requirement already satisfied: pandas-flavor in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.6.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.10.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.11.0)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.14.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5->pingouin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5->pingouin) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5->pingouin) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2->pingouin) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2->pingouin) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pingouin) (3.0.9)\n",
      "Requirement already satisfied: xarray in /opt/conda/lib/python3.10/site-packages (from pandas-flavor->pingouin) (2023.9.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels->pingouin) (0.5.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels->pingouin) (1.16.0)\n",
      "Requirement already satisfied: minio in /opt/conda/lib/python3.10/site-packages (7.2.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from minio) (2023.7.22)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from minio) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from minio) (21.3.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from minio) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from minio) (4.6.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.21)\n",
      "Requirement already satisfied: pandasql in /opt/conda/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pandasql) (1.24.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from pandasql) (2.0.2)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (from pandasql) (2.0.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pandasql) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pandasql) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy->pandasql) (4.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy->pandasql) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.16.0)\n",
      "Requirement already satisfied: timeit_decorator in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from timeit_decorator) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "#Install\n",
    "!pip install scikit-bio\n",
    "!pip install duckdb\n",
    "!pip install pingouin\n",
    "!pip install minio\n",
    "!pip install pandasql\n",
    "!pip install timeit_decorator\n",
    "\n",
    "#Import\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import duckdb\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "from duckdb import BinderException, CatalogException\n",
    "from IPython.display import display\n",
    "from minio import Minio, S3Error\n",
    "from pandasql import sqldf\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import entr  # Ensure you import entropy\n",
    "from scipy.stats import entropy, levene, shapiro\n",
    "from skbio.stats.distance import DistanceMatrix, permanova\n",
    "from sklearn.decomposition import PCA\n",
    "from timeit_decorator import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd1bf9-cc47-4958-afd9-0913aeb65494",
   "metadata": {},
   "source": [
    "<h3> Downloading data from Minio <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d982bc0c-4414-48d2-b120-c9f8983c5402",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────────┐\n",
       "│      name       │\n",
       "│     varchar     │\n",
       "├─────────────────┤\n",
       "│ LSU             │\n",
       "│ OBS_METADATA    │\n",
       "│ SAMPLE_METADATA │\n",
       "│ SSU             │\n",
       "│ SSU_class_all   │\n",
       "│ go              │\n",
       "│ go_slim         │\n",
       "│ ips             │\n",
       "│ ko              │\n",
       "│ pfam            │\n",
       "├─────────────────┤\n",
       "│     10 rows     │\n",
       "└─────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this dictionary, the data tables will be stored as panda DataFrames\n",
    "mgf_parquet_dfs = {}\n",
    "\n",
    "# Loop through the folder and load each .parquet file\n",
    "for file_name in os.listdir(\"parquet_files\"):\n",
    "    if file_name.endswith(\".parquet\"):\n",
    "        file_path = os.path.join(\"parquet_files\", file_name)\n",
    "        df = pd.read_parquet(file_path)\n",
    "        name = file_name.split(\".\")[-2]\n",
    "        mgf_parquet_dfs[name] = df\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "sample_metadata = pd.read_csv(\n",
    "    \"parquet_files/Batch1and2_combined_logsheets_2024-09-11.csv\"\n",
    ")\n",
    "\n",
    "# Observatory metadata - from the GoogleSheets\n",
    "observatory_metadata = pd.read_csv(\n",
    "    \"parquet_files/Observatory_combined_logsheets_validated.csv\"\n",
    ")\n",
    "\n",
    "# Into duckdb\n",
    "try:\n",
    "    duckdb.sql(\"DROP TABLE SAMPLE_METADATA\")\n",
    "    duckdb.sql(\"DROP TABLE OBS_METADATA\")\n",
    "    for table_name in mgf_parquet_dfs:\n",
    "        cmd = f\"DROP TABLE {table_name}\"\n",
    "        duckdb.sql(cmd)\n",
    "except CatalogException:\n",
    "    pass\n",
    "duckdb.sql(\"CREATE TABLE SAMPLE_METADATA AS SELECT * FROM sample_metadata\")\n",
    "duckdb.sql(\"SELECT COUNT(*) FROM SAMPLE_METADATA\")\n",
    "duckdb.sql(\"CREATE TABLE OBS_METADATA AS SELECT * FROM observatory_metadata\")\n",
    "duckdb.sql(\"SELECT COUNT(*) FROM OBS_METADATA\")\n",
    "for table_name in mgf_parquet_dfs:\n",
    "    df = mgf_parquet_dfs[table_name]\n",
    "    cmd = f\"CREATE TABLE {table_name} AS SELECT * FROM df\"\n",
    "    duckdb.sql(cmd)\n",
    "\n",
    "duckdb.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b94d6-fd71-48b3-adbc-31526b4735f1",
   "metadata": {},
   "source": [
    "<h3> Here the user should be able to select a table (change the code below) <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c6238-08d4-43fa-8259-57ece95dfdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"try:\n",
    "    duckdb.sql(\"DROP TABLE SSU\")\n",
    "except CatalogException:\n",
    "    pass\n",
    "duckdb.sql(\"CREATE TABLE SSU AS SELECT * FROM df\")\n",
    "duckdb.sql(\"SELECT COUNT(*) FROM SSU\")\n",
    "\n",
    "# Query to get column names from the 'SSU' table\n",
    "column_headers = duckdb.sql(\n",
    "    \"SELECT column_name FROM information_schema.columns WHERE table_name = 'SSU';\"\n",
    ").fetchdf()\n",
    "\n",
    "# Print the column headers\n",
    "print(column_headers[\"column_name\"].tolist()) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5858145-a158-49c6-ab0c-a21ccf548c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object(bucket_name, file_format, file_name, verbose=True):\n",
    "    if verbose:\n",
    "        print(f\"{bucket_name=} - {file_format=} - {file_name=}\")\n",
    "    try:\n",
    "        response = client.get_object(bucket_name, file_name)\n",
    "        buffer = io.BytesIO(response.read())\n",
    "    except S3Error:\n",
    "        raise\n",
    "    finally:\n",
    "        if file_format == \"parquet\":\n",
    "            df = pd.read_parquet(buffer, engine=\"pyarrow\")\n",
    "        elif file_format == \"csv\":\n",
    "            df = pd.read_csv(buffer)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown {file_format=}\")\n",
    "        response.close()\n",
    "        response.release_conn()\n",
    "        if verbose:\n",
    "            print(f\"Downloaded {file_name} into dataframe\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84004ef0-03f3-4cbf-8d12-9779351eab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The destination bucket and filename on the MinIO server\n",
    "#bucket_name = \"emo-bon-tables\"\n",
    "#for obj in client.list_objects(bucket_name):\n",
    "#    print(obj.object_name)\n",
    "# Currently only v1 tables are available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfc447-74cf-401c-bf9c-3c2fd1181a4e",
   "metadata": {},
   "source": [
    "<h3> Working on full metadata <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47a9888-b238-47a6-b127-371d60b13e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MGF parquet tables to data frames\u001b[39;00m\n\u001b[1;32m      2\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memo-bon-tables\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m objects \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mlist_objects(bucket_name, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m mgf_parquet_dfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# MGF parquet tables to data frames\n",
    "bucket_name = \"emo-bon-tables\"\n",
    "objects = client.list_objects(bucket_name, recursive=True)\n",
    "mgf_parquet_dfs = {}\n",
    "for obj in objects:\n",
    "    name = obj.object_name.split(\".\")[-2]\n",
    "    df = get_object(bucket_name, \"parquet\", obj.object_name, verbose=False)\n",
    "    mgf_parquet_dfs[name] = df\n",
    "\n",
    "# Sample metadata\n",
    "# Get the latest Batch combined logsheets file\n",
    "# Remember we are downloading from MinIO\n",
    "batch_file = \"Batch1and2_combined_logsheets_2024-09-11.csv\"\n",
    "sample_metadata = (\"emo-bon-metadata-tables\", \"csv\", batch_file)\n",
    "sample_metadata = get_object(*sample_metadata, verbose=False)\n",
    "\n",
    "# Observatory metadata - from the GoogleSheets\n",
    "observatory_metadata = (\n",
    "    \"emo-bon-metadata-tables\",\n",
    "    \"csv\",\n",
    "    \"Observatory_combined_logsheets_validated.csv\",\n",
    ")\n",
    "observatory_metadata = get_object(*observatory_metadata, verbose=False)\n",
    "\n",
    "# Into duckdb\n",
    "try:\n",
    "    duckdb.sql(\"DROP TABLE SAMPLE_METADATA\")\n",
    "    duckdb.sql(\"DROP TABLE OBS_METADATA\")\n",
    "    for table_name in mgf_parquet_dfs:\n",
    "        cmd = f\"DROP TABLE {table_name}\"\n",
    "        duckdb.sql(cmd)\n",
    "except CatalogException:\n",
    "    pass\n",
    "duckdb.sql(\"CREATE TABLE SAMPLE_METADATA AS SELECT * FROM sample_metadata\")\n",
    "duckdb.sql(\"SELECT COUNT(*) FROM SAMPLE_METADATA\")\n",
    "duckdb.sql(\"CREATE TABLE OBS_METADATA AS SELECT * FROM observatory_metadata\")\n",
    "duckdb.sql(\"SELECT COUNT(*) FROM OBS_METADATA\")\n",
    "for table_name in mgf_parquet_dfs:\n",
    "    df = mgf_parquet_dfs[table_name]\n",
    "    cmd = f\"CREATE TABLE {table_name} AS SELECT * FROM df\"\n",
    "    duckdb.sql(cmd)\n",
    "\n",
    "duckdb.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd038d-3cb6-49c0-a531-71b00a009163",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61bd15-362b-46ab-ba6d-4930a3262832",
   "metadata": {},
   "source": [
    "<h3> Define the query <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a09215d3-aa9a-47f1-8234-82b84caf0cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name \"SSU_class_all\" already exists!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mPIVOT (\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mORDER BY class\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save the result of the query into a DuckDB table called \"SSU_class_all\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mduckdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43mCREATE TABLE SSU_class_all AS\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquery\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Optionally, show the saved table to verify it\u001b[39;00m\n\u001b[1;32m     26\u001b[0m duckdb\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM SSU_class_all\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(max_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, max_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m55\u001b[39m)\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name \"SSU_class_all\" already exists!"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "PIVOT (\n",
    "SELECT\n",
    "ref_code,\n",
    "class,\n",
    "sum(abundance) as total\n",
    "FROM SSU \n",
    "WHERE class <> '' AND class IS NOT NULL\n",
    "GROUP BY class, ref_code\n",
    "ORDER BY class, sum(abundance) DESC\n",
    ")\n",
    "ON ref_code\n",
    "USING sum(total)\n",
    "ORDER BY class\n",
    "\"\"\"\n",
    "\n",
    "# Save the result of the query into a DuckDB table called \"SSU_class_all\"\n",
    "duckdb.sql(\n",
    "    f\"\"\"\n",
    "CREATE TABLE SSU_class_all AS\n",
    "{query}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Optionally, show the saved table to verify it\n",
    "duckdb.sql(\"SELECT * FROM SSU_class_all\").show(max_width=30, max_rows=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b262811e-ab91-43f0-8279-09f3016010ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class_Acantharea  class_Acidimicrobiia  class_Acidithiobacillia  \\\n",
      "0                1.0                 248.0                      1.0   \n",
      "1                0.0                 300.0                      1.0   \n",
      "2                0.0                 646.0                      0.0   \n",
      "3                0.0                 287.0                      2.0   \n",
      "4                0.0                 260.0                      4.0   \n",
      "5                0.0                 298.0                      4.0   \n",
      "6                0.0                 436.0                      0.0   \n",
      "7                0.0                 434.0                      1.0   \n",
      "8                0.0                 217.0                      4.0   \n",
      "9                0.0                 247.0                      0.0   \n",
      "10               0.0                 260.0                      3.0   \n",
      "11               2.0                 134.0                      0.0   \n",
      "12               6.0                 162.0                      0.0   \n",
      "13              21.0                  11.0                      0.0   \n",
      "14              22.0                   6.0                      0.0   \n",
      "15               5.0                 564.0                      1.0   \n",
      "16               1.0                 550.0                      0.0   \n",
      "17              29.0                  17.0                      0.0   \n",
      "18               4.0                 237.0                      0.0   \n",
      "19               9.0                 304.0                      0.0   \n",
      "20               8.0                 456.0                      1.0   \n",
      "21              11.0                 295.0                      2.0   \n",
      "22              33.0                 668.0                      2.0   \n",
      "23              16.0                 787.0                      0.0   \n",
      "24               0.0                1260.0                      1.0   \n",
      "25               0.0                 471.0                      1.0   \n",
      "26               0.0                1164.0                      2.0   \n",
      "27               0.0                 980.0                      3.0   \n",
      "28              57.0                 194.0                      0.0   \n",
      "29              38.0                 215.0                      6.0   \n",
      "30               4.0                  85.0                      0.0   \n",
      "31               9.0                 138.0                      0.0   \n",
      "32              10.0                 218.0                      0.0   \n",
      "33               6.0                 134.0                      0.0   \n",
      "34               1.0                 133.0                      0.0   \n",
      "35               4.0                 173.0                      0.0   \n",
      "36               0.0                  90.0                      2.0   \n",
      "37               0.0                 170.0                      3.0   \n",
      "38               0.0                 575.0                      0.0   \n",
      "39               0.0                 852.0                      5.0   \n",
      "40               0.0                 170.0                      3.0   \n",
      "41               0.0                 230.0                      1.0   \n",
      "42               0.0                 340.0                      2.0   \n",
      "43               0.0                 428.0                      4.0   \n",
      "44               0.0                 445.0                      1.0   \n",
      "45               0.0                 269.0                      2.0   \n",
      "46               1.0                 384.0                      2.0   \n",
      "47               0.0                 301.0                      5.0   \n",
      "48               0.0                 479.0                      2.0   \n",
      "49               3.0                 359.0                      3.0   \n",
      "\n",
      "    class_Acidobacteriia  class_Aconoidasida  class_Actinobacteria  \\\n",
      "0                   11.0                 0.0                  14.0   \n",
      "1                   23.0                 0.0                   2.0   \n",
      "2                    5.0                 0.0                  24.0   \n",
      "3                   10.0                 0.0                   4.0   \n",
      "4                   11.0                 0.0                   1.0   \n",
      "5                    5.0                 0.0                  19.0   \n",
      "6                    3.0                 0.0                  44.0   \n",
      "7                   24.0                 0.0                 191.0   \n",
      "8                    5.0                 0.0                 127.0   \n",
      "9                   20.0                 1.0                  90.0   \n",
      "10                   8.0                 0.0                  68.0   \n",
      "11                   7.0                 0.0                1424.0   \n",
      "12                   3.0                 0.0                1447.0   \n",
      "13                   5.0                 0.0                  25.0   \n",
      "14                   4.0                 1.0                  18.0   \n",
      "15                  27.0                 0.0                1112.0   \n",
      "16                  13.0                 1.0                 874.0   \n",
      "17                  22.0                 1.0                  25.0   \n",
      "18                  15.0                 0.0                 154.0   \n",
      "19                  32.0                 0.0                 204.0   \n",
      "20                  16.0                 1.0                 409.0   \n",
      "21                  17.0                 0.0                 319.0   \n",
      "22                  13.0                 0.0                1430.0   \n",
      "23                  13.0                 0.0                1730.0   \n",
      "24                   7.0                 1.0                  54.0   \n",
      "25                   1.0                 0.0                2932.0   \n",
      "26                  16.0                 1.0                  45.0   \n",
      "27                   8.0                 0.0                  68.0   \n",
      "28                  36.0                 6.0                  70.0   \n",
      "29                  55.0                 2.0                  77.0   \n",
      "30                   7.0                 0.0                 732.0   \n",
      "31                 128.0                 0.0                  45.0   \n",
      "32                 193.0                 5.0                 104.0   \n",
      "33                  59.0                 0.0                 175.0   \n",
      "34                  23.0                 0.0                 698.0   \n",
      "35                  14.0                 0.0                 871.0   \n",
      "36                  63.0                 1.0                 183.0   \n",
      "37                   5.0                 0.0                  19.0   \n",
      "38                  37.0                 0.0                   5.0   \n",
      "39                  27.0                 1.0                  10.0   \n",
      "40                   5.0                 0.0                  17.0   \n",
      "41                  11.0                 0.0                  42.0   \n",
      "42                   4.0                 0.0                  46.0   \n",
      "43                  15.0                 0.0                  41.0   \n",
      "44                  29.0                 0.0                 262.0   \n",
      "45                  26.0                 0.0                  94.0   \n",
      "46                  38.0                 0.0                 142.0   \n",
      "47                  33.0                 0.0                  85.0   \n",
      "48                  30.0                 0.0                  21.0   \n",
      "49                  22.0                 0.0                  28.0   \n",
      "\n",
      "    class_Actinopteri  class_Agaricomycetes  class_Agaricostilbomycetes  \\\n",
      "0                 0.0                   0.0                         0.0   \n",
      "1                 0.0                   1.0                         0.0   \n",
      "2                 0.0                   0.0                         0.0   \n",
      "3                 0.0                   0.0                         0.0   \n",
      "4                 0.0                   0.0                         0.0   \n",
      "5                 0.0                   0.0                         0.0   \n",
      "6                 0.0                   0.0                         0.0   \n",
      "7                 0.0                   0.0                         0.0   \n",
      "8                 0.0                   0.0                         0.0   \n",
      "9                 0.0                   0.0                         0.0   \n",
      "10                0.0                   1.0                         0.0   \n",
      "11                0.0                   0.0                         0.0   \n",
      "12                0.0                   0.0                         0.0   \n",
      "13                0.0                   0.0                         0.0   \n",
      "14                0.0                   0.0                         0.0   \n",
      "15                0.0                   0.0                         0.0   \n",
      "16                0.0                   0.0                         0.0   \n",
      "17                0.0                   0.0                         0.0   \n",
      "18                1.0                   2.0                         0.0   \n",
      "19                2.0                   0.0                         0.0   \n",
      "20                0.0                  15.0                         5.0   \n",
      "21                2.0                   5.0                         1.0   \n",
      "22                0.0                   1.0                         0.0   \n",
      "23                0.0                   0.0                         0.0   \n",
      "24                2.0                   2.0                         1.0   \n",
      "25                0.0                   1.0                         0.0   \n",
      "26                1.0                   0.0                         0.0   \n",
      "27                0.0                   1.0                         2.0   \n",
      "28                6.0                   0.0                         3.0   \n",
      "29                8.0                   3.0                         1.0   \n",
      "30                0.0                   0.0                         0.0   \n",
      "31                2.0                  17.0                         0.0   \n",
      "32                0.0                  28.0                         4.0   \n",
      "33                1.0                   0.0                         0.0   \n",
      "34                0.0                   0.0                         0.0   \n",
      "35                0.0                   0.0                         0.0   \n",
      "36                0.0                   0.0                         4.0   \n",
      "37                2.0                   0.0                         0.0   \n",
      "38                0.0                   0.0                         0.0   \n",
      "39                0.0                   0.0                         0.0   \n",
      "40                0.0                   0.0                         0.0   \n",
      "41                2.0                   1.0                         0.0   \n",
      "42                0.0                   1.0                         0.0   \n",
      "43                0.0                   0.0                         0.0   \n",
      "44                0.0                   0.0                         0.0   \n",
      "45                0.0                   0.0                         0.0   \n",
      "46                0.0                   0.0                         0.0   \n",
      "47                0.0                   0.0                         0.0   \n",
      "48                2.0                   1.0                         0.0   \n",
      "49                0.0                   0.0                         0.0   \n",
      "\n",
      "    class_Allomalorhagida  ...  sulfate  sulfate_method  sulfide  \\\n",
      "0                     0.0  ...      NaN             NaN      NaN   \n",
      "1                     0.0  ...      NaN             NaN      NaN   \n",
      "2                     0.0  ...      NaN             NaN      NaN   \n",
      "3                     0.0  ...      NaN             NaN      NaN   \n",
      "4                     0.0  ...      NaN             NaN      NaN   \n",
      "5                     0.0  ...      NaN             NaN      NaN   \n",
      "6                     0.0  ...      NaN             NaN      NaN   \n",
      "7                    19.0  ...      NaN             NaN      NaN   \n",
      "8                     0.0  ...      NaN             NaN      NaN   \n",
      "9                     0.0  ...      NaN             NaN      NaN   \n",
      "10                    0.0  ...      NaN             NaN      NaN   \n",
      "11                    0.0  ...      NaN             NaN      NaN   \n",
      "12                    0.0  ...      NaN             NaN      NaN   \n",
      "13                    0.0  ...      NaN             NaN      NaN   \n",
      "14                    0.0  ...      NaN             NaN      NaN   \n",
      "15                    0.0  ...      NaN             NaN      NaN   \n",
      "16                    0.0  ...      NaN             NaN      NaN   \n",
      "17                    0.0  ...      NaN             NaN      NaN   \n",
      "18                    0.0  ...      NaN             NaN      NaN   \n",
      "19                    0.0  ...      NaN             NaN      NaN   \n",
      "20                    0.0  ...      NaN             NaN      NaN   \n",
      "21                    0.0  ...      NaN             NaN      NaN   \n",
      "22                    0.0  ...      NaN             NaN      NaN   \n",
      "23                    0.0  ...      NaN             NaN      NaN   \n",
      "24                    0.0  ...      NaN             NaN      NaN   \n",
      "25                    0.0  ...      NaN             NaN      NaN   \n",
      "26                    0.0  ...      NaN             NaN      NaN   \n",
      "27                    0.0  ...      NaN             NaN      NaN   \n",
      "28                    0.0  ...      NaN             NaN      NaN   \n",
      "29                    0.0  ...      NaN             NaN      NaN   \n",
      "30                    0.0  ...      NaN             NaN      NaN   \n",
      "31                    0.0  ...      NaN             NaN      NaN   \n",
      "32                    0.0  ...      NaN             NaN      NaN   \n",
      "33                    0.0  ...      NaN             NaN      NaN   \n",
      "34                    0.0  ...      NaN             NaN      NaN   \n",
      "35                    0.0  ...      NaN             NaN      NaN   \n",
      "36                    0.0  ...      NaN             NaN      NaN   \n",
      "37                    0.0  ...      NaN             NaN      NaN   \n",
      "38                    0.0  ...      NaN             NaN      NaN   \n",
      "39                    0.0  ...      NaN             NaN      NaN   \n",
      "40                    0.0  ...      NaN             NaN      NaN   \n",
      "41                    0.0  ...      NaN             NaN      NaN   \n",
      "42                    0.0  ...      NaN             NaN      NaN   \n",
      "43                    0.0  ...      NaN             NaN      NaN   \n",
      "44                    0.0  ...      NaN             NaN      NaN   \n",
      "45                    0.0  ...      NaN             NaN      NaN   \n",
      "46                    0.0  ...      NaN             NaN      NaN   \n",
      "47                    0.0  ...      NaN             NaN      NaN   \n",
      "48                    0.0  ...      NaN             NaN      NaN   \n",
      "49                    0.0  ...      NaN             NaN      NaN   \n",
      "\n",
      "    sulfide_method  turbidity  turbidity_method  water_current  \\\n",
      "0              NaN        NaN              None            NaN   \n",
      "1              NaN        NaN              None            NaN   \n",
      "2              NaN        NaN              None            NaN   \n",
      "3              NaN        NaN              None            NaN   \n",
      "4              NaN        NaN              None            NaN   \n",
      "5              NaN        NaN              None            NaN   \n",
      "6              NaN        NaN              None            NaN   \n",
      "7              NaN        NaN              None            NaN   \n",
      "8              NaN        NaN              None            NaN   \n",
      "9              NaN        NaN              None            NaN   \n",
      "10             NaN        NaN              None            NaN   \n",
      "11             NaN        NaN              None            NaN   \n",
      "12             NaN        NaN              None            NaN   \n",
      "13             NaN        NaN              None            NaN   \n",
      "14             NaN        NaN              None            NaN   \n",
      "15             NaN        NaN              None            NaN   \n",
      "16             NaN        NaN              None            NaN   \n",
      "17             NaN        NaN              None            NaN   \n",
      "18             NaN        NaN              None            NaN   \n",
      "19             NaN        NaN              None            NaN   \n",
      "20             NaN        NaN              None            NaN   \n",
      "21             NaN        NaN              None            NaN   \n",
      "22             NaN        NaN              None            NaN   \n",
      "23             NaN        NaN              None            NaN   \n",
      "24             NaN        NaN              None            NaN   \n",
      "25             NaN        NaN              None            NaN   \n",
      "26             NaN        NaN              None            NaN   \n",
      "27             NaN        NaN              None            NaN   \n",
      "28             NaN        NaN              None            NaN   \n",
      "29             NaN        NaN              None            NaN   \n",
      "30             NaN        NaN              None            NaN   \n",
      "31             NaN        NaN              None            NaN   \n",
      "32             NaN        NaN              None            NaN   \n",
      "33             NaN        6.0       Secchi disc            NaN   \n",
      "34             NaN        6.0       Secchi disc            NaN   \n",
      "35             NaN        6.0       Secchi disc            NaN   \n",
      "36             NaN       10.0       Secchi disc            NaN   \n",
      "37             NaN        NaN              None            NaN   \n",
      "38             NaN        NaN              None            NaN   \n",
      "39             NaN        NaN              None            NaN   \n",
      "40             NaN        NaN              None            NaN   \n",
      "41             NaN        NaN              None            NaN   \n",
      "42             NaN        NaN              None            NaN   \n",
      "43             NaN        NaN              None            NaN   \n",
      "44             NaN        NaN              None            NaN   \n",
      "45             NaN        NaN              None            NaN   \n",
      "46             NaN        NaN              None            NaN   \n",
      "47             NaN        NaN              None            NaN   \n",
      "48             NaN        NaN              None            NaN   \n",
      "49             NaN        NaN              None            NaN   \n",
      "\n",
      "    water_current_method  env_package_1     ref_code  \n",
      "0                    NaN  soft_sediment  EMOBON00001  \n",
      "1                    NaN  soft_sediment  EMOBON00084  \n",
      "2                    NaN  soft_sediment  EMOBON00086  \n",
      "3                    NaN  soft_sediment  EMOBON00088  \n",
      "4                    NaN  soft_sediment  EMOBON00091  \n",
      "5                    NaN  soft_sediment  EMOBON00092  \n",
      "6                    NaN  soft_sediment  EMOBON00093  \n",
      "7                    NaN  soft_sediment  EMOBON00094  \n",
      "8                    NaN  soft_sediment  EMOBON00095  \n",
      "9                    NaN  soft_sediment  EMOBON00097  \n",
      "10                   NaN  soft_sediment  EMOBON00098  \n",
      "11                   NaN   water_column  EMOBON00120  \n",
      "12                   NaN   water_column  EMOBON00121  \n",
      "13                   NaN   water_column  EMOBON00122  \n",
      "14                   NaN   water_column  EMOBON00123  \n",
      "15                   NaN   water_column  EMOBON00124  \n",
      "16                   NaN   water_column  EMOBON00125  \n",
      "17                   NaN   water_column  EMOBON00126  \n",
      "18                   NaN   water_column  EMOBON00130  \n",
      "19                   NaN   water_column  EMOBON00131  \n",
      "20                   NaN   water_column  EMOBON00136  \n",
      "21                   NaN   water_column  EMOBON00137  \n",
      "22                   NaN   water_column  EMOBON00138  \n",
      "23                   NaN   water_column  EMOBON00139  \n",
      "24                   NaN  soft_sediment  EMOBON00140  \n",
      "25                   NaN  soft_sediment  EMOBON00141  \n",
      "26                   NaN  soft_sediment  EMOBON00142  \n",
      "27                   NaN  soft_sediment  EMOBON00143  \n",
      "28                   NaN   water_column  EMOBON00144  \n",
      "29                   NaN   water_column  EMOBON00145  \n",
      "30                   NaN   water_column  EMOBON00147  \n",
      "31                   NaN   water_column  EMOBON00148  \n",
      "32                   NaN   water_column  EMOBON00149  \n",
      "33                   NaN   water_column  EMOBON00155  \n",
      "34                   NaN   water_column  EMOBON00156  \n",
      "35                   NaN   water_column  EMOBON00157  \n",
      "36                   NaN   water_column  EMOBON00158  \n",
      "37                   NaN  soft_sediment  EMOBON00193  \n",
      "38                   NaN  soft_sediment  EMOBON00194  \n",
      "39                   NaN  soft_sediment  EMOBON00195  \n",
      "40                   NaN  soft_sediment  EMOBON00224  \n",
      "41                   NaN  soft_sediment  EMOBON00225  \n",
      "42                   NaN  soft_sediment  EMOBON00226  \n",
      "43                   NaN  soft_sediment  EMOBON00227  \n",
      "44                   NaN  soft_sediment  EMOBON00236  \n",
      "45                   NaN  soft_sediment  EMOBON00237  \n",
      "46                   NaN  soft_sediment  EMOBON00238  \n",
      "47                   NaN  soft_sediment  EMOBON00241  \n",
      "48                   NaN  soft_sediment  EMOBON00242  \n",
      "49                   NaN  soft_sediment  EMOBON00243  \n",
      "\n",
      "[50 rows x 387 columns]\n"
     ]
    }
   ],
   "source": [
    "#### joining all the tables together - metadata and the SSU class level\n",
    "### NaN converted to 0, but the data needs standardisation and square rooting\n",
    "\n",
    "# Define the query for full_metadata\n",
    "query = \"\"\"\n",
    "SELECT OBS_METADATA.*,\n",
    "       SAMPLE_METADATA.*,\n",
    "FROM SAMPLE_METADATA\n",
    "INNER JOIN OBS_METADATA \n",
    "ON SAMPLE_METADATA.obs_id = OBS_METADATA.obs_id\n",
    "AND SAMPLE_METADATA.env_package = OBS_METADATA.env_package\n",
    "ORDER BY SAMPLE_METADATA.ref_code ASC\n",
    "\"\"\"\n",
    "\n",
    "# Get the full_metadata DataFrame\n",
    "full_metadata = duckdb.sql(query).df()\n",
    "\n",
    "# Define the query to get SSU_class_all data\n",
    "ssu_class_all_query = \"SELECT * FROM SSU_class_all\"\n",
    "\n",
    "# Get the SSU_class_all DataFrame\n",
    "ssu_class_all = duckdb.sql(ssu_class_all_query).df()\n",
    "\n",
    "# Step 1: Transpose the 'SSU_class_all' DataFrame\n",
    "ssu_class_all_transposed = ssu_class_all.transpose().reset_index()\n",
    "ssu_class_all_transposed.columns = [\"ref_code\"] + list(\n",
    "    ssu_class_all_transposed.iloc[0, 1:]\n",
    ")  # Set ref_code as the first column and the remaining as data\n",
    "ssu_class_all_transposed = ssu_class_all_transposed.drop(0).reset_index(\n",
    "    drop=True\n",
    ")  # Drop the first row used for column names\n",
    "\n",
    "# Step 2: Convert NaN values in the transposed 'SSU_class_all' to 0\n",
    "ssu_class_all_transposed = ssu_class_all_transposed.fillna(0)\n",
    "\n",
    "# Step 3: Add prefix to each column header from SSU_class_all\n",
    "ssu_class_all_transposed.columns = [\"ref_code\"] + [\n",
    "    \"class_\" + col for col in ssu_class_all_transposed.columns[1:]\n",
    "]\n",
    "\n",
    "# Step 4: Merge the transposed 'SSU_class_all' with 'full_metadata' on 'ref_code'\n",
    "merged_data = pd.merge(\n",
    "    full_metadata, ssu_class_all_transposed, on=\"ref_code\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Step 5: Reorder columns to place SSU_class_all columns at the beginning\n",
    "ssu_class_all_columns = [\n",
    "    col for col in ssu_class_all_transposed.columns if col != \"ref_code\"\n",
    "]\n",
    "other_columns = [\n",
    "    col\n",
    "    for col in merged_data.columns\n",
    "    if col not in ssu_class_all_columns and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Define new column order: SSU_class_all columns first, then other columns, followed by 'ref_code'\n",
    "new_column_order = ssu_class_all_columns + other_columns + [\"ref_code\"]\n",
    "merged_data = merged_data[new_column_order]\n",
    "\n",
    "# Display the reordered merged data (optional)\n",
    "print(merged_data)\n",
    "\n",
    "# Export the result to CSV\n",
    "output_csv = \"merged_data.csv\"  # Specify your file path here\n",
    "\n",
    "duckdb.sql(\n",
    "    f\"\"\"\n",
    "COPY (\n",
    "    {query}\n",
    ") TO '{output_csv}' WITH (FORMAT CSV, HEADER TRUE)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a6ca06-5b7a-4ad8-9799-fc658961c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  class  EMOBON00001  EMOBON00084  EMOBON00086  EMOBON00088  \\\n",
      "0            Acantharea          1.0          NaN          NaN          NaN   \n",
      "1        Acidimicrobiia        248.0        300.0        646.0        287.0   \n",
      "2     Acidithiobacillia          1.0          1.0          NaN          2.0   \n",
      "3        Acidobacteriia         11.0         23.0          5.0         10.0   \n",
      "4          Aconoidasida          NaN          NaN          NaN          NaN   \n",
      "..                  ...          ...          ...          ...          ...   \n",
      "244     Wallemiomycetes          NaN          NaN          NaN          NaN   \n",
      "245       Xanthophyceae          NaN          NaN          NaN          NaN   \n",
      "246  Zetaproteobacteria          NaN          NaN          NaN          3.0   \n",
      "247      Zoopagomycetes          NaN          NaN          NaN          NaN   \n",
      "248      Zygnemophyceae          NaN          NaN          NaN          NaN   \n",
      "\n",
      "     EMOBON00091  EMOBON00092  EMOBON00093  EMOBON00094  EMOBON00095  ...  \\\n",
      "0            NaN          NaN          NaN          NaN          NaN  ...   \n",
      "1          260.0        298.0        436.0        434.0        217.0  ...   \n",
      "2            4.0          4.0          NaN          1.0          4.0  ...   \n",
      "3           11.0          5.0          3.0         24.0          5.0  ...   \n",
      "4            NaN          NaN          NaN          NaN          NaN  ...   \n",
      "..           ...          ...          ...          ...          ...  ...   \n",
      "244          NaN          NaN          NaN          NaN          NaN  ...   \n",
      "245          NaN          NaN          NaN          NaN          NaN  ...   \n",
      "246         12.0          4.0          NaN          3.0          5.0  ...   \n",
      "247          NaN          NaN          NaN          NaN          NaN  ...   \n",
      "248          NaN          NaN          NaN          NaN          NaN  ...   \n",
      "\n",
      "     EMOBON00224  EMOBON00225  EMOBON00226  EMOBON00227  EMOBON00236  \\\n",
      "0            NaN          NaN          NaN          NaN          NaN   \n",
      "1          170.0        230.0        340.0        428.0        445.0   \n",
      "2            3.0          1.0          2.0          4.0          1.0   \n",
      "3            5.0         11.0          4.0         15.0         29.0   \n",
      "4            NaN          NaN          NaN          NaN          NaN   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "244          NaN          NaN          NaN          NaN          NaN   \n",
      "245          NaN          NaN          NaN          NaN          NaN   \n",
      "246          3.0          1.0          NaN          3.0          9.0   \n",
      "247          NaN          NaN          NaN          NaN          4.0   \n",
      "248          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "     EMOBON00237  EMOBON00238  EMOBON00241  EMOBON00242  EMOBON00243  \n",
      "0            NaN          1.0          NaN          NaN          3.0  \n",
      "1          269.0        384.0        301.0        479.0        359.0  \n",
      "2            2.0          2.0          5.0          2.0          3.0  \n",
      "3           26.0         38.0         33.0         30.0         22.0  \n",
      "4            NaN          NaN          NaN          NaN          NaN  \n",
      "..           ...          ...          ...          ...          ...  \n",
      "244          NaN          NaN          NaN          NaN          NaN  \n",
      "245          NaN          NaN          NaN          NaN          NaN  \n",
      "246          3.0          7.0          3.0          NaN          NaN  \n",
      "247          NaN          NaN          NaN          NaN          NaN  \n",
      "248          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[249 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Execute the query to get SSU_class_all\n",
    "ssu_class_all_query = \"SELECT * FROM SSU_class_all\"\n",
    "\n",
    "# Get the SSU_class_all DataFrame\n",
    "ssu_class_all = duckdb.sql(ssu_class_all_query).df()\n",
    "\n",
    "# Option 1: Print the full DataFrame\n",
    "print(ssu_class_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228ccdc-7f74-42c3-9cfb-4a05bcbd9aa4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function to calculate Shannon index\n",
    "\n",
    "\n",
    "def calculate_shannon_index(df):\n",
    "    def shannon_index(row):\n",
    "        total_abundance = row.sum()\n",
    "        if total_abundance == 0:\n",
    "            return np.nan\n",
    "        relative_abundance = row / total_abundance\n",
    "        return entropy(\n",
    "            relative_abundance, base=np.e\n",
    "        )  # Shannon entropy (natural log base)\n",
    "\n",
    "    return df.apply(shannon_index, axis=1)\n",
    "\n",
    "\n",
    "# Extract numeric columns and metadata\n",
    "numeric_columns = [col for col in merged_data.columns if col.startswith(\"class_\")]\n",
    "metadata_columns = [\n",
    "    col\n",
    "    for col in merged_data.columns\n",
    "    if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Convert columns to numeric and replace NaN with 0\n",
    "merged_data[numeric_columns] = (\n",
    "    merged_data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "\n",
    "# Calculate Shannon index for each sample\n",
    "shannon_values = calculate_shannon_index(merged_data[numeric_columns])\n",
    "\n",
    "# Create a DataFrame for Shannon index values\n",
    "shannon_df = pd.DataFrame(\n",
    "    {\"ref_code\": merged_data[\"ref_code\"], \"Shannon\": shannon_values}\n",
    ")\n",
    "\n",
    "# Plot the Shannon index for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(shannon_df[\"ref_code\"], shannon_df[\"Shannon\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Shannon Index\")\n",
    "plt.title(\"Shannon Index for Each Sample\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ea382-5d0e-4368-a766-5356ef42590f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_columns = [col for col in merged_data.columns if col.startswith(\"class_\")]\n",
    "metadata_columns = [\n",
    "    col\n",
    "    for col in merged_data.columns\n",
    "    if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Convert columns to numeric and replace NaN with 0\n",
    "merged_data[numeric_columns] = (\n",
    "    merged_data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "\n",
    "# Calculate Shannon index for each sample\n",
    "shannon_values = calculate_shannon_index(merged_data[numeric_columns])\n",
    "\n",
    "\n",
    "# Example if metadata is a list of dictionaries\n",
    "metadata = pd.DataFrame(metadata)\n",
    "\n",
    "\n",
    "# Function to calculate Shannon index\n",
    "def calculate_shannon_index(df):\n",
    "    def shannon_index(row):\n",
    "        total_abundance = row.sum()\n",
    "        if total_abundance == 0:\n",
    "            return np.nan\n",
    "        relative_abundance = row / total_abundance\n",
    "        return entr(relative_abundance).sum()  # Shannon entropy\n",
    "\n",
    "    return df.apply(shannon_index, axis=1)\n",
    "\n",
    "\n",
    "def calculate_alpha_diversity(df, metadata):\n",
    "    # Filter numeric columns for Shannon calculation\n",
    "    numeric_columns = [col for col in df.columns if col.startswith(\"class_\")]\n",
    "    transposed_data = df[numeric_columns].copy()  # Select only numeric columns\n",
    "    shannon_values = calculate_shannon_index(transposed_data)\n",
    "    alpha_diversity_df = pd.DataFrame(\n",
    "        {\"ref_code\": df[\"ref_code\"], \"Shannon\": shannon_values}\n",
    "    )\n",
    "    alpha_diversity_df = pd.merge(\n",
    "        alpha_diversity_df, metadata, on=\"ref_code\", how=\"left\"\n",
    "    )\n",
    "    return alpha_diversity_df\n",
    "\n",
    "\n",
    "def plot_shannon_index(alpha_diversity_df, selected_factor):\n",
    "    alpha_diversity_sorted = alpha_diversity_df.sort_values(by=selected_factor)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        x=\"ref_code\",\n",
    "        y=\"Shannon\",\n",
    "        hue=selected_factor,\n",
    "        data=alpha_diversity_sorted,\n",
    "        dodge=False,\n",
    "        palette=\"coolwarm\",\n",
    "        errorbar=None,\n",
    "    )\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Shannon Index\")\n",
    "    plt.title(f\"Shannon Index Grouped by {selected_factor}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_average_shannon_per_condition(alpha_diversity_df, selected_factor):\n",
    "    palette = sns.color_palette(\n",
    "        \"coolwarm\", len(alpha_diversity_df[selected_factor].unique())\n",
    "    )\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    means = grouped_data.mean()\n",
    "    errors = grouped_data.sem()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    means.plot(kind=\"bar\", yerr=errors, color=palette, capsize=5)\n",
    "    plt.xlabel(selected_factor)\n",
    "    plt.ylabel(\"Average Shannon Index\")\n",
    "    plt.title(f\"Average Shannon Index by {selected_factor}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_normality(data):\n",
    "    \"\"\"Check normality using Shapiro-Wilk test\"\"\"\n",
    "    stat, p_value = shapiro(data)\n",
    "    return p_value > 0.05  # True if data is normally distributed\n",
    "\n",
    "\n",
    "def check_homogeneity_of_variances(groups):\n",
    "    \"\"\"Check homogeneity of variances using Levene's test\"\"\"\n",
    "    stat, p_value = levene(*groups)\n",
    "    return p_value > 0.05  # True if variances are equal\n",
    "\n",
    "\n",
    "def run_anova_and_posthoc(alpha_diversity_df, selected_factor):\n",
    "    # ANOVA for the selected factor\n",
    "    anova_results = pg.anova(\n",
    "        data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "    )\n",
    "\n",
    "    # Create a string to capture the output\n",
    "    anova_output = \"\\nANOVA Results:\\n\"\n",
    "    anova_output += anova_results.to_string(index=False)\n",
    "\n",
    "    # Check the distribution of data\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    groups = [group for name, group in grouped_data]\n",
    "\n",
    "    normal = check_normality(alpha_diversity_df[\"Shannon\"])\n",
    "    homogeneity = check_homogeneity_of_variances(groups)\n",
    "\n",
    "    normality_result = f\"Normality check: {'Pass' if normal else 'Fail'}\"\n",
    "    homogeneity_result = (\n",
    "        f\"Homogeneity of variances check: {'Pass' if homogeneity else 'Fail'}\"\n",
    "    )\n",
    "\n",
    "    anova_output += f\"\\n{normality_result}\\n{homogeneity_result}\"\n",
    "\n",
    "    if anova_results[\"p-unc\"].values[0] < 0.05:\n",
    "        posthoc_results_str = \"\"\n",
    "        if normal and homogeneity:\n",
    "            # Tukey's HSD for normal data and equal variances\n",
    "            posthoc_results = pg.pairwise_ttests(\n",
    "                data=alpha_diversity_df,\n",
    "                dv=\"Shannon\",\n",
    "                between=selected_factor,\n",
    "                padjust=\"holm\",\n",
    "            )\n",
    "            posthoc_results_str = \"\\nPost-hoc test used: Tukey's HSD\\n\"\n",
    "            posthoc_results_str += posthoc_results.to_string(index=False)\n",
    "        else:\n",
    "            # Games-Howell for non-normal data or unequal variances\n",
    "            posthoc_results = pg.pairwise_gameshowell(\n",
    "                data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "            )\n",
    "            posthoc_results_str = \"\\nPost-hoc test used: Games-Howell\\n\"\n",
    "            posthoc_results_str += posthoc_results.to_string(index=False)\n",
    "\n",
    "        anova_output += f\"\\n\\n{posthoc_results_str}\"\n",
    "    else:\n",
    "        anova_output += f\"\\nNo significant difference found in {selected_factor}. Post-hoc test is not necessary.\"\n",
    "\n",
    "    return anova_output\n",
    "\n",
    "\n",
    "def update_plot(change):\n",
    "    with output_plot:\n",
    "        output_plot.clear_output(wait=True)\n",
    "        selected_factor = color_factor_dropdown.value\n",
    "        alpha_diversity_df = calculate_alpha_diversity(\n",
    "            data, metadata\n",
    "        )  # Ensure 'data' and 'metadata' are defined\n",
    "        plot_shannon_index(alpha_diversity_df, selected_factor)\n",
    "        plot_average_shannon_per_condition(alpha_diversity_df, selected_factor)\n",
    "\n",
    "        # Run ANOVA and display results\n",
    "        anova_output = run_anova_and_posthoc(alpha_diversity_df, selected_factor)\n",
    "        print(anova_output)  # Print ANOVA results to the output area\n",
    "\n",
    "\n",
    "# Ensure metadata is a DataFrame and contains valid columns\n",
    "if isinstance(metadata, pd.DataFrame):\n",
    "    options = [\n",
    "        col\n",
    "        for col in metadata.columns\n",
    "        if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "    ]\n",
    "else:\n",
    "    print(\"metadata is not a DataFrame. Please check the definition.\")\n",
    "    options = []\n",
    "\n",
    "# Widget Definition for Color Factor\n",
    "color_factor_dropdown = widgets.Dropdown(\n",
    "    options=options,\n",
    "    description=\"Color Factor:\",\n",
    ")\n",
    "# Output area for plots\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "# Link the dropdown to the update function\n",
    "color_factor_dropdown.observe(update_plot, names=\"value\")\n",
    "\n",
    "# Display widgets\n",
    "display(color_factor_dropdown, output_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1104e8b-8374-452f-a7f8-6a9a84cfa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b61ba6-29a7-42e6-9538-e9e9cb93d817",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming merged_data is a DataFrame already defined\n",
    "numeric_columns = [col for col in merged_data.columns if col.startswith(\"class_\")]\n",
    "metadata_columns = [\n",
    "    col\n",
    "    for col in merged_data.columns\n",
    "    if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Convert columns to numeric and replace NaN with 0\n",
    "merged_data[numeric_columns] = (\n",
    "    merged_data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate Shannon index for each sample\n",
    "def calculate_shannon_index(df):\n",
    "    def shannon_index(row):\n",
    "        total_abundance = row.sum()\n",
    "        if total_abundance == 0:\n",
    "            return np.nan\n",
    "        relative_abundance = row / total_abundance\n",
    "        return entr(relative_abundance).sum()  # Shannon entropy\n",
    "\n",
    "    return df.apply(shannon_index, axis=1)\n",
    "\n",
    "\n",
    "shannon_values = calculate_shannon_index(merged_data[numeric_columns])\n",
    "\n",
    "# Ensure metadata is a DataFrame\n",
    "metadata = pd.DataFrame(metadata) if isinstance(metadata, (list, dict)) else metadata\n",
    "\n",
    "\n",
    "def calculate_alpha_diversity(df, metadata):\n",
    "    numeric_columns = [col for col in df.columns if col.startswith(\"class_\")]\n",
    "    transposed_data = df[numeric_columns].copy()\n",
    "    shannon_values = calculate_shannon_index(transposed_data)\n",
    "    alpha_diversity_df = pd.DataFrame(\n",
    "        {\"ref_code\": df[\"ref_code\"], \"Shannon\": shannon_values}\n",
    "    )\n",
    "    alpha_diversity_df = pd.merge(\n",
    "        alpha_diversity_df, metadata, on=\"ref_code\", how=\"left\"\n",
    "    )\n",
    "    return alpha_diversity_df\n",
    "\n",
    "\n",
    "def plot_shannon_index(alpha_diversity_df, selected_factor):\n",
    "    alpha_diversity_sorted = alpha_diversity_df.sort_values(by=selected_factor)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        x=\"ref_code\",\n",
    "        y=\"Shannon\",\n",
    "        hue=selected_factor,\n",
    "        data=alpha_diversity_sorted,\n",
    "        dodge=False,\n",
    "        palette=\"coolwarm\",\n",
    "        errorbar=None,\n",
    "    )\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Shannon Index\")\n",
    "    plt.title(f\"Shannon Index Grouped by {selected_factor}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_average_shannon_per_condition(alpha_diversity_df, selected_factor):\n",
    "    palette = sns.color_palette(\n",
    "        \"coolwarm\", len(alpha_diversity_df[selected_factor].unique())\n",
    "    )\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    means = grouped_data.mean()\n",
    "    errors = grouped_data.sem()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    means.plot(kind=\"bar\", yerr=errors, color=palette, capsize=5)\n",
    "    plt.xlabel(selected_factor)\n",
    "    plt.ylabel(\"Average Shannon Index\")\n",
    "    plt.title(f\"Average Shannon Index by {selected_factor}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_normality(data):\n",
    "    \"\"\"Check normality using Shapiro-Wilk test\"\"\"\n",
    "    stat, p_value = shapiro(data)\n",
    "    return p_value > 0.05  # True if data is normally distributed\n",
    "\n",
    "\n",
    "def check_homogeneity_of_variances(groups):\n",
    "    \"\"\"Check homogeneity of variances using Levene's test\"\"\"\n",
    "    stat, p_value = levene(*groups)\n",
    "    return p_value > 0.05  # True if variances are equal\n",
    "\n",
    "\n",
    "def run_anova_and_posthoc(alpha_diversity_df, selected_factor):\n",
    "    # ANOVA for the selected factor\n",
    "    anova_results = pg.anova(\n",
    "        data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "    )\n",
    "\n",
    "    # Create a string to capture the output\n",
    "    anova_output = \"\\nANOVA Results:\\n\"\n",
    "    anova_output += anova_results.to_string(index=False)\n",
    "\n",
    "    # Check the distribution of data\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    groups = [group for name, group in grouped_data]\n",
    "\n",
    "    normal = check_normality(alpha_diversity_df[\"Shannon\"])\n",
    "    homogeneity = check_homogeneity_of_variances(groups)\n",
    "\n",
    "    normality_result = f\"Normality check: {'Pass' if normal else 'Fail'}\"\n",
    "    homogeneity_result = (\n",
    "        f\"Homogeneity of variances check: {'Pass' if homogeneity else 'Fail'}\"\n",
    "    )\n",
    "\n",
    "    anova_output += f\"\\n{normality_result}\\n{homogeneity_result}\"\n",
    "\n",
    "    if anova_results[\"p-unc\"].values[0] < 0.05:\n",
    "        posthoc_results_str = \"\"\n",
    "        if normal and homogeneity:\n",
    "            # Tukey's HSD for normal data and equal variances\n",
    "            posthoc_results = pg.pairwise_ttests(\n",
    "                data=alpha_diversity_df,\n",
    "                dv=\"Shannon\",\n",
    "                between=selected_factor,\n",
    "                padjust=\"holm\",\n",
    "            )\n",
    "            posthoc_results_str = \"\\nPost-hoc test used: Tukey's HSD\\n\"\n",
    "            posthoc_results_str += posthoc_results.to_string(index=False)\n",
    "        else:\n",
    "            # Games-Howell for non-normal data or unequal variances\n",
    "            posthoc_results = pg.pairwise_gameshowell(\n",
    "                data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "            )\n",
    "            posthoc_results_str = \"\\nPost-hoc test used: Games-Howell\\n\"\n",
    "            posthoc_results_str += posthoc_results.to_string(index=False)\n",
    "\n",
    "        anova_output += f\"\\n\\n{posthoc_results_str}\"\n",
    "    else:\n",
    "        anova_output += f\"\\nNo significant difference found in {selected_factor}. Post-hoc test is not necessary.\"\n",
    "\n",
    "    return anova_output\n",
    "\n",
    "\n",
    "def update_plot(change):\n",
    "    with output_plot:\n",
    "        output_plot.clear_output(wait=True)\n",
    "        selected_factor = color_factor_dropdown.value\n",
    "        alpha_diversity_df = calculate_alpha_diversity(\n",
    "            merged_data, metadata\n",
    "        )  # Ensure 'merged_data' and 'metadata' are defined\n",
    "        plot_shannon_index(alpha_diversity_df, selected_factor)\n",
    "        plot_average_shannon_per_condition(alpha_diversity_df, selected_factor)\n",
    "\n",
    "        # Run ANOVA and display results\n",
    "        anova_output = run_anova_and_posthoc(alpha_diversity_df, selected_factor)\n",
    "        print(anova_output)  # Print ANOVA results to the output area\n",
    "\n",
    "\n",
    "# Ensure metadata is a DataFrame\n",
    "if isinstance(metadata, pd.DataFrame):\n",
    "    color_factor_dropdown = widgets.Dropdown(\n",
    "        options=[\n",
    "            col\n",
    "            for col in metadata.columns\n",
    "            if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "        ],\n",
    "        description=\"Color Factor:\",\n",
    "    )\n",
    "else:\n",
    "    print(\"Error: metadata is not a DataFrame.\")\n",
    "    # Handle the error or initialize metadata properly\n",
    "\n",
    "# Output area for plots\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "# Link the dropdown to the update function\n",
    "color_factor_dropdown.observe(update_plot, names=\"value\")\n",
    "\n",
    "# Display widgets\n",
    "display(color_factor_dropdown, output_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6a025-3052-4826-9c1e-e5d6b25bf2d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### delete later\n",
    "\n",
    "# Step 1: Load the table from DuckDB into a DataFrame\n",
    "data = duckdb.sql(\"SELECT * FROM SSU_for_visualisation\").fetchdf()\n",
    "\n",
    "# Step 2: Set 'taxonomic_concat' as the index and transpose the DataFrame\n",
    "transposed_data = data.set_index(\"taxonomic_concat\").T\n",
    "\n",
    "# Step 3: Load the material information from the CSV file\n",
    "metadata = pd.read_csv(\"/home/jupyter-andrzej/metadata/metadata_jup_test4.csv\")\n",
    "\n",
    "# Step 4: Merge metadata with transposed data based on 'ref_code'\n",
    "merged_data = pd.merge(\n",
    "    transposed_data,\n",
    "    metadata[\n",
    "        [\"ref_code\"]\n",
    "        + [\n",
    "            col\n",
    "            for col in metadata.columns\n",
    "            if col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "        ]\n",
    "    ],\n",
    "    left_index=True,\n",
    "    right_on=\"ref_code\",\n",
    ")\n",
    "\n",
    "# Exclude metadata columns from Shannon index calculation\n",
    "metadata_columns = [\n",
    "    \"filter_size\",\n",
    "    \"date\",\n",
    "    \"replcate\",\n",
    "    \"station_filter\",\n",
    "    \"filter_rep\",\n",
    "    \"location\",\n",
    "    \"country\",\n",
    "    \"column12\",\n",
    "    \"column13\",\n",
    "]\n",
    "numeric_columns = [\n",
    "    col for col in transposed_data.columns if col not in metadata_columns\n",
    "]\n",
    "\n",
    "\n",
    "#############################\n",
    "# Step 1: Load the table from DuckDB into a DataFrame\n",
    "data = merged_data  # Use 'merged_data'\n",
    "\n",
    "# Ensure that we only use numeric data for distance calculation\n",
    "numeric_columns = [\n",
    "    col for col in data.columns if col.startswith(\"class_\")\n",
    "]  # Columns with the prefix 'class_'\n",
    "metadata = [\n",
    "    col for col in data.columns if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Convert the columns to numeric (if they are not already) and replace NaN with 0\n",
    "data[numeric_columns] = (\n",
    "    data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "# data[numeric_columns] = data[numeric_columns].astype(float).fillna(0)\n",
    "\n",
    "\n",
    "# Now all 'NaN' values in columns with names starting with 'class_' have been replaced with 0.\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "# Function to calculate Shannon index\n",
    "# def calculate_shannon_index(df):\n",
    "#    def shannon_index(row):\n",
    "#        float_values = row\n",
    "#        if float_values.sum() == 0:\n",
    "#            return np.nan\n",
    "#        relative_abundance = float_values / float_values.sum()\n",
    "#        return entropy(relative_abundance, base=np.e)\n",
    "\n",
    "#    return df.apply(shannon_index, axis=1)\n",
    "\n",
    "# Filter columns matching the pattern 'number;sk_*' (where 'number;' can be any text)\n",
    "# pattern = re.compile(r'^.*;sk_.*')\n",
    "# filtered_data = merged_data.filter(regex=pattern)\n",
    "\n",
    "# Calculate Shannon index and add it as a new column\n",
    "# merged_data['Shannon'] = calculate_shannon_index(filtered_data)\n",
    "\n",
    "# Function to plot alpha diversity metrics\n",
    "\n",
    "\n",
    "def plot_alpha_diversity_grouped(alpha_diversity_df, selected_factor):\n",
    "    alpha_diversity_sorted = alpha_diversity_df.sort_values(by=selected_factor)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Suppress FutureWarnings related to the ci parameter\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "        sns.barplot(\n",
    "            x=\"ref_code\",\n",
    "            y=\"Shannon\",\n",
    "            hue=selected_factor,\n",
    "            data=alpha_diversity_sorted,\n",
    "            dodge=False,\n",
    "            palette=\"coolwarm\",\n",
    "            errorbar=None,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Shannon Index\")\n",
    "    plt.title(f\"Shannon Index Grouped by {selected_factor}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Calculate alpha diversity metrics (Shannon)\n",
    "\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "def calculate_shannon_index(df):\n",
    "    def shannon_index(row):\n",
    "        total_abundance = row.sum()\n",
    "        if total_abundance == 0:\n",
    "            return np.nan\n",
    "        relative_abundance = row / total_abundance\n",
    "        return entropy(\n",
    "            relative_abundance, base=np.e\n",
    "        )  # Shannon entropy (natural log base)\n",
    "\n",
    "    return df.apply(shannon_index, axis=1)\n",
    "\n",
    "\n",
    "def calculate_alpha_diversity(transposed_data, metadata):\n",
    "    # Calculate Shannon index for each sample\n",
    "    shannon_values = calculate_shannon_index(transposed_data)\n",
    "\n",
    "    # Create a DataFrame for Shannon index values\n",
    "    alpha_diversity_df = pd.DataFrame(\n",
    "        {\"ref_code\": transposed_data.index, \"Shannon\": shannon_values}\n",
    "    )\n",
    "\n",
    "    # Merge the Shannon index with metadata\n",
    "    alpha_diversity_df = pd.merge(\n",
    "        alpha_diversity_df, metadata, on=\"ref_code\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    return alpha_diversity_df\n",
    "\n",
    "\n",
    "# Function to calculate ANOVA for all factors and run post-hoc test for the selected factor\n",
    "def run_anova_for_factors(alpha_diversity_df, selected_factor):\n",
    "    # List of all factors from the metadata (excluding ref_code and other irrelevant columns)\n",
    "    all_factors = [\n",
    "        col\n",
    "        for col in metadata.columns\n",
    "        if not re.search(r\"\\d\", col) and col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "    ]\n",
    "\n",
    "    print(\"\\nANOVA Results for all Factors:\")\n",
    "    anova_results_list = []\n",
    "    for factor in all_factors:\n",
    "        anova_results = pg.anova(data=alpha_diversity_df, dv=\"Shannon\", between=factor)\n",
    "        f_value = anova_results[\"F\"].values[0]\n",
    "        p_value = anova_results[\"p-unc\"].values[0]\n",
    "        anova_results_list.append((factor, f_value, p_value))\n",
    "        print(f\"{factor} - F-value: {f_value:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "    # Based on the selected factor, run the post-hoc test if p-value < 0.05\n",
    "    selected_factor_anova = [\n",
    "        result for result in anova_results_list if result[0] == selected_factor\n",
    "    ][0]\n",
    "\n",
    "    if selected_factor_anova[2] < 0.05:\n",
    "        print(f\"\\nRunning post-hoc tests for {selected_factor}...\")\n",
    "        posthoc_results = pg.pairwise_ttests(\n",
    "            data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "        )\n",
    "        print(\"\\nPosthoc Test Results:\")\n",
    "        print(posthoc_results)\n",
    "    else:\n",
    "        print(\n",
    "            f\"No significant difference found in {selected_factor}. Post-hoc test is not necessary.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def check_normality(data):\n",
    "    \"\"\"Check normality using Shapiro-Wilk test\"\"\"\n",
    "    stat, p_value = shapiro(data)\n",
    "    return p_value > 0.05  # True if data is normally distributed\n",
    "\n",
    "\n",
    "def check_homogeneity_of_variances(groups):\n",
    "    \"\"\"Check homogeneity of variances using Levene's test\"\"\"\n",
    "    stat, p_value = levene(*groups)\n",
    "    return p_value > 0.05  # True if variances are equal\n",
    "\n",
    "\n",
    "def run_anova_and_posthoc(alpha_diversity_df, selected_factor):\n",
    "    # ANOVA for the selected factor\n",
    "    anova_results = pg.anova(\n",
    "        data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "    )\n",
    "    print(\"\\nANOVA Results:\")\n",
    "    print(anova_results)\n",
    "\n",
    "    # Check the distribution of data\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    groups = [group for name, group in grouped_data]\n",
    "\n",
    "    normal = check_normality(alpha_diversity_df[\"Shannon\"])\n",
    "    homogeneity = check_homogeneity_of_variances(groups)\n",
    "\n",
    "    print(f\"Normality check: {'Pass' if normal else 'Fail'}\")\n",
    "    print(f\"Homogeneity of variances check: {'Pass' if homogeneity else 'Fail'}\")\n",
    "\n",
    "    if anova_results[\"p-unc\"].values[0] < 0.05:\n",
    "        print(f\"\\nRunning post-hoc tests for {selected_factor}...\")\n",
    "\n",
    "        if normal and homogeneity:\n",
    "            # Tukey's HSD for normal data and equal variances\n",
    "            posthoc_results = pg.pairwise_ttests(\n",
    "                data=alpha_diversity_df,\n",
    "                dv=\"Shannon\",\n",
    "                between=selected_factor,\n",
    "                padjust=\"holm\",\n",
    "            )\n",
    "            print(\"Post-hoc test used: Tukey's HSD\")\n",
    "        else:\n",
    "            # Games-Howell for non-normal data or unequal variances\n",
    "            posthoc_results = pg.pairwise_gameshowell(\n",
    "                data=alpha_diversity_df, dv=\"Shannon\", between=selected_factor\n",
    "            )\n",
    "            print(\"Post-hoc test used: Games-Howell\")\n",
    "\n",
    "        print(\"\\nPosthoc Test Results:\")\n",
    "        print(posthoc_results)\n",
    "    else:\n",
    "        print(\n",
    "            f\"No significant difference found in {selected_factor}. Post-hoc test is not necessary.\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Use the function in the update_alpha_diversity\n",
    "def update_alpha_diversity(change):\n",
    "    with output_alpha_diversity:\n",
    "        output_alpha_diversity.clear_output(wait=True)\n",
    "\n",
    "        selected_factor = alpha_factor_dropdown.value\n",
    "\n",
    "        # Calculate alpha diversity with metadata\n",
    "        alpha_diversity_df = calculate_alpha_diversity(transposed_data, metadata)\n",
    "\n",
    "        # Plot the alpha diversity grouped by the selected factor\n",
    "        plot_alpha_diversity_grouped(alpha_diversity_df, selected_factor)\n",
    "\n",
    "        # Plot the average Shannon index per category\n",
    "        plot_average_shannon(alpha_diversity_df, selected_factor)\n",
    "\n",
    "        # Run ANOVA and post-hoc tests with appropriate test selection\n",
    "        run_anova_and_posthoc(alpha_diversity_df, selected_factor)\n",
    "\n",
    "\n",
    "# Widget Definition for Grouping Factor (only)\n",
    "alpha_factor_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        col\n",
    "        for col in metadata.columns\n",
    "        if not re.search(r\"\\d\", col) and col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "    ],\n",
    "    description=\"Grouping Factor:\",\n",
    ")\n",
    "\n",
    "\n",
    "def plot_average_shannon(alpha_diversity_df, selected_factor):\n",
    "    # Determine the color palette from the grouped plot\n",
    "    palette = sns.color_palette(\n",
    "        \"coolwarm\", len(alpha_diversity_df[selected_factor].unique())\n",
    "    )\n",
    "\n",
    "    # Group data by the selected factor and calculate the mean and standard error of Shannon index\n",
    "    grouped_data = alpha_diversity_df.groupby(selected_factor)[\"Shannon\"]\n",
    "    means = grouped_data.mean()\n",
    "    errors = grouped_data.sem()  # Standard error of the mean\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot the average Shannon index with error bars and custom colors\n",
    "    bars = means.plot(kind=\"bar\", yerr=errors, color=palette, capsize=5)\n",
    "    plt.xlabel(selected_factor)\n",
    "    plt.ylabel(\"Average Shannon Index\")\n",
    "    plt.title(f\"Average Shannon Index by {selected_factor}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Output area for Alpha Diversity\n",
    "output_alpha_diversity = widgets.Output()\n",
    "\n",
    "# Link alpha diversity dropdowns to the update function\n",
    "alpha_factor_dropdown.observe(update_alpha_diversity, names=\"value\")\n",
    "\n",
    "# Display widgets\n",
    "display(alpha_factor_dropdown, output_alpha_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e908e-90dc-4396-beee-499df8bae513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a86f58-d48c-48e1-bcf5-ca30531cd53f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming `merged` is the updated DataFrame\n",
    "data = merged_data  # Use 'merged' instead of 'SSU_class_all'\n",
    "\n",
    "# Set 'ref_code' as the index and transpose the DataFrame\n",
    "transposed_data = data.set_index(\"ref_code\").T\n",
    "\n",
    "# Load metadata from `merged`\n",
    "metadata = full_metadata\n",
    "\n",
    "# Exclude metadata columns from Shannon index calculation\n",
    "metadata_columns = [\n",
    "    \"filter_size\",\n",
    "    \"date\",\n",
    "    \"replcate\",\n",
    "    \"station_filter\",\n",
    "    \"filter_rep\",\n",
    "    \"location\",\n",
    "    \"country\",\n",
    "    \"column12\",\n",
    "    \"column13\",\n",
    "]\n",
    "numeric_columns = [col for col in transposed_data.columns if col.startswith(\"class_\")]\n",
    "\n",
    "\n",
    "# Function to compute the distance matrix based on the selected distance metric\n",
    "def compute_distance_matrix(metric):\n",
    "    if metric == \"braycurtis\":\n",
    "        return squareform(pdist(transposed_data[numeric_columns], metric=\"braycurtis\"))\n",
    "    elif metric == \"euclidean\":\n",
    "        return squareform(pdist(transposed_data[numeric_columns], metric=\"euclidean\"))\n",
    "    elif metric == \"jaccard\":\n",
    "        return squareform(pdist(transposed_data[numeric_columns], metric=\"jaccard\"))\n",
    "    elif metric == \"cityblock\":\n",
    "        return squareform(pdist(transposed_data[numeric_columns], metric=\"cityblock\"))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric selected\")\n",
    "\n",
    "\n",
    "# Step 6: Perform PERMANOVA and PCoA based on the selected distance metric\n",
    "def run_permanova_and_pcoa(distance_matrix):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        permanova_summary = pd.DataFrame(columns=[\"Factor\", \"Pseudo-F\", \"p-value\"])\n",
    "        factors_to_analyze = [\n",
    "            col\n",
    "            for col in metadata.columns\n",
    "            if not re.search(r\"\\d\", col)\n",
    "            and col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "        ]\n",
    "        for factor in factors_to_analyze:\n",
    "            unique_values = merged_data[factor].nunique()\n",
    "            if unique_values > 1:\n",
    "                metadata_reindexed = merged_data.set_index(\"ref_code\").reindex(\n",
    "                    transposed_data.index\n",
    "                )\n",
    "                try:\n",
    "                    dist_matrix_obj = DistanceMatrix(\n",
    "                        distance_matrix, ids=transposed_data.index\n",
    "                    )\n",
    "                    permanova_results = permanova(\n",
    "                        dist_matrix_obj,\n",
    "                        metadata_reindexed[factor].values,\n",
    "                        permutations=999,\n",
    "                    )\n",
    "                    pseudo_F = (\n",
    "                        permanova_results[\"test statistic\"]\n",
    "                        if \"test statistic\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    p_value = (\n",
    "                        permanova_results[\"p-value\"]\n",
    "                        if \"p-value\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    new_row = pd.DataFrame(\n",
    "                        {\n",
    "                            \"Factor\": [factor],\n",
    "                            \"Pseudo-F\": [pseudo_F],\n",
    "                            \"p-value\": [p_value],\n",
    "                        }\n",
    "                    )\n",
    "                    permanova_summary = pd.concat(\n",
    "                        [permanova_summary, new_row], ignore_index=True\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        permanova_summary = permanova_summary.sort_values(\n",
    "            by=\"Pseudo-F\", ascending=False\n",
    "        )\n",
    "        print(\"\\nPERMANOVA Summary:\")\n",
    "        print(permanova_summary.to_string(index=False))\n",
    "\n",
    "        # PCoA (PCA as approximation)\n",
    "        pcoa = PCA(n_components=2)\n",
    "        pcoa_coords = pcoa.fit_transform(distance_matrix)\n",
    "        pcoa_df = pd.DataFrame(\n",
    "            pcoa_coords, columns=[\"PCoA1\", \"PCoA2\"], index=transposed_data.index\n",
    "        )\n",
    "\n",
    "        return permanova_summary, pcoa_df\n",
    "\n",
    "\n",
    "# Plot the PCoA with optional coloring by Shannon index\n",
    "def plot_pcoa_black(pcoa_df, color_by=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if color_by is not None:\n",
    "        scatter = plt.scatter(\n",
    "            pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], c=color_by, cmap=\"RdYlGn\", edgecolor=\"k\"\n",
    "        )\n",
    "        plt.colorbar(scatter, label=\"Shannon Index\")\n",
    "    else:\n",
    "        plt.scatter(pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], color=\"black\")\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(\"PCoA Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the PCoA with the selected factor\n",
    "def plot_pcoa_with_factor(pcoa_df, selected_factor):\n",
    "    if selected_factor not in merged_data.columns:\n",
    "        print(f\"Factor '{selected_factor}' not found in the metadata.\")\n",
    "        return\n",
    "\n",
    "    pcoa_df[selected_factor] = (\n",
    "        merged_data.set_index(\"ref_code\")[selected_factor].reindex(pcoa_df.index).values\n",
    "    )\n",
    "    colors_list = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"orange\", \"purple\", \"pink\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    unique_values = pcoa_df[selected_factor].unique()\n",
    "    for i, value in enumerate(unique_values):\n",
    "        color = colors_list[i % len(colors_list)]\n",
    "        subset = pcoa_df[pcoa_df[selected_factor] == value]\n",
    "        plt.scatter(subset[\"PCoA1\"], subset[\"PCoA2\"], label=value, color=color)\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(f\"PCoA Plot Grouped by {selected_factor}\")\n",
    "    plt.legend(title=selected_factor)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SIMPER calculation excluding Shannon and metadata columns\n",
    "def calculate_simper(group1, group2):\n",
    "    group1_filtered = group1.select_dtypes(include=[np.number]).drop(\n",
    "        columns=[\"Shannon\"], errors=\"ignore\"\n",
    "    )\n",
    "    group2_filtered = group2.select_dtypes(include=[np.number]).drop(\n",
    "        columns=[\"Shannon\"], errors=\"ignore\"\n",
    "    )\n",
    "\n",
    "    mean_group1 = group1_filtered.mean()\n",
    "    mean_group2 = group2_filtered.mean()\n",
    "\n",
    "    differences = abs(mean_group1 - mean_group2)\n",
    "    total_difference = differences.sum()\n",
    "    contributions = (differences / total_difference) * 100\n",
    "\n",
    "    return contributions\n",
    "\n",
    "\n",
    "# SIMPER plot\n",
    "def plot_simper(simper_result, selected_group1, selected_group2):\n",
    "    simper_result_sorted = simper_result.sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    simper_result_sorted.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Contribution to Dissimilarity (%)\")\n",
    "    plt.title(\n",
    "        f\"SIMPER: Top 20 Features Dissimilarity between {selected_group1} and {selected_group2}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Interactive part begins ---\n",
    "\n",
    "# Define widgets\n",
    "distance_metric_dropdown = widgets.Dropdown(\n",
    "    options=[\"braycurtis\", \"euclidean\", \"jaccard\", \"cityblock\"],\n",
    "    description=\"Distance Metric:\",\n",
    ")\n",
    "\n",
    "factor_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        col\n",
    "        for col in metadata.columns\n",
    "        if not re.search(r\"\\d\", col) and col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "    ],\n",
    "    description=\"PCoA Factor:\",\n",
    "    disabled=True,\n",
    ")\n",
    "\n",
    "simper_dropdown_1 = widgets.Dropdown(\n",
    "    options=[], description=\"SIMPER: Condition 1:\", disabled=True\n",
    ")\n",
    "\n",
    "simper_dropdown_2 = widgets.Dropdown(\n",
    "    options=[], description=\"SIMPER: Condition 2:\", disabled=True\n",
    ")\n",
    "\n",
    "# Output areas\n",
    "output_permanova = widgets.Output()\n",
    "output_pcoa = widgets.Output()\n",
    "output_simper = widgets.Output()\n",
    "output_shannon = widgets.Output()\n",
    "\n",
    "\n",
    "# Function to run analysis after distance metric is selected\n",
    "def on_distance_change(change):\n",
    "    with output_permanova:\n",
    "        output_permanova.clear_output(wait=True)\n",
    "        with output_pcoa:\n",
    "            output_pcoa.clear_output(wait=True)\n",
    "            with output_shannon:\n",
    "                output_shannon.clear_output(wait=True)\n",
    "\n",
    "                selected_metric = distance_metric_dropdown.value\n",
    "                distance_matrix = compute_distance_matrix(selected_metric)\n",
    "\n",
    "                # PERMANOVA and initial PCoA\n",
    "                global permanova_summary, pcoa_df\n",
    "                permanova_summary, pcoa_df = run_permanova_and_pcoa(distance_matrix)\n",
    "\n",
    "                # Plot PCoA colored by Shannon index\n",
    "                plot_pcoa_black(pcoa_df, color_by=transposed_data[\"Shannon\"])\n",
    "\n",
    "                # Update factor and SIMPER dropdowns\n",
    "                available_factors = [\n",
    "                    col\n",
    "                    for col in merged_data.columns\n",
    "                    if not re.search(r\"\\d\", col)\n",
    "                    and col not in [\"ref_code\", \"our_code\", \"#NAME\"]\n",
    "                ]\n",
    "                factor_dropdown.options = available_factors\n",
    "                factor_dropdown.disabled = False\n",
    "\n",
    "                # Initialize SIMPER dropdowns\n",
    "                if factor_dropdown.value:\n",
    "                    current_factor = factor_dropdown.value\n",
    "                    simper_options = sorted(merged_data[current_factor].unique())\n",
    "                    simper_dropdown_1.options = simper_options\n",
    "                    simper_dropdown_2.options = simper_options\n",
    "                    simper_dropdown_1.disabled = False\n",
    "                    simper_dropdown_2.disabled = False\n",
    "\n",
    "\n",
    "distance_metric_dropdown.observe(on_distance_change, names=\"value\")\n",
    "\n",
    "\n",
    "# Function to update PCoA plot after factor is selected\n",
    "def on_factor_change(change):\n",
    "    with output_pcoa:\n",
    "        output_pcoa.clear_output(wait=True)\n",
    "\n",
    "        # Plot the PCoA with colors based on the selected factor\n",
    "        selected_factor = factor_dropdown.value\n",
    "        plot_pcoa_with_factor(pcoa_df, selected_factor)\n",
    "\n",
    "        # Enable and update the SIMPER condition dropdowns based on the selected factor\n",
    "        simper_dropdown_1.options = merged_data[selected_factor].unique()\n",
    "        simper_dropdown_2.options = merged_data[selected_factor].unique()\n",
    "        simper_dropdown_1.disabled = False\n",
    "        simper_dropdown_2.disabled = False\n",
    "\n",
    "\n",
    "# Function to run SIMPER after both conditions are selected\n",
    "def on_simper_change(change):\n",
    "    if simper_dropdown_1.value != simper_dropdown_2.value:\n",
    "        with output_simper:\n",
    "            output_simper.clear_output(wait=True)\n",
    "\n",
    "            # Filter data for the two selected conditions\n",
    "            selected_factor = factor_dropdown.value\n",
    "            group1 = merged_data[\n",
    "                merged_data[selected_factor] == simper_dropdown_1.value\n",
    "            ]\n",
    "            group2 = merged_data[\n",
    "                merged_data[selected_factor] == simper_dropdown_2.value\n",
    "            ]\n",
    "\n",
    "            # Calculate SIMPER and plot\n",
    "            simper_result = calculate_simper(group1, group2)\n",
    "            plot_simper(simper_result, simper_dropdown_1.value, simper_dropdown_2.value)\n",
    "\n",
    "\n",
    "# Link widget events to functions\n",
    "distance_metric_dropdown.observe(on_distance_change, names=\"value\")\n",
    "factor_dropdown.observe(on_factor_change, names=\"value\")\n",
    "simper_dropdown_1.observe(on_simper_change, names=\"value\")\n",
    "simper_dropdown_2.observe(on_simper_change, names=\"value\")\n",
    "\n",
    "# Display widgets and output areas\n",
    "display(\n",
    "    distance_metric_dropdown,\n",
    "    output_permanova,\n",
    "    output_pcoa,\n",
    "    factor_dropdown,\n",
    "    simper_dropdown_1,\n",
    "    simper_dropdown_2,\n",
    "    output_simper,\n",
    "    output_shannon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5106b0-68f8-4069-b064-970015102238",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Load the table from DuckDB into a DataFrame\n",
    "data = merged_data  # Use 'merged_data'\n",
    "\n",
    "\n",
    "# Ensure that we only use numeric data for distance calculation\n",
    "numeric_columns = [\n",
    "    col for col in data.columns if col.startswith(\"class_\")\n",
    "]  # Columns with the prefix 'class_'\n",
    "\n",
    "# Convert the columns to numeric (if they are not already) and replace NaN with 0\n",
    "data[numeric_columns] = (\n",
    "    data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "# Now compute the distance matrix\n",
    "def compute_distance_matrix(metric):\n",
    "    numeric_data = data[numeric_columns]  # Use updated data with NaNs replaced by 0\n",
    "\n",
    "    if metric == \"braycurtis\":\n",
    "        return squareform(pdist(numeric_data, metric=\"braycurtis\"))\n",
    "    elif metric == \"euclidean\":\n",
    "        return squareform(pdist(numeric_data, metric=\"euclidean\"))\n",
    "    elif metric == \"jaccard\":\n",
    "        return squareform(pdist(numeric_data, metric=\"jaccard\"))\n",
    "    elif metric == \"cityblock\":\n",
    "        return squareform(pdist(numeric_data, metric=\"cityblock\"))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric selected\")\n",
    "\n",
    "\n",
    "# Step 3: Perform PERMANOVA and PCoA based on the selected distance metric\n",
    "def run_permanova_and_pcoa(distance_matrix):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        permanova_summary = pd.DataFrame(columns=[\"Factor\", \"Pseudo-F\", \"p-value\"])\n",
    "        factors_to_analyze = [\n",
    "            col\n",
    "            for col in data.columns\n",
    "            if col not in numeric_columns and col != \"ref_code\"\n",
    "        ]\n",
    "        for factor in factors_to_analyze:\n",
    "            unique_values = data[factor].nunique()\n",
    "            if unique_values > 1:\n",
    "                try:\n",
    "                    dist_matrix_obj = DistanceMatrix(distance_matrix, ids=data.index)\n",
    "                    permanova_results = permanova(\n",
    "                        dist_matrix_obj, data[factor].values, permutations=999\n",
    "                    )\n",
    "                    pseudo_F = (\n",
    "                        permanova_results[\"test statistic\"]\n",
    "                        if \"test statistic\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    p_value = (\n",
    "                        permanova_results[\"p-value\"]\n",
    "                        if \"p-value\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    new_row = pd.DataFrame(\n",
    "                        {\n",
    "                            \"Factor\": [factor],\n",
    "                            \"Pseudo-F\": [pseudo_F],\n",
    "                            \"p-value\": [p_value],\n",
    "                        }\n",
    "                    )\n",
    "                    permanova_summary = pd.concat(\n",
    "                        [permanova_summary, new_row], ignore_index=True\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        permanova_summary = permanova_summary.sort_values(\n",
    "            by=\"Pseudo-F\", ascending=False\n",
    "        )\n",
    "        print(\"\\nPERMANOVA Summary:\")\n",
    "        print(permanova_summary.to_string(index=False))\n",
    "\n",
    "        # PCoA (PCA as approximation)\n",
    "        pcoa = PCA(n_components=2)\n",
    "        pcoa_coords = pcoa.fit_transform(distance_matrix)\n",
    "        pcoa_df = pd.DataFrame(\n",
    "            pcoa_coords, columns=[\"PCoA1\", \"PCoA2\"], index=data.index\n",
    "        )\n",
    "\n",
    "        return permanova_summary, pcoa_df\n",
    "\n",
    "\n",
    "# Plot the PCoA with optional coloring by Shannon index\n",
    "def plot_pcoa_black(pcoa_df, color_by=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if color_by is not None:\n",
    "        scatter = plt.scatter(\n",
    "            pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], c=color_by, cmap=\"RdYlGn\", edgecolor=\"k\"\n",
    "        )\n",
    "        plt.colorbar(scatter, label=\"Shannon Index\")\n",
    "    else:\n",
    "        plt.scatter(pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], color=\"black\")\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(\"PCoA Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the PCoA with the selected factor\n",
    "def plot_pcoa_with_factor(pcoa_df, selected_factor):\n",
    "    if selected_factor not in data.columns:\n",
    "        print(f\"Factor '{selected_factor}' not found in the metadata.\")\n",
    "        return\n",
    "\n",
    "    pcoa_df[selected_factor] = data[selected_factor].values\n",
    "    colors_list = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"orange\", \"purple\", \"pink\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    unique_values = pcoa_df[selected_factor].unique()\n",
    "    for i, value in enumerate(unique_values):\n",
    "        color = colors_list[i % len(colors_list)]\n",
    "        subset = pcoa_df[pcoa_df[selected_factor] == value]\n",
    "        plt.scatter(subset[\"PCoA1\"], subset[\"PCoA2\"], label=value, color=color)\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(f\"PCoA Plot Grouped by {selected_factor}\")\n",
    "    plt.legend(title=selected_factor)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SIMPER calculation\n",
    "def calculate_simper(group1, group2):\n",
    "    group1_filtered = group1[numeric_columns]\n",
    "    group2_filtered = group2[numeric_columns]\n",
    "\n",
    "    mean_group1 = group1_filtered.mean()\n",
    "    mean_group2 = group2_filtered.mean()\n",
    "\n",
    "    differences = abs(mean_group1 - mean_group2)\n",
    "    total_difference = differences.sum()\n",
    "    contributions = (differences / total_difference) * 100\n",
    "\n",
    "    return contributions\n",
    "\n",
    "\n",
    "# SIMPER plot\n",
    "def plot_simper(simper_result, selected_group1, selected_group2):\n",
    "    simper_result_sorted = simper_result.sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    simper_result_sorted.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Contribution to Dissimilarity (%)\")\n",
    "    plt.title(\n",
    "        f\"SIMPER: Top 20 Features Dissimilarity between {selected_group1} and {selected_group2}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Interactive part begins ---\n",
    "\n",
    "# Step 8: Define widgets\n",
    "distance_metric_dropdown = widgets.Dropdown(\n",
    "    options=[\"braycurtis\", \"euclidean\", \"jaccard\", \"cityblock\"],\n",
    "    description=\"Distance Metric:\",\n",
    ")\n",
    "\n",
    "factor_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        col for col in data.columns if col not in numeric_columns and col != \"ref_code\"\n",
    "    ],\n",
    "    description=\"PCoA Factor:\",\n",
    "    disabled=True,\n",
    ")\n",
    "\n",
    "simper_dropdown_1 = widgets.Dropdown(\n",
    "    options=[], description=\"SIMPER: Condition 1:\", disabled=True\n",
    ")\n",
    "\n",
    "simper_dropdown_2 = widgets.Dropdown(\n",
    "    options=[], description=\"SIMPER: Condition 2:\", disabled=True\n",
    ")\n",
    "\n",
    "# Output areas\n",
    "output_permanova = widgets.Output()\n",
    "output_pcoa = widgets.Output()\n",
    "output_simper = widgets.Output()\n",
    "output_shannon = widgets.Output()\n",
    "\n",
    "\n",
    "# Step 9: Function to run analysis after distance metric is selected\n",
    "def on_distance_change(change):\n",
    "    with output_permanova:\n",
    "        output_permanova.clear_output(wait=True)\n",
    "        with output_pcoa:\n",
    "            output_pcoa.clear_output(wait=True)\n",
    "            with output_shannon:\n",
    "                output_shannon.clear_output(wait=True)\n",
    "\n",
    "                selected_metric = distance_metric_dropdown.value\n",
    "                distance_matrix = compute_distance_matrix(selected_metric)\n",
    "\n",
    "                # PERMANOVA and initial PCoA\n",
    "                global permanova_summary, pcoa_df\n",
    "                permanova_summary, pcoa_df = run_permanova_and_pcoa(distance_matrix)\n",
    "\n",
    "                # Plot PCoA colored by Shannon index\n",
    "                plot_pcoa_black(pcoa_df)\n",
    "\n",
    "                # Update factor and SIMPER dropdowns\n",
    "                available_factors = [\n",
    "                    col\n",
    "                    for col in data.columns\n",
    "                    if col not in numeric_columns and col != \"ref_code\"\n",
    "                ]\n",
    "                factor_dropdown.options = available_factors\n",
    "                factor_dropdown.disabled = False\n",
    "\n",
    "                # Initialize SIMPER dropdowns\n",
    "                if factor_dropdown.value:\n",
    "                    current_factor = factor_dropdown.value\n",
    "                    simper_options = sorted(data[current_factor].unique())\n",
    "                    simper_dropdown_1.options = simper_options\n",
    "                    simper_dropdown_2.options = simper_options\n",
    "                    simper_dropdown_1.disabled = False\n",
    "                    simper_dropdown_2.disabled = False\n",
    "\n",
    "\n",
    "distance_metric_dropdown.observe(on_distance_change, names=\"value\")\n",
    "\n",
    "\n",
    "# Function to update PCoA plot after factor is selected\n",
    "def on_factor_change(change):\n",
    "    with output_pcoa:\n",
    "        output_pcoa.clear_output(wait=True)\n",
    "\n",
    "        # Plot the PCoA with colors based on the selected factor\n",
    "        selected_factor = factor_dropdown.value\n",
    "        plot_pcoa_with_factor(pcoa_df, selected_factor)\n",
    "\n",
    "        # Enable and update the SIMPER condition dropdowns based on the selected factor\n",
    "        simper_dropdown_1.options = data[selected_factor].unique()\n",
    "        simper_dropdown_2.options = data[selected_factor].unique()\n",
    "        simper_dropdown_1.disabled = False\n",
    "        simper_dropdown_2.disabled = False\n",
    "\n",
    "\n",
    "# Function to run SIMPER after both conditions are selected\n",
    "def on_simper_change(change):\n",
    "    if simper_dropdown_1.value != simper_dropdown_2.value:\n",
    "        with output_simper:\n",
    "            output_simper.clear_output(wait=True)\n",
    "\n",
    "            # Filter data for the two selected conditions\n",
    "            selected_factor = factor_dropdown.value\n",
    "            group1 = data[data[selected_factor] == simper_dropdown_1.value]\n",
    "            group2 = data[data[selected_factor] == simper_dropdown_2.value]\n",
    "\n",
    "            # Calculate SIMPER and plot\n",
    "            simper_result = calculate_simper(group1, group2)\n",
    "            plot_simper(simper_result, simper_dropdown_1.value, simper_dropdown_2.value)\n",
    "\n",
    "\n",
    "# Step 10: Link widget events to functions\n",
    "distance_metric_dropdown.observe(on_distance_change, names=\"value\")\n",
    "factor_dropdown.observe(on_factor_change, names=\"value\")\n",
    "simper_dropdown_1.observe(on_simper_change, names=\"value\")\n",
    "simper_dropdown_2.observe(on_simper_change, names=\"value\")\n",
    "\n",
    "# Display widgets and output areas\n",
    "display(\n",
    "    distance_metric_dropdown,\n",
    "    output_permanova,\n",
    "    output_pcoa,\n",
    "    factor_dropdown,\n",
    "    simper_dropdown_1,\n",
    "    simper_dropdown_2,\n",
    "    output_simper,\n",
    "    output_shannon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aac140-dafa-4481-bd95-ae467636e363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32f7c75-bfa3-4fae-b5b0-3ccbcfb0975f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b27202299624b058396cea68471002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Distance Metric:', options=('please select', 'braycurtis', 'euclidean', 'jaccard', 'city…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d43811972d4abeb151c3a0ef597112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04ada1f5d5147599d7acbb00f0a868b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e66db66ea004449b211b2eefa93e73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='PCoA Factor:', disabled=True, options=('please select', 'obs_id', 'project_name', 'latit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b821f0fb66724a08bb5f4d7b1a7a2759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='SIMPER: Condition 1:', disabled=True, options=('please select',), value='please select')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c6a5f103c48dcaeb6338aa7f50fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='SIMPER: Condition 2:', disabled=True, options=('please select',), value='please select')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77027e0219d5415981d3872066ff98af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load the table from DuckDB into a DataFrame\n",
    "data = merged_data  # Use 'merged_data'\n",
    "\n",
    "# Ensure that we only use numeric data for distance calculation\n",
    "numeric_columns = [\n",
    "    col for col in data.columns if col.startswith(\"class_\")\n",
    "]  # Columns with the prefix 'class_'\n",
    "metadata = [\n",
    "    col for col in data.columns if not col.startswith(\"class_\") and col != \"ref_code\"\n",
    "]\n",
    "\n",
    "# Convert the columns to numeric (if they are not already) and replace NaN with 0\n",
    "data[numeric_columns] = (\n",
    "    data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    ")\n",
    "# data[numeric_columns] = data[numeric_columns].astype(float).fillna(0)\n",
    "\n",
    "\n",
    "# Now all 'NaN' values in columns with names starting with 'class_' have been replaced with 0.\n",
    "\n",
    "\n",
    "# Now compute the distance matrix\n",
    "def compute_distance_matrix(metric):\n",
    "    numeric_data = data[numeric_columns]  # Use updated data with NaNs replaced by 0\n",
    "\n",
    "    if metric == \"braycurtis\":\n",
    "        return squareform(pdist(numeric_data, metric=\"braycurtis\"))\n",
    "    elif metric == \"euclidean\":\n",
    "        return squareform(pdist(numeric_data, metric=\"euclidean\"))\n",
    "    elif metric == \"jaccard\":\n",
    "        return squareform(pdist(numeric_data, metric=\"jaccard\"))\n",
    "    elif metric == \"cityblock\":\n",
    "        return squareform(pdist(numeric_data, metric=\"cityblock\"))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric selected\")\n",
    "\n",
    "\n",
    "# Continue with the rest of the code\n",
    "\n",
    "\n",
    "# Step 3: Perform PERMANOVA and PCoA based on the selected distance metric\n",
    "def run_permanova_and_pcoa(distance_matrix):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        permanova_summary = pd.DataFrame(columns=[\"Factor\", \"Pseudo-F\", \"p-value\"])\n",
    "        factors_to_analyze = [\n",
    "            col\n",
    "            for col in data.columns\n",
    "            if col not in numeric_columns and col != \"ref_code\"\n",
    "        ]\n",
    "        for factor in factors_to_analyze:\n",
    "            unique_values = data[factor].nunique()\n",
    "            if unique_values > 1:\n",
    "                try:\n",
    "                    dist_matrix_obj = DistanceMatrix(distance_matrix, ids=data.index)\n",
    "                    permanova_results = permanova(\n",
    "                        dist_matrix_obj, data[factor].values, permutations=999\n",
    "                    )\n",
    "                    pseudo_F = (\n",
    "                        permanova_results[\"test statistic\"]\n",
    "                        if \"test statistic\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    p_value = (\n",
    "                        permanova_results[\"p-value\"]\n",
    "                        if \"p-value\" in permanova_results\n",
    "                        else None\n",
    "                    )\n",
    "                    new_row = pd.DataFrame(\n",
    "                        {\n",
    "                            \"Factor\": [factor],\n",
    "                            \"Pseudo-F\": [pseudo_F],\n",
    "                            \"p-value\": [p_value],\n",
    "                        }\n",
    "                    )\n",
    "                    permanova_summary = pd.concat(\n",
    "                        [permanova_summary, new_row], ignore_index=True\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        permanova_summary = permanova_summary.sort_values(\n",
    "            by=\"Pseudo-F\", ascending=False\n",
    "        )\n",
    "        print(\"\\nPERMANOVA Summary:\")\n",
    "        print(permanova_summary.to_string(index=False))\n",
    "\n",
    "        # PCoA (PCA as approximation)\n",
    "        pcoa = PCA(n_components=2)\n",
    "        pcoa_coords = pcoa.fit_transform(distance_matrix)\n",
    "        pcoa_df = pd.DataFrame(\n",
    "            pcoa_coords, columns=[\"PCoA1\", \"PCoA2\"], index=data.index\n",
    "        )\n",
    "\n",
    "        return permanova_summary, pcoa_df\n",
    "\n",
    "\n",
    "# Plot the PCoA with optional coloring by Shannon index\n",
    "def plot_pcoa_black(pcoa_df, color_by=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if color_by is not None:\n",
    "        scatter = plt.scatter(\n",
    "            pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], c=color_by, cmap=\"RdYlGn\", edgecolor=\"k\"\n",
    "        )\n",
    "        plt.colorbar(scatter, label=\"Shannon Index\")\n",
    "    else:\n",
    "        plt.scatter(pcoa_df[\"PCoA1\"], pcoa_df[\"PCoA2\"], color=\"black\")\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(\"PCoA Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the PCoA with the selected factor\n",
    "def plot_pcoa_with_factor(pcoa_df, selected_factor):\n",
    "    if selected_factor not in data.columns:\n",
    "        print(f\"Factor '{selected_factor}' not found in the metadata.\")\n",
    "        return\n",
    "\n",
    "    pcoa_df[selected_factor] = data[selected_factor].values\n",
    "    colors_list = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"orange\", \"purple\", \"pink\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    unique_values = pcoa_df[selected_factor].unique()\n",
    "    for i, value in enumerate(unique_values):\n",
    "        color = colors_list[i % len(colors_list)]\n",
    "        subset = pcoa_df[pcoa_df[selected_factor] == value]\n",
    "        plt.scatter(subset[\"PCoA1\"], subset[\"PCoA2\"], label=value, color=color)\n",
    "\n",
    "    plt.xlabel(\"PCoA1\")\n",
    "    plt.ylabel(\"PCoA2\")\n",
    "    plt.title(f\"PCoA Plot Grouped by {selected_factor}\")\n",
    "    plt.legend(title=selected_factor)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SIMPER calculation\n",
    "def calculate_simper(group1, group2):\n",
    "    group1_filtered = group1[numeric_columns]\n",
    "    group2_filtered = group2[numeric_columns]\n",
    "\n",
    "    mean_group1 = group1_filtered.mean()\n",
    "    mean_group2 = group2_filtered.mean()\n",
    "\n",
    "    differences = abs(mean_group1 - mean_group2)\n",
    "    total_difference = differences.sum()\n",
    "    contributions = (differences / total_difference) * 100\n",
    "\n",
    "    return contributions\n",
    "\n",
    "\n",
    "# SIMPER plot\n",
    "def plot_simper(simper_result, selected_group1, selected_group2):\n",
    "    simper_result_sorted = simper_result.sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    simper_result_sorted.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Contribution to Dissimilarity (%)\")\n",
    "    plt.title(\n",
    "        f\"SIMPER: Top 20 Features Dissimilarity between {selected_group1} and {selected_group2}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Interactive part begins ---\n",
    "\n",
    "# Step 8: Define widgets\n",
    "\n",
    "# Adding \"please select\" as the first option for the distance metric dropdown\n",
    "distance_metric_dropdown = widgets.Dropdown(\n",
    "    options=[\"please select\", \"braycurtis\", \"euclidean\", \"jaccard\", \"cityblock\"],\n",
    "    description=\"Distance Metric:\",\n",
    ")\n",
    "\n",
    "# Adding \"please select\" as the first option for the factor dropdown\n",
    "factor_dropdown = widgets.Dropdown(\n",
    "    options=[\"please select\"]\n",
    "    + [col for col in data.columns if col not in numeric_columns and col != \"ref_code\"],\n",
    "    description=\"PCoA Factor:\",\n",
    "    disabled=True,\n",
    ")\n",
    "\n",
    "# SIMPER dropdowns with \"please select\" as the default\n",
    "simper_dropdown_1 = widgets.Dropdown(\n",
    "    options=[\"please select\"], description=\"SIMPER: Condition 1:\", disabled=True\n",
    ")\n",
    "\n",
    "simper_dropdown_2 = widgets.Dropdown(\n",
    "    options=[\"please select\"], description=\"SIMPER: Condition 2:\", disabled=True\n",
    ")\n",
    "\n",
    "\n",
    "# Step 9: Function to run analysis after distance metric is selected\n",
    "def on_distance_change(change):\n",
    "    if (\n",
    "        distance_metric_dropdown.value != \"please select\"\n",
    "    ):  # Only run if a valid option is selected\n",
    "        with output_permanova:\n",
    "            output_permanova.clear_output(wait=True)\n",
    "            with output_pcoa:\n",
    "                output_pcoa.clear_output(wait=True)\n",
    "                with output_shannon:\n",
    "                    output_shannon.clear_output(wait=True)\n",
    "\n",
    "                    selected_metric = distance_metric_dropdown.value\n",
    "                    distance_matrix = compute_distance_matrix(selected_metric)\n",
    "\n",
    "                    # PERMANOVA and initial PCoA\n",
    "                    global permanova_summary, pcoa_df\n",
    "                    permanova_summary, pcoa_df = run_permanova_and_pcoa(distance_matrix)\n",
    "\n",
    "                    # Plot PCoA colored by Shannon index\n",
    "                    plot_pcoa_black(pcoa_df)\n",
    "\n",
    "                    # Update factor and SIMPER dropdowns\n",
    "                    available_factors = [\"please select\"] + [\n",
    "                        col\n",
    "                        for col in data.columns\n",
    "                        if col not in numeric_columns and col != \"ref_code\"\n",
    "                    ]\n",
    "                    factor_dropdown.options = available_factors\n",
    "                    factor_dropdown.disabled = False\n",
    "\n",
    "                    # Initialize SIMPER dropdowns\n",
    "                    if (\n",
    "                        factor_dropdown.value\n",
    "                        and factor_dropdown.value != \"please select\"\n",
    "                    ):\n",
    "                        current_factor = factor_dropdown.value\n",
    "                        simper_options = [\"please select\"] + sorted(\n",
    "                            data[current_factor].unique()\n",
    "                        )\n",
    "                        simper_dropdown_1.options = simper_options\n",
    "                        simper_dropdown_2.options = simper_options\n",
    "                        simper_dropdown_1.disabled = False\n",
    "                        simper_dropdown_2.disabled = False\n",
    "\n",
    "\n",
    "# Step 9b: Function to handle factor change and plot PCoA with selected factor\n",
    "def on_factor_change(change):\n",
    "    if factor_dropdown.value != \"please select\":  # Ensure a valid factor is selected\n",
    "        with output_pcoa:\n",
    "            output_pcoa.clear_output(wait=True)\n",
    "            selected_factor = factor_dropdown.value\n",
    "            plot_pcoa_with_factor(pcoa_df, selected_factor)\n",
    "\n",
    "        # Enable and populate SIMPER dropdowns\n",
    "        simper_options = [\"please select\"] + sorted(data[selected_factor].unique())\n",
    "        simper_dropdown_1.options = simper_options\n",
    "        simper_dropdown_2.options = simper_options\n",
    "        simper_dropdown_1.disabled = False\n",
    "        simper_dropdown_2.disabled = False\n",
    "    else:\n",
    "        # Disable SIMPER dropdowns if no valid factor is selected\n",
    "        simper_dropdown_1.disabled = True\n",
    "        simper_dropdown_2.disabled = True\n",
    "\n",
    "\n",
    "# Function to run SIMPER after both conditions are selected\n",
    "def on_simper_change(change):\n",
    "    if simper_dropdown_1.value != simper_dropdown_2.value:\n",
    "        with output_simper:\n",
    "            output_simper.clear_output(wait=True)\n",
    "\n",
    "            # Filter data for the two selected conditions\n",
    "            selected_factor = factor_dropdown.value\n",
    "            group1 = merged_data[\n",
    "                merged_data[selected_factor] == simper_dropdown_1.value\n",
    "            ]\n",
    "            group2 = merged_data[\n",
    "                merged_data[selected_factor] == simper_dropdown_2.value\n",
    "            ]\n",
    "\n",
    "            # Calculate SIMPER and plot\n",
    "            simper_result = calculate_simper(group1, group2)\n",
    "            plot_simper(simper_result, simper_dropdown_1.value, simper_dropdown_2.value)\n",
    "\n",
    "\n",
    "# Step 10: Link widget events to functions\n",
    "distance_metric_dropdown.observe(on_distance_change, names=\"value\")\n",
    "factor_dropdown.observe(\n",
    "    on_factor_change, names=\"value\"\n",
    ")  # Now linked to the correct function\n",
    "simper_dropdown_1.observe(\n",
    "    on_simper_change, names=\"value\"\n",
    ")  # Assuming on_simper_change is defined\n",
    "simper_dropdown_2.observe(\n",
    "    on_simper_change, names=\"value\"\n",
    ")  # Assuming on_simper_change is defined\n",
    "\n",
    "\n",
    "# Display widgets and output areas\n",
    "display(\n",
    "    distance_metric_dropdown,\n",
    "    output_permanova,\n",
    "    output_pcoa,\n",
    "    factor_dropdown,\n",
    "    simper_dropdown_1,\n",
    "    simper_dropdown_2,\n",
    "    output_simper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a5af5-15af-4cf0-b0ed-a56cf1bc7f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
