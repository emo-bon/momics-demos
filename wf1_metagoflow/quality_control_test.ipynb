{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querry data based on ro-Crates\n",
    "\n",
    "1. This specifically looks at the intermediate steps of the metaGOflow pipeline.\n",
    "2. `fastap` outputs\n",
    "3. ...\n",
    "\n",
    "**Steps:** (for each metaGOflow step)\n",
    "1. Acess ro-crate metadata file and extract needed data sources\n",
    "2. Get the data\n",
    "3. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import gc\n",
    "import logging\n",
    "import psutil\n",
    "\n",
    "from IPython import get_ipython\n",
    "logger = logging.getLogger(name=\"Diversity analysis app\")\n",
    "NUMBER_PERMUTATIONS = 999\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Setting Google colab, you will need a ngrok account to make the dashboard display over the tunnel. \\\n",
    "    https://ngrok.com/')\n",
    "    # clone the momics-demos repository to use it to load data\n",
    "    try:\n",
    "        os.system('git clone https://github.com/palec87/momics-demos.git')\n",
    "        logger.info(f\"Repository cloned\")\n",
    "    except OSError as e:\n",
    "        logger.info(f\"An error occurred while cloning the repository: {e}\")\n",
    "\n",
    "    sys.path.insert(0,'/content/momics-demos')\n",
    "\n",
    "    # this step takes time beacause of many dependencies\n",
    "    os.system('pip install momics@git+https://github.com/emo-bon/marine-omics-methods.git@main')\n",
    "\n",
    "elif psutil.users() == []:\n",
    "    logger.info(\"Binder\")\n",
    "    NUMBER_PERMUTATIONS = 29  # permanova extremely slow on binder, therefore a change here\n",
    "else:\n",
    "    logger.info(\"Local\")\n",
    "\n",
    "\n",
    "from momics.utils import (\n",
    "    memory_load, reconfig_logger,\n",
    "    init_setup, get_notebook_environment,\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "reconfig_logger()\n",
    "\n",
    "# Determine the notebook environment\n",
    "env = get_notebook_environment()\n",
    "\n",
    "init_setup()\n",
    "logger.info(f\"Environment: {env}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be repeated here for the Pannel dashboard to work, WEIRD\n",
    "# TODO: report as possible bug\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import panel as pn\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# from json2txttree import json2txttree\n",
    "\n",
    "# All low level functions are imported from the momics package\n",
    "from momics.loader import get_ro_crate_metadata_gh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying new public access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rocrate_metadata(sample_id):\n",
    "    \"\"\"\n",
    "    Get the metadata from the ro-crate\n",
    "    \"\"\"\n",
    "    # Get the metadata from the ro-crate\n",
    "    url = f\"https://api.github.com/repos/emo-bon/analysis-results-cluster-01-crate/contents/{sample_id}-ro-crate/ro-crate-metadata.json\"\n",
    "    req = requests.get(\n",
    "        url,\n",
    "        headers={\n",
    "            \"accept\": \"application/vnd.github.v3.raw\",\n",
    "        },\n",
    "    )\n",
    "    print(\"ro-crate-metadata.json request status\", req.status_code)\n",
    "    return req.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro-crate-metadata.json request status 200\n"
     ]
    }
   ],
   "source": [
    "# TODO: is this nomenclature the final one?\n",
    "sample_id = \"EMOBON_PiEGetxo_Wa_4\"\n",
    "met_json = get_rocrate_metadata(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pretty nice tool\n",
    "# print(json2txttree(met_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "- I do not really want to code parsing of this html\n",
    "  - TODO: check for some written analyser of fastap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_by_name(metadata, name='FASTP analysis of raw sequence data'):\n",
    "    for d in metadata['@graph']:\n",
    "        if 'name' in d.keys() and d['name'] == name:\n",
    "            data = d\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_all_datafiles(metadata):\n",
    "    datafiles = []\n",
    "    for d in metadata['@graph']:\n",
    "        if 'name' in d.keys() and d['@type'] == 'File':\n",
    "            data_unit = {}\n",
    "            data_unit['name'] = d['name']\n",
    "            try:\n",
    "                # in MB\n",
    "                data_unit['sizeMB'] = int(int(d['contentSize'])/1e6)\n",
    "            except KeyError:\n",
    "                data_unit['sizeMB'] = 'unknown'\n",
    "\n",
    "            try:\n",
    "                data_unit['downloadUrl'] = d['downloadUrl']\n",
    "            except KeyError:\n",
    "                data_unit['downloadUrl'] = 'unknown'\n",
    "            datafiles.append(data_unit)\n",
    "            \n",
    "    return datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 53)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all related data files\n",
    "datafiles = extract_all_datafiles(met_json)\n",
    "assert len(datafiles) == len([k for k in datafiles if k['sizeMB'] != 'unknown'])\n",
    "assert len(datafiles) == len([k for k in datafiles if k['downloadUrl'] != 'unknown'])\n",
    "\n",
    "len(datafiles), len([k for k in datafiles if k['sizeMB'] < 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this means I have 50 outputs which I can do something about with size < 50 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'FASTP analysis of raw sequence data',\n",
       "  'sizeMB': 0,\n",
       "  'downloadUrl': 'https://s3.mesocentre.uca.fr/mgf-data-products/files/md5/99/d78d57cf8c0ebc38e15162b0afe37f'},\n",
       " {'name': 'FASTA formatted contig sequences',\n",
       "  'sizeMB': 92,\n",
       "  'downloadUrl': 'https://s3.mesocentre.uca.fr/mgf-data-products/files/md5/b4/1de79ad2ea5e565064d74362b76563'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all data files which contain word fastq\n",
    "[k for k in datafiles if 'fast' in k['name'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MetaGOflow YAML configuration file',\n",
       " 'FASTP analysis of raw sequence data',\n",
       " 'FASTA formatted contig sequences',\n",
       " 'MetaGOflow configuration in YAML',\n",
       " 'Overlapped coding sequences',\n",
       " 'Trimmed forward reads',\n",
       " 'Unfiltered merged reads',\n",
       " 'Trimmed reverse reads',\n",
       " 'Trimmed reverse reads QC summary',\n",
       " 'Protein coding nucleotide sequences',\n",
       " 'QC summary of merged reads',\n",
       " 'Trimmed forward reads QC summary',\n",
       " 'MOTUs',\n",
       " 'Protein coding amino acid sequences',\n",
       " 'Merged reads',\n",
       " 'Geno Ontology summary statistics',\n",
       " 'InterProScan summary statistics',\n",
       " 'Kegg Ontology summary statistics',\n",
       " 'ORF summary statistics',\n",
       " 'Pfam summary statistcs',\n",
       " 'Merged contigs CDS I5 summary',\n",
       " 'Merged contigs HMM summary',\n",
       " 'Merged contigs GO summary',\n",
       " 'Merged contigs InterProScan slim',\n",
       " 'Merged contigs InterProScan',\n",
       " 'Merged contigs KO summary',\n",
       " 'Merged contigs PFAM summary',\n",
       " 'RDF 1.2 Turtle triples of the functional analyses results',\n",
       " 'Eggnog emapper summary',\n",
       " 'RNA prediction for 5_8S',\n",
       " 'RNA prediction for LSU_rRNA_archaea - Rfam accesssion number: RF02540',\n",
       " 'RNA prediction for LSU_rRNA_eukarya - Rfam accesssion number: RF02543',\n",
       " 'RNA prediction for alpha_tmRNA - Rfam accesssion number: RF01849',\n",
       " 'RNA prediction for Bacteria_small_SRP - Rfam accesssion number: RF00169',\n",
       " 'RNA prediction for cyano_tmRNA - Rfam accesssion number: RF01851',\n",
       " 'RNA prediction for tRNA - Rfam accesssion number: RF00005',\n",
       " 'RNA prediction for LSU_rRNA_bacteria - Rfam accesssion number: RF02541',\n",
       " 'RNA prediction for RNaseP_bact_a - Rfam accesssion number: RF00010',\n",
       " 'RNA prediction for RNaseP_arch - Rfam accesssion number: RF00373',\n",
       " 'RNA prediction for tRNA-Sec - Rfam accesssion number: RF01852',\n",
       " 'RNA prediction for Metazoa_SRP - Rfam accesssion number: RF00017',\n",
       " 'RNA prediction for tmRNA - Rfam accesssion number: RF00023',\n",
       " 'RNA prediction for SSU_rRNA_eukarya - Rfam accesssion number: RF01960',\n",
       " 'RNA prediction for SSU_rRNA_bacteria - Rfam accesssion number: RF00177',\n",
       " 'RNA prediction for SSU_rRNA_archaea - Rfam accesssion number: RF01959',\n",
       " \"Numbers of RNA's counted\",\n",
       " 'Krona summary of LSU taxonomic inventory',\n",
       " 'LSU sequences used for identification',\n",
       " 'BIOM formatted hdf5 taxon counts for LSU sequences',\n",
       " 'BIOM formatted taxon counts for LSU sequences',\n",
       " 'Tab-separated formatted taxon counts for LSU sequences',\n",
       " 'Text-based taxon counts for LSU sequences',\n",
       " 'RDF 1.2 Turtle triples of the LSU taxonomic analyses results',\n",
       " 'Krona summary of SSU taxonomic inventory',\n",
       " 'SSU sequences used for identification',\n",
       " 'BIOM formatted hdf5 taxon counts for SSU sequences',\n",
       " 'BIOM formatted taxon counts for SSU sequences',\n",
       " 'Tab-separated formatted taxon counts for SSU sequences',\n",
       " 'Text-based formatted taxon counts for SSU sequences',\n",
       " 'RDF 1.2 Turtle triples of the SSU taxonomic analyses results']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k['name' ] for k in datafiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@id': './final.contigs.fa.bz2',\n",
       "  '@type': 'File',\n",
       "  'name': 'FASTA formatted contig sequences',\n",
       "  'description': 'These are the assembled contig sequences from the merged reads in FASTA format',\n",
       "  'downloadUrl': 'https://s3.mesocentre.uca.fr/mgf-data-products/files/md5/b4/1de79ad2ea5e565064d74362b76563',\n",
       "  'encodingFormat': 'application/x-bzip2',\n",
       "  'contentSize': '92742645'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in met_json['@graph'] if k['@type'] == 'File' and k['name'] == 'FASTA formatted contig sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_data_by_name(met_json)\n",
    "r = requests.get(data['downloadUrl'])\n",
    "print(r.status_code)\n",
    "\n",
    "# both look the same, but plots are generated by scripts, will not display here\n",
    "# display(HTML(r.content.decode('utf-8')))\n",
    "HTML(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questionable for Gcolab, but locally works\n",
    "import webbrowser\n",
    "webbrowser.open_new_tab(data['downloadUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momics-demos",
   "language": "python",
   "name": "momics-demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
